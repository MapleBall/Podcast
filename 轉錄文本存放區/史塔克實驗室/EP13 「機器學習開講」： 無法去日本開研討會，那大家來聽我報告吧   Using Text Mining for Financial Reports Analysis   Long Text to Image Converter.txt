(00:00~01:00) 沒有武漢肺炎的話 這一週原本我應該是在日本賞的 Confluence 一邊逛東京 武漢肺炎 這邊是武漢流感的啦 那我今天就來介紹一下我會在研討會講的題目吧 Useing tax mining for finance repose analysis Long tax to a magic converter 哈囉大家好歡迎收聽史達克實驗室我是李嘉豪 那今天就想開頭我們講的 我們就來分享 我會在日本的研討會所講所演講的一個內容 那題目呢是關於 使用機器學習然後來分析 彩報 這種東西好像很多人講過類似的題目 跟人家不一樣的事情是 我是直接讓模型去學習看彩報的圖而不是看他的文字 那這種看圖的方式呢就有點像是 機器學習去分類貓跟狗 我會讓機器學習分類的是
(01:00~02:02) 彩報的影像 那用影像去分類這個彩報到底是一個好 他們講的裡面講的都 他們對未來公司的展望是好還是不好 那我們就留給一下等一下我來講好了 那我在講的過程中我可能會用中音交雜的方式然後來去跟大家介紹 那我前面會先講一下一些知識背景以及簡介 I will introduce some background and introduction Deverihingchen He was one of the important and influential researchers to work on machine learning field 2018 In a speech His topic is the Application of text image information analysis He mentioned a new ideas which is using convolution neural network to handle article image analysis 好 那Deverihingchen這位學者呢 他是一位 蠻有名而且影響力很深的一位科學家研究者 在我們機器學習領域裡面
(02:02~03:04) 那在2018年的時候呢 他提到了一些文字影像的資料處理的應用 然後在一個演講裡面 那就提到一個蠻新的一個概念就是用 convolution neural network這個模型然後來去分析我們文章的影像 We took a ballstone traditional text analysis technique When analysis a long article We need to separate the sentence word 那我們先來談一下比較傳統的一些NLP技術好了文字分析的技術 當我們在分析一個比較長句子的文章的時候啊 我們需要先用段字 像是今天天氣很好好了我們會把它變成今天天氣 剛好變成三個字 那英文就是用空格去分嘛那中文就比較麻煩 我們要用一些經驗或者是字典來去分類它 把段字 After separating sentence to many words
(03:04~04:06) We will using some technique to handle this text information Like back of word Water vector Or dictionary to filter useless words And again use for words waiting This information preprocess on necessary but wasting our research time 那在經過段字之後呢我們會使用一些技術 去處理這些字的資訊 像是back of word 那下面我就不翻中文了因為是一些技術的名詞 像 Water vector back of word或者是一些字典 然後他們可以去 為什麼要用一些專業的字典呢因為我們會想要把 比較我們講話的時候一些罪字啊 我們會把它處理掉 只剩下那些 有用的單字然後來去處理它 那因為這些上述這些錢處理的動作都其實蠻浪費時間的 所以我們纔想要去使用比較新的技術看看可不可以直接分類 我們文章的圖片 Gerry Hinton proposed the ideal is using
(04:06~05:07) Convolution neural network to analysis article information Instance traditional and your pre-technic 那我剛剛講到的這位大師Gerry Hinton呢他就提到一個 新的點子嘛那他就是使用 分類圖像的一個技術然後來去直接處理而不是使用 傳統文字的分析技術 And we compare this three methods Critic Information learned Traditional and your pre-technic and our LTIC could handle Short and long text information In preprocessed part Only traditional and your pre-technic to need to use this step The second method will analysis some distortion image That's your influence layer in accuracy 我去讀了一些paper然後去比較一些分析方法 那在文字那在文章的長度的話 傳統的NLP技術還有我們即將創造出來的 LTIC model 他們都可以處理比較長文章和短文章的部分資訊
(05:07~06:11) 那在前處理的部分呢 只有傳統的NLP技術需要用到這個部分前處理 那在第二個 那在其他論文有用到這種去偵測影像文字意義的一些技術呢 他們有的時候照到真實世界的圖像 會產生一些distortion distortion就有點像影像扭曲啊或石針這樣子 那這種影像資訊會去影響到他們模型最後判別出來的一個正確率 Let's put in your pre-technic aside And compile the other method Let's do method both reduce the pre-process time Different is our LTIC method could serve long text information And our information wouldn't have distortion 那我們先不管傳統的文字分析技術好了 我們先比較其他文章跟我們的LTIC model 我們都可以不要去做前處理的動作 然後都可以大量的節省這一方面的時間 但不一樣的是
(06:11~07:18) 我們的LTIC可以去處理長文章的資訊 而且我們的影像資訊不會失真 Our proposal are creating the LTIC model Optimize the parameter And we could reduce the time for article classification Finally, we will validate the feasibility of the LTIC 那我們這邊的目的就是創造出 我們剛剛上述這個比較新的分類技術的模型 並且我們驗證它的可信度 這個模型創造出來之後 我們就可以為文字分析的技術 直接節省到一些前處理的時間 我們就不用那邊斷字然後朝字點等等 那些前處理的動作 那下面我們會介紹一些我們的方法和我們的實驗 The classification problem is analysis of financial 10k report
(07:18~08:21) The 10k report, 7 chapters usually write the company financial status and chain in the future 那我們來介紹一下我們的模型架構好了 我們的基底是使用CNN技術 然後來去處理一個分類問題 這個分類問題我們會來分析公司的年度財報 這份年度財報的第七章通常公司會寫 他們對於這家公司的內部狀況以及未來的趨勢 分析未來趨勢我們就可以知道 他們這個作者在寫這份財報的態度是正面、負面 還是其實跟去年差不多的狀況 我們的資料會選擇美國公司的資料報告 而這份資料會從美國國際保安及交流公司的資料 我們的財報就是剛剛講的天橋報告
(08:21~09:22) 然後會從剛剛我們上述講的美國國際公司這個組織下載而來 我們選擇公司為我們的訓練資料和測試資料 我們選擇了Apo,Micron Technology,Sensata,Technology Holding, and Midlife 在此我們選擇了兩個資料報告去測試我們的模特兒資料 第一種是測試資料會使用國際公司 但是他們有不同的年度在訓練資料和測試資料 我們選擇了另外四個公司為我們的第二個測試資料 Layer Period 2015-2017 Financial Reports 我們這邊先選了四個公司當作我們的訓練及測試及 像Apple,Migron,Midlife,Sensata,Technology Holding 我們先選了幾家公司當作我們的訓練及 因為我們要進一步驗證我們模型的可信度
(09:22~10:23) 我們會選擇另外兩個訓練及 其中第一個訓練及是同樣的四家公司,但不同年份 我們會選擇四家不同的公司 當作我們的驗證及,用這兩個驗證及來測試模型的正確率 經過我的正確率來看一下模型可信度有多少 OK,Next we will optimize the input data image First, we will abandon the image black area Layer uses this information,所以我們會把這資料放在訓練的資料中 我們一張圖片下載下來之後 我們寫文章在一張A4紙裡面總會看到 總會看到有一些空白區域,因為我們寫些寫 下面會有一些空白區域,我們寫Word或其他 看PDF的時候也是如此 那我們就會把這些空白區域捨棄 不要去把它拿去訓練,因為這些是一些沒有用的資訊 我們會改變 image size
(10:23~11:25) 接下來我們會去優化我們的影像尺寸 我們控制了2 parameter, length and width 它的領域是pixels,我們測試13不同的parameters 我們想知道哪一個有好表現,我們想知道哪一個有好表現 所以我們會控制兩個變數 影像的我們會去拆切它的長度跟寬度 會去把一篇文章拆切,然後去得到最佳的長度跟寬度 我們去設計了13種不同的變數在裡面 我們會想知道哪一種參數組合會是最好的 根據上一步,我們會把依照的關係與parameters,Area Lens or White 我們要看這條依照,White and Accuracy White and Accuracy has positive correlation
(11:25~12:28) 所以我們說的 white parameter is 12000 pixels When people reading front size of the articles are almost 16 pixels to 25 pixels We want to simulate these behaviors So we said length parameter is 25 pixels 那我們最後有看到影像寬度跟正確率有一個正相關的部分 所以我們的影像寬度最後是取1200 pixels 它就是原始影像的最大寬度 長度的部分我們是沒有看到正相關的部分 其實都差不多,所以我們會想要去模擬人類在讀文章的行為 我們是一行一行讀的,每一次只會看一行 文字長度大概都是在16到25 pixels的部分 所以我們最後想要模擬人類這個行為 影像的長度我們就設計成25 pixel
(12:28~13:28) Our final target is using our model to read 10k reports and predicts next year stock price trend So our upper label is different between two years If next year price is higher than last year, we label earth rise If next year price is lower than last year, we label drop The discrepancy between two price is within 5% The statement we will label as no change 那我們最終目的就是用我們的模型去閱讀美國的財報 去看明年的趨勢是怎麼樣 那我們就做一個預測 那我們 label 就會去比較兩年的價差是多少 如果我們今年的價差比去年還要高的話 我們就標記為上升嘛 那我們今年跟...那我們的今年 如果比去年的價錢來的低 我們就標記為下降 那如果兩年的...那如果兩年的價差不超過5%的話
(13:28~14:28) 我們就標記為差不多就是 no change Summarize our model structure Our input data is US company 10k reports Imager size will cut to 25 cross 12,000 pixels 那我們剛剛講到我們的訓練級就是使用美國財報嘛 那影像才切成25成1200px Our LTIC is based on convolution network And we decide containing two convolution layers The first convolution layer has 5T kernels And layer size is 10 cross 10 The second convolution layer has 25 kernels And its size is 5 cross 5 pixels And finally we have the two fully connected layers It has 1024 and 512 NURALs 那我們有提到說我們的基底是使用CNN model嘛
(14:28~15:28) 那CNN model會有 convolution layer 跟 fully connected layer 那這邊就是講一下我的參數是怎麼設計的 第一層的 convolution layer 是有 50 kernel 那它的 size 是10x10 每次往右移1 pixel 而第二個 convolution layer 是有25 kernel 那它的 size 大小是5x1 那 fully connected layer 全年階層的部分 第一層有兩層全年階層 那第一層是1024 第二層是512 NURAL Our output label has three categories Rise, Drop and No Change 那我分類就是分成三類嘛 上成下降跟不變 Show our experiment results 那接下來呢我們就來講一下我們的實驗結果 Accuracy, Precision, Recode and Influence Score are common edicates in machine learning field We will use these four educates to evaluate our model performance
(15:28~16:31) 那我剛剛講到了那四個指標就是 Accuracy, Precision, Recode and Influence Score 那這四個東西都是在機器學習領域中 最常見到的四個指標 那大家就會用這些四個指標的數字大小 然後來判斷這個模型的好壞 那數字越大當然是越好 And we get the confusion matrix We could calculate this indicator 那我們先得到了混亂矩陣 就可以從混亂矩陣中去計算 剛剛我們講的那四個指標 The testing data accuracy is 80% Position is 83, Recode is 86 And the difference score is 84 So our LTIC model achieves a good classification result 那剛剛我們有看聽到的四個數字就是 80, 83, 86跟84 從這數字的大小我們認為 已經得到了一個不錯的分類效果 In attention We check the validation data set performance
(16:31~17:33) The result of validation data set 1 It shows that when data set are same company's compensation The accuracy and the other indicators Different are within 3% However, validation data set 2 Experiment result is lower than other groups The result is that Validation data set 2 Financial compensation has never been changed That is the reason reducing the accuracy Therefore, if you want to predict a new company's doctrine We will need to use new data set to retrain And getting better accuracy results 那我們有看到說在驗證級1的部分 它最後的結果其實出來數字是 正確率是78, 80, 84跟82 那它就跟我們原始剛剛講的 Testing data set最後的結果差不多 那如果差大概誤差在3%之內
(17:33~18:33) 那我們覺得是一個不錯的預測結果 在驗證級2的部分出來就比較差一點 它的正確率是60, 70, 62跟66 那我們看到這個結果其實 正確率就比其他兩個還要爛 就比我們原始的Testing data 還有我們第一個驗證級 低滿多的 我們覺得呢 是因為我們根本就沒有去 training這個驗證級2的 任何一家公司的財報 因為他們的用詞或者是一些 重點的部分可能完全 他們的影像放的地方可能會不一樣 他們表現的地方很不一樣 那我們的驗證級1跟我們原本的 Testing data是用一樣的公司 那它的表現出來的結果就不錯 那所以我們覺得如果以後 那我們要在做不同的公司的時候 可能就是要做一個retraining的動作 然後來讓這個表現 會得到比較好的結果 我們剛剛聽到那些正確率的數字 像67, 16, 26, 26 其實都還是比50%好 所以我們還是覺得
(18:33~19:34) 是有達到一個普通的水準 雖然沒有我們一開始 雖然沒有我們原本模型 就是做特定公司的訓練的時候來得好 但是也是有一個不錯的效果 Finaly is all conclusion 那我們最後講一下結論吧 我們在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面
(19:34~20:34) 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 我們想要在這方面 注意 如果你想將新增機的狀況 重新建立 我們需要用新的電腦設計 去重新按進 會更改 越多的規律 好那就是我剛剛講的結論 就是我們成功的建立了 LTIC的模型 得到的證券率也不錯
(20:34~21:35) 只是比較美中不足的東西 如果我們今天要換一個公司預測 但是我們沒有讓他學習 公司的財報的話 可能正確率就會差蠻多的 比較差一點大概在60幾% 這個上 大概在60幾% 那如果我們是預測 我們本來就在這幾家的公司的話 那他的正確率就不錯 都是在8成左右 那大概我想分 我的分享的資訊就到這邊 那我還是覺得很可惜 這一次沒有跑到日本 去參加這一個conference 真的是很該死的武漢肺炎 那就跟大家聊聊這部分 就大家辛苦了 連續兩週都是機器學習開講 那怕大家無聊 對 就跟大家先聊一下 那這個技術呢 其實就是來跟大家說 機器學習其實也是不斷的往前邁進嘛 那以前我們在做一些text mining 大家一定聽過text mining 就文字探看的部分 把一段文章 擷取出來之後 然後來看裡面有什麼有用的文字 然後來跟讀者
(21:35~22:36) 然後來節省肯讀者的時間說 這個文章的重點可能就在哪邊 那我們的分類技術 其實也是差不多的東西啦 那我們就是來讀取文章的資訊嘛 然後來跟讀者分類說 啊這篇文章 它可能是 一個正向的文章 還是一個比較負面的文章 那如果是正向的文章的話 就代表說 這個作者對他們公司的未來 是比較抱持著樂觀的態度 那他們可能公司明年長的機率 就會比較多這樣子 那我們就是用這個方式 然後來去得到說 他們對於公司的未來展望 那就是 那這個部分大概是八成 因為他們自己 大公司在預測的部分也是 大概八成都是蠻準的啦 ok 那雖然我們在講預測 但是還是要請大家注意到說 雖然我們研究圈 就是我們博士在做這些 研究的時候
(22:36~23:38) 都是抱持的樂觀 或者就是你剛剛聽到什麼 八成啊九成 八成啊七成這種數字 好像聽起來很高 但是應用在真實的投資的時候 其實 還是要請大家注意一下 大家可以去聽前面幾集的部分 我其實就有一次不斷的 跟大家講說 這些技術都是參考 那是還是希望 投資者就 你們自己要注意一下這些東西 他背後的原因到底是什麼 那我剛也講了我們剛剛預測 是怎麼預測出來的 我們就是使用他原本的財報嘛 然後來去看他背後的文字是什麼 那原始的話 人家會使用文字分析的技術 那我就是用圖片分類 那圖片分類如果大家還不清楚的話 可以在下面留言 我看這二包在開一集也沒有關係 好那大概就是這樣 以後我們也會在節目上 不斷跟大家分享這些 研究權或者是人家使用的一些 機器學習啊 或能工智慧
(23:38~24:02) 他們應用在金融科技上的一些 案例或者是他們的工具是什麼 那我們也盡量能夠 幫大家分析他們背後的原因 好那我們今天的分享就到這邊 謝謝大家這一次的收聽 哎 再講一次這樣都真的比較硬 就辛苦大家了 那也歡迎大家在我們的FB 或者是Podcast底下留言 然後五星分享 謝謝大家 ok 那我們下次見
