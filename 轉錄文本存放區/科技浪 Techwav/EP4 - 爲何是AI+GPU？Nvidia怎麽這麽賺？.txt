(00:00~01:00) 哈囉大家好 歡迎來到科技浪 我是主持人哈利 科技浪是一個白話給你聊科技的Podcast 希望可以用簡單易懂 但是又深入的方式 帶你了解時下最火的科技話題 好 那我現在在錄影的當下呢 其實是颱風侵襲台灣的時候 那目前呢 在我中部這邊 其實是沒有什麼太大的雨啊 然後就有一點點風這樣 是還好 希望各位在聽到這個Podcast的時候呢 也都是安全的 然後有如願的放到颱風架 然後可以在家裡看真人版的航海王 那我今天其實準備了超級多 超有料的內容 我覺得大家聽完這集一定會滿載而歸啊 但在講這些嚴肅的科技話題之前呢 我其實想跟大家先聊一個有趣的新聞 就是最近有個台灣的大學男生 在國外直接爆紅了 事情是這樣 我們要先從一個美國的直播主開始講起 這個美國直播主叫做Kai Sennett 他在美國是一個超爆紅的直播主 他的Twitch有6.7M 就是670萬的人在追蹤 然後他的YouTube呢 也有400多萬的訂閱 那像他這種巨型網紅呢 台灣的一般網紅是沒有辦法相比的嘛
(01:00~02:01) 就算是台灣最紅的阿滴 也就只有270幾萬的訂閱 然後這個Kai呢 他其實就是一個小屁孩 21歲 然後他在直播上就是 就是做一些蠢事啊 大吼大叫 然後摔椅子啊這樣 反正就是一個白痴搞笑型的直播主啊 然後這個Kai呢 他前一陣子跑到日本去直播 然後他就在日本的街道上走來走去啊 然後就是他有個攝影師跟著他一直拍 讓他直播這樣 然後他在一間日本的Semi-11前面 遇到了一個台灣的男生叫做Ray 那個叫做Ray的男生呢是 應該是一輔大的一個大學生啦 然後我看他那時候應該是剛好去日本玩 然後就在街上遇到了Kai 那這個Ray呢也是Kai的中式粉絲嘛 所以他就上去跟Kai要了一張合照 但他要合照的方式不是跟一般人一樣 他是比較 他是充滿了熱情的去要合照 因為我覺得他第一個他是 他應該是Kai的大粉絲啦 然後再來就是 他自己也是一個蠻 個性蠻鮮明的一個男生啊 所以他就走上去跟Kai說 還是什麼東西 然後就是 就跟他擁抱啊然後合照
(02:01~03:03) 然後Kai就是看到他這麼好放 他自己也是很開心嘛 因為我覺得 他可能也比較少在路上看到這種 跟他的調調這麼合的路人 所以他們就站在那邊一直聊天 然後大叫大笑啊 然後這個時候聊天室的反應都很好 就大家都很喜歡看到這兩個人在互動 然後Kai應該也是真的很喜歡Ray啦 所以他隔天就 邀請了Ray跟他一起去逛日本 然後他們就一起在街上這樣逛啊 然後一起直播 然後買東西啊去唱卡拉OK啊之類的 然後觀眾都超級買單喔 他們這一陣子這幾天在日本 拍的所有影片 在所有的social media加起來 總共有超過2億的觀看次數 然後在幾個禮拜前呢 這個Kai就把這個Ray飛到了美國去 跟他一起拍了一大堆影片 當然他這麼做可能他跟Ray之間 真的有友誼的產生啦 但是撇除友誼不看 他這麼做也是很有商業意義的 因為到現在這個Ray 已經基本上是流量保證了啦 因為在那個Ray飛到美國之前啊 他的TikTok帳號 已經有超過100萬的追蹤人數了 然後他的IG應該
(03:03~04:04) 我記得也有30幾萬了 你要知道在這之前 Ray就是一個完完全全的一個 台灣普通男大學生喔 就可能IG幾十個幾百個追蹤人數啊之類的 所以他完完全全是靠這個機遇 一夕爆紅 然後他飛到美國之後呢 就跟Kai直播了好幾次 然後拍了很多東西 還拍了一部影片 有一點類似電影的一部影片 然後過程中很多這些影片我都有看到啊 因為這個故事我從一開始就有在追了 我真的覺得很有趣 就是一個台灣的小男生就這樣爆紅 所以我就一直在看這些影片 然後影片中的那個Ray啊 他其實不太會講英文 所以他有時候聽不懂啊 然後就反應就蠻好笑的 但我覺得大部分的國外觀眾 好像覺得這個是他個性的一部分啊 還是怎樣的 覺得大家都很買單 他的流量超級好耶 Kai把他跟Ray的一些互動放到了YouTube 然後這部影片在六天之內 就已經有超過730萬個觀看了 這應該也是他表現最好的影片之一了 然後在這過程中呢 其實剛好有遇到第12屆的Streamy Awards頒獎 Streamy就有點像是
(04:04~05:05) 直播界的格萊美獎啊 艾美獎那種等級的獎項 然後Kai Snad正好是今年Streamy Awards的 Streamer of the Year 就是年度最佳直播主 然後他上台頒獎的時候 就帶著Ray一起上台 所以Ray就成為了第一個 站上Streamer Awards的台灣人 好那我剛剛看了一下 那個Ray的IG帳號呢 追蹤人數已經接近50萬了 現在是49萬8千 50萬是什麼概念 Jomang的追蹤人數就是52萬 他幾乎什麼文都沒有 才四篇文 然後他追蹤人數已經要接近Jomang了 然後他的TikTok 現在已經有180萬個追蹤人數了 而且最扯的你知道是什麼嗎 他在TikTok上這樣有追蹤我耶 我覺得他應該是 他還沒沉迷的時候追蹤我啊 他現在就是 他現在已經比我大咖太多了 而且他現在我才也沒有時間 可以看我的影片了 好那我覺得就是一個很有趣的故事啦 就是一個很普通的台灣男大學生 甚至不太會講英文 但是真的是因緣際會的 在路上遇到Kai 然後因此變成了一個國際巨星 那我同時也很好奇
(05:05~06:05) 這個故事接下來會怎麼展開啦 就是我覺得他現在一定在 每天都在苦苦的思考 他究竟要怎麼樣運用這些流量 究竟要怎麼把這些流量變現 讓他做出一番事業 我看他的影片他是有說 他想要當一個streamer 他也要當直播主 但是直播主 就是你還是要有方法 可以持續抓住觀眾的眼球 那你又是沒有經驗 然後就突然爆紅 那立刻要開始做 而且你的觀眾全部都是美國人 所以我覺得這個對Ray來說真的不好做 如果他有機會可以找到一個 國外的agency來簽他 然後幫他訂製內容啊 幫他一起做 那我覺得應該會好很多 好啦無論如何都祝福Ray可以長紅 然後我會繼續的關注你 那也希望你可以繼續看我的影片 好那我們接下來就進入科技話題吧 那首先我想先問大家一個問題 2023年如果你要挑一間最紅的科技公司 你會挑哪一間 我覺得是我的話 我會挑NVIDIA 回答 然後我覺得大部分人的回答 應該也都是這間公司 這間公司的股價從年初到現在 已經漲了三倍多了 然後上禮拜開彩炮的時候
(06:05~07:07) 他們的營收甚至打破了 最樂觀的分析師的預期 那在這個總經狀況不是很好 利率這麼高 尤其前一陣子那個科技業 才在剛低迷的時候 既然NVIDIA一間公司可以這樣一軍突起 它一定是騎到了某波浪 那這一波浪呢 當然就是深層是AI的浪 那這波浪潮當然也有燒到台灣嘛 就是前一陣子台灣也一堆人在炒那些AI股嘛 把一些穩定存股的標的全部都炒成了標股啊 但說真的 這些人真的知道他們在炒什麼嗎 就是我覺得有一些關鍵的問題啊 像是到底有哪幾種不同的AI AI的推論跟訓練的差別在哪裡 推論跟訓練分別要做什麼樣的計算 這些計算為什麼要用到GPU 只能用GPU嗎 要怎麼使用GPU 我覺得這些問題算是基本啊 但是你可能拿這些問題去問一些那些 在追AI股的投資人啊 他們可能都答不出來 那不要說投資人啊 一般大眾一定更疑惑 就是他們可能根本不知道NVIDIA到底是在做什麼東西 那這些東西到底跟AI有什麼關係 所以我今天想幫大家在這個AI運算的主題下 建立一個很完整的知識架構 就是我們從最底層的知識開始
(07:07~08:10) 先了解到底是什麼是GPU 然後GPU到底跟AI有什麼關係 再來了解為什麼現在NVIDIA是 唯一一間可以獨吃整個AI運算市場的公司 最後再來聊一下這個 NVIDIA這個誇張的報酬到底可不可以持續的賺下去 那我今天會講的盡量是讓任何人都聽得懂 儘管你對於AI跟GPU完全沒有概念的人也聽得懂 那你如果原本就很熟的人呢 你也可以聽聽看你有沒有什麼知識的漏洞 或是你也可以跳到後面 直接去聽我比較高層次的預測的或是分析的部分 好那我們就從最底層的問題開始來吧 NVIDIA這間公司是在做GPU的嘛 那到底什麼是GPU呢 GPU的英文叫做Graphic Processing Unit 所謂的processing unit就是處理器的意思 那graphic是圖像的意思 所以說合起來就變成圖像處理器 那這個GPU圖像處理器呢 它其實是一個比較特別的存在 那我們在講它之前 我們應該要先講一個比較一般的存在 也就是每一個每一台電腦都有的CPU中央處理器 那這個CPU呢就是你的電腦的大腦 你在使用這台電腦時做的所有的操作
(08:10~09:12) 你看到的所有的畫面都是需要被計算出來的 就是儘管你是移動一下你的滑鼠 然後你看你的鼠標從左邊移到右邊 這件事情也需要做計算 詳細一點來講呢 就是你電腦裡面所有的軟體 就從你的作業系統到你的Excel到你的瀏覽器 他們全部都是用程式語言寫出來的 就像是C++ C Sharp這種程式語言 那你在使用這些軟體的時候呢 電腦是在跑那個C++的程式 然後它在跑的過程中呢 第一步驟就是會先把這個C++的程式碼 先翻譯成機器看得懂的語言 叫做機器語言 機器語言呢基本上就是0跟1的語言 就是它會把這個程式碼呢 直接轉換成一大堆的0跟1 真正最準確的動詞其實是編譯啊 就是它把C++編譯成機器語言 然後這個0跟1的語言就會被丟給你的CPU 那這就是你CPU可以直接處理的指令 你的CPU裡面有很多很多的電晶體嘛 這個我在第一集有講過 那每個電晶體都可以代表0或者是1 然後它會用這十幾億個電晶體 來處理這些0跟1的指令 然後你電腦螢幕上看到的一切 就是他們處理出來的結果
(09:12~10:16) 那在最一開始呢一般的電腦只有CPU 然後確實只有CPU其實就夠了 因為CPU啊它什麼工作都可以做 從你要開啟你要使用你的Excel 你要瀏覽器你要上網你要看影片 CPU全都做得到 然後它在執行這些工作的時候 它是以一個叫做sequential processing的方式進行處理 中文叫做順序處理 就是它先處理完A再處理B 再處理C再處理D 那基本上一般的所有事情呢 就用這種sequential processing的處理方式 就已經可以處理完成了 但是在某一些非常計算密集的工作上 這種sequential processing就做不太到 比如說你要玩一個視覺很好的遊戲 然後它是一個第一人稱的槍戰遊戲 你的角色往左前方走一步 你畫面上所有東西都要動一下 然後有些東西還要轉一轉一轉一面 因為你的角度變了嘛 這時候你電腦要做的計算是 你要計算每一個物體 你遊戲中的每一個物體 它經過你這次的移動呢 它會轉變成什麼樣子 那你用GPU的sequential processing來處理這個事情呢 你就會變成是你只要角色移動 它就要先計算
(10:16~11:17) OK先計算你前面右前方的這個箱子 它會轉變成什麼樣 算好了之後再算 你旁邊的這棵樹它會轉變成什麼樣 然後算好了之後再算 這個光影會怎麼樣變 不不不不 很多很多的計算要算 然後它一個一個算的話 你遊戲體驗會很差 因為你根本就動不了 很明顯的用sequential processing 是解不太了這個問題的 你真正要有好的遊戲體驗 你必須要使用parallel processing 平行處理 意思就是說當你角色往左前方走一步的時候 平行處理是可以平行同時的處理 畫面上所有東西它會怎麼動 那麼NVIDIA的CEO老黃呢 在2000年初當時就是看到了這個遊戲的需求 然後他就為了這個需求呢 製作了全世界的第一張GPU 那這個GPU呢 專門就是為了遊戲畫面的平行處理而設計的 你從硬體的設計上 你就可以很明顯的看到這一點 首先一個處理器 不管是GPU還是CPU 下面都有多個核心 然後每個核心下面有1到2個所謂的執行序 這個執行序呢 才是處理工作的單位 你總共有幾個執行序 你就可以同時處理幾個工作
(11:17~12:19) 然後像一個典型的CPU 它可能有8個核心 然後每個核心下面會有1到2個執行序 我們算兩個好了 那也就是說8乘以2 它最多可以同時處理16個工作 那麼我們來看一下GPU 一個一般的遊戲的GPU 就是遊戲的顯卡 我們拿NVIDIA的RTX3070來舉例好了 RTX3070它有將近5800個核心 相對於CPU只有8個 然後每個核心它通常只有一個執行序 但是這樣總共加起來 也就代表它同時可以處理5800個工作 5800相對於16 是不是平行運算的能力就差很多 那這個5800跟16 當然是不能直接相比的嘛 對吧 CPU的一個執行序 它可以處理的是一個APP 或者是一個瀏覽器 那那個GPU上面的5000多個核心 不可能每一個都有能力處理一個APP 他們有能力做的 也是特別他們特別擅長做的 是某一些特定的數學計算 這些數學計算 如果是在一張遊戲顯卡上 當然就是這個遊戲畫面的運算 那這些所有運算當中
(12:19~13:20) 最常用的一個是叫做矩陣運算 不知道大家還記不記得矩陣是什麼 這個是我們高中數學學過的東西嘛 就是你如果還記得的話 就是有一個章節 我們都在講一個中括號括起來 然後中括號當中 會有排列很整齊的N行的數字 那這個中括號框起來的東西呢 就叫做一個矩陣 那這個矩陣本身是一個 沒有實質意義的一個數學物件 但是當你在計算一個遊戲畫面的時候 其實很多很多的東西 你都可以用矩陣來代表 這邊接下去就太數學太複雜了 大家可以自己去查查看 反正重點就是 你在運算遊戲畫面的時候 你要做大量的矩陣運算 就是把這個矩陣乘上另外一個矩陣 或是拿這個向量來乘上這個矩陣 所以這邊如果做個小節的話 就是GPU之所以會比CPU 更適合處理遊戲的計算 是因為它可以同時做大量的矩陣運算 然後CPU不行 那我這邊來問你一個小問題好了 你知道除了遊戲以外 還有什麼樣的工作要進行 大量的矩陣運算嗎 沒錯就是你那個 今年聽到已經快煩死的東西 AI
(13:20~14:21) 那AI是在做什麼矩陣運算呢 首先我們要先定義一下 我們這邊講的AI是什麼 因為AI這個詞說真的 真的是非常的廣 然後現在什麼東西都可以是AI 就是我前幾天在逛加勒福的時候 我看到有一個按摩椅 它竟然是AI按摩椅 那我是不知道它的AI在哪裡 不知道是不是你在按摩的時候 它會有那個CHAT GPT在你的耳邊 跟你悄悄話之類的 好啦我是開玩笑的 但是真的啦 現在什麼東西都可以冠上AI這兩個字 然後說真的也不能說他們錯 因為AI真的是定義太廣了 就是任何可以模仿 就算是極少量人類智慧的機器 你都可以把它稱作AI 好啦不管了 反正我們這邊要討論的AI 是Machine Learning的AI 就是它是用機器學習的方法訓練出來的AI 這我看那個按摩椅就會被排除了吧 那你在使用這些機器學習的AI的時候 它其實都在進行矩陣運算 這個概念呢 如果你有買我的電子書 你就會很熟 就是我的電子書就是從簡單的數學 了解機器學習嘛 那這個就是我其中一個要傳達給觀眾的 很重要的一個概念 那你沒買的話也沒關係
(14:21~15:22) 我這邊就大概講一下 那反正這些AI呢 它所有的智慧 它的知識 它對於這個世界的了解 它可以做到的事情 全部都是以一個叫做權重的形式在儲存 權重的英文叫做waits 它其實就是很多很多的浮點數 浮點數就是那種有小數點的數字 比如說0.15啊 1.1啊之類的 然後你在使用這個AI模型的時候啊 它會先把你輸入的資料 不管你是輸入打入一串字啊 還是一張圖片啊 還是你的會員資料啊 它都會把它變成一個一個的像量 那像量其實就是跟矩陣有點像的東西啊 但是它不像是矩陣有很多行 它只有一行 然後是用中括號括起來的數字這樣 然後它會把那個權重啊 也變成一個一個的矩陣 然後拿這些像量 乘上這些矩陣 然後一個像量乘上一個矩陣 乘出來也是一個像量嘛 然後你把這個新的像量呢 做一些數學的處理 然後再乘上一個新的矩陣 然後再做一些數學的處理 然後再乘上一個新的矩陣 然後是一直這樣這樣用乘乘乘乘乘乘乘 最後吐出來的那個像量 就是這個模型吐出來的答案
(15:22~16:23) 當然這個是有一點點過度簡化的解釋啊 但基本的概念就是這樣子 那我們知道記憶學習其實也有分兩種 一種是比較典型的記憶學習 就是可能比較偏統計模型的記憶學習 然後另外一種呢 是比較偏深度學習的記憶學習 兩者的最大差別就是深度學習 用的是神經網路的架構 那這兩種記憶學習的模型呢 其實都會用到這種矩陣乘法 但是典型的記憶學習模型 做的矩陣乘法很少 深度學習要做的矩陣乘法是超級超級多的 那這邊有一個我覺得蠻有趣的故事 可以跟大家講一下 就是記憶學習領域裡面有一個比賽叫做 ImageNet 這個ImageNet它其實就是一個很大很龐大的一個電腦視覺資料庫 意思就是說它裡面有超級超級多種不同的物件的圖片 就是比如說它有一顆草莓的圖片啊 它有一個施工的人的圖片啊等等 然後很多這些圖片下面都有標示 比如說草莓圖片下面就有標示說這是一個草莓 然後每一種圖片也都有很多張哦 就比如說它可能會有很多很多張草莓
(16:23~17:25) 然後都看起來不太一樣的草莓 但都是草莓 然後也有很多很多很多張那種施工人的圖片 然後都不太一樣 那這個資料庫呢總共有超過1400多萬張圖片 然後這個ImageNet的比賽呢 當然就是在比賽說誰可以訓練 誰可以拿這個ImageNet的資料集來訓練一個機器學習模型 是可以最好的辨識物件的 就比如說我給你一張水壺的照片 你要能夠吐出水壺這兩個字 然後這個比賽呢是從2010年開始舉辦 然後每年舉辦一次 然後在2012年的時候呢 就是這個比賽辦了兩屆之後 有一個團隊在這個比賽裡面創造了歷史 這團隊呢主要是兩個人 一個是Alex一個是Ilya 他們做了一個AI模型叫做AlexNet 那最後比賽結果出爐的時候 大家看到直接嚇一跳 這個AlexNet拿到了第一名 然後第二名的成績就是他的錯誤率是26% 然後這個AlexNet只有16% 比第二名還低了10% 這是一個前所未見的超級好成績 那他們之所以可以這樣屌打競爭對手
(17:25~18:27) 主要是因為他們訓練的AI模型是一個神經網路 然後這個神經網路是很大很深的 它總共有6200萬個參數 當然6200萬在現在的規模來看就沒有很大 那時候已經非常大 然後其他競爭者呢都沒有像他們做的這麼大 因為那個時候訓練機器學習的主流 是拿CPU在做訓練 那個時候的GPU單純的就是玩遊戲的而已 所以說其他人覺得有這個運算的限制 都不會把自己的模型建得太大太深 但是這個AlexNet的團隊呢 他們是拿GPU在做訓練 他們是拿兩張NVIDIA的GPU訓練出了這個模型 當然他們不是第一個拿GPU在計算AI的人 但這次的比賽是第一次讓世人看到深度學習的可能性 以及GPU可以如何加速深度學習 然後在那件事情之後呢 有些人就說開啟了這個深度學習的文藝復興 就是越來越多人開始研究深度學習 研究這些神經網路 然後把神經網路建得越來越多層越來越大 當然同時呢就是硬體的部分也一直在成長
(18:27~19:29) 就是那時候他拿來訓練AlexNet的GPU 是兩張3GB VRAM的GPU 現在隨便一張A100就已經40GB了 雖然說A100是企業等級的GPU 然後模型也大很多 就是那時候AlexNet6200萬超大 但現在隨便一個模型就好幾億個參數了 那這個ImageNet團隊裡面的那個Iliya呢 她的全名叫做Iliya Sutskova 講到這裡可能有一些人就是 有在研究機器學習的可能就聽到 喔原來是她喔 因為她現在是真的是很有名 她是OpenAI的Cofounder跟Chief Scientist 好那那個2012年AlexNet得獎的時候呢 其實有一個人在背景虎視眈眈的看著AlexNet 這個人就是NVIDIA的CEO老黃 老黃就說從那個時候開始 他就發現就是GPU在AI的應用真的是很大 你如果要訓練一個最強的神經網路模型 你一定要用到GPU 然後神經網路這個東西這麼強 未來一定會紅 所以他就從那個時候開始持續加大他在AI的佈局 我們來盤點一下他這十年來的戰績 我覺得主要分成三個部分
(19:29~20:29) 第一個部分是他持續加重投資Cuda Cuda英文是C-U-D-A-Cuda Cuda就是讓NVIDIA GPU可以進行編程 就是大家可以寫code 讓GPU可以處理遊戲以外的工作 其中當然就是包括了AI 就是儘管你買了這張NVIDIA顯卡呢 它是一張遊戲的顯卡 你還是可以去他們的官網下載一個軟體叫做Cuda 然後你就可以寫一些Cuda的code 讓你的機器讓你的顯卡也可以跑AI的程式 那這個Cuda code 那當然就是應該是蠻難的一個code吧 反正我自己是沒寫過啦 我連看都沒有看過 因為現在那個PyTorch都幫你處理的好好的嘛 那儘管那個時候很多投資人在反對NVIDIA投資Cuda這件事情 老黃仍然是加重投資Cuda 因為他相信AI的未來一定會很美好 而且他確實賭對了 好那以上是Cuda的部分 那第二個部分呢是硬體的部分 就是老黃有針對AI推出一系列特別的GPU 首先是在2017年到2018年之間呢 他推出了一個Tesla系列的GPU 有Tesla P100、V100跟T4
(20:29~21:30) 那你如果是一個GPU貧窮戶呢 像我你可能就有用過Google的一個線上ID 雲端ID叫做Google Collab 然後Google Collab的免費版呢 你使用的時候你如果要用到GPU的話 它會給你的就是一個Tesla T4的GPU 那這個Tesla T4的GPU它其實已經蠻強的嘛 而且它是主要為AI設計的 但是在2020年的時候 老黃又推出了新的一款GPU叫做A100 那這個A100呢今年大家應該都蠻熟悉的嘛 因為這基本上現在所有想做AI的公司 都在瘋強的資源 那個時候OpenAI在train那個Chat GPT 他們就是用A100的GPU在train的 然後這個A100的短缺呢 連我都切身感受到啊 因為我是有在用Google Collab嘛 我剛剛有說過 然後在這個這波生成式AI爆發之前呢 就是在今年以前 你只要有每個月花300塊買Google Collab Pro 它就有很高的機率會給你A100的GPU 它幾乎就絕對會給你 就是你只要選擇那個A100GPU它就會給你 但是在今年啊 我有買Google Collab Pro一個月300塊
(21:30~22:31) 但有時候我選了A100GPU 我根本就排不到 我通應該不是應該說我通常我都排不到 我可能一個早上都排不到 然後我就變成我是付費用戶 但是我被迫要用跟免費用戶一樣的GPU 有時候真的是很不爽 但沒辦法嘛 現在這個A100就是極度短缺的資源啊 就只能這樣吧 然後在2022年的時候呢 老黃又推出了A100的進化版叫做H100 這個當然也是現在非常短缺的資源 然後再來就是今年啊 他又宣布了老黃又宣布了 他要把一個原本拿來處理圖像的GPU叫做L40 拿來改成處理大型語言模型的 然後把它稱作L40S 所以你可以看到老黃這十年的佈局真的厲害啊 在軟體硬體方面都加重投資AI 然後在硬體的部分其實還不只這樣哦 就是我一開始說他在加重投資AI的部分有三個嘛 第三個部分呢 是為企業推出的DGX系統 那我剛剛說的那些GPU啊 不管是A100 H100還是Tesla系列 他們都是單張的GPU 然後一間公司可能會買一個伺服器的價值 可能八個空格
(22:31~23:33) 然後買八張這些GPU然後插進去這樣 但這些DGX系統啊 是NVIDIA自己幫你調好的一個超級電腦 就是他會把很多GPU直接合在一起 然後用最先進的硬體 最適合的硬體跟最適合的軟體把他們合在一起 他們有推出DGX A100 DGX H100系列 然後還有今年最出名的DGX Grace Hopper 200 我那時候第一次看到他在那個台北國際電腦展 展示這個DGX Grace Hopper 200的時候 我整個下巴都掉下來 我還PO一個限動說 我覺得這個東西應該會毀滅人類 這個DGX Grace Hopper 200有144TB的GPU RAM 然後他的算力有一個XFLOP 一個XFLOP的概念是什麼呢 假設你每一秒做一個運算 就是你每一秒都會算一個 比如說2乘以2.1之類的 或是3乘以5這樣的運算 你每秒算一次 然後你總共要算316億年 你才比得上這台電腦算一秒 然後其實人類一秒做一次計算 我覺得其實差不多
(23:33~24:35) 所以說這台電腦算一秒 人類要算316億年 反正就是一台救急怪物 好那你可能會問說 那為什麼NVIDIA還要特別推出這種 幫人家組好的一個Cluster呢 一般公司不是自己去架一個伺服器 然後自己插那個顯卡進去 也可以做到這件事嗎 其實假設今天你有一台伺服器 你自己架的8張 你插8張顯卡進去 跟一台NVIDIA的DGX 假設這兩個系統有同樣的VRAM 就是有同樣的GPU記憶體的話 這時候就代表他們可以跑 同樣等級的AI模型對不對 因為我們知道我們在跑AI模型的時候 我們要把AI模型存在VRAM當中 然後既然他們的VRAM是一樣大的 他們可以存一樣大的AI模型進去 但儘管他們跑的模型是一樣的 我覺得DGX的系統 跑的會比一般的伺服器還更快 這是因為你在跑AI模型的時候 它的速度的最大的bottleneck 速度的最大的瓶頸是寬瓶 這邊的寬瓶不只有VRAM to GPU的寬瓶 還有GPU to GPU的寬瓶
(24:35~25:36) 也就是說你把資料從VRAM送到GPU的速度 以及GPU跟GPU互相之間傳輸資料的速度 會很大程度影響你跑AI模型的速度 因為很多時候你在跑的時候 你其實是在等那個資料來 而不是你在等你算好 所以這個DGX的系統 他們自己建立起一個系統 他們在寬瓶的部分就可以做很多的優化 好那我們這邊做小節 反正老黃在這十年一直以來在布局AI 不僅投資了CUDA的軟體系統 還投資了單片的GPU 也投資了企業端要用的DGX 然後這些投資在2023年 生成是AI爆紅的時候 全部都得到了最大的回報 因為你現在放眼望去 真的沒有任何一間公司 它AI加速器做得跟NVIDIA一樣好 NVIDIA GPU它一直以來最大的競爭者是誰 其實就只有一個人 就是一間叫做AMD的公司 那這個AMD的公司有在做顯卡 但是它跟NVIDIA比起來 它比較斜槓一點 就是它也有在做CPU 所以它在GPU這邊 近十年來它就沒有在做這種 NVIDIA這種程度的AI的布局 它就是比較是在做這種
(25:36~26:36) General Purpose的GPU 就是一般普通的GPU這樣 所以說基本上在2023年 這個生成是AI的運算需求 基本上全部都是被NVIDIA吃下來 可能90%以上 所以他們今年真的是 財報一季開得比一季高 真的是賺飽飽 他們的毛利率已經跟那種軟體公司差不多了 那這邊就迎來了一個很重要的問題 就是NVIDIA獨霸市場這件事情 究竟會不會持續下去 究竟會持續到什麼時候 當然我不是投資節目 所以我這邊不會給大家一個 我很明確的projection 就不是很明確的給你一個數字說 某一年之前 它就會被其他的競爭者趕上 什麼有的沒的 我會給大家的是一個 我思考這件事情的架構 然後我覺得有哪些重要的面向要考慮 以及一個我從一個比較技術的角度出發 提供一些觀點這樣 好那首先 你如果從一個經濟學的角度思考 你就會知道 當然NVIDIA獨霸市場這個情況 不可能一直持續下去的 這邊我覺得很重要兩點是 第一點 從經濟學裡面我們知道 一間公司在賺超額報酬的時候
(26:36~27:37) 一定會有其他公司來分這個報酬 第二點 NVIDIA並沒有一個超級強的互成盒 就是其他人如果要推出競品的話 他們是做得到的 這是因為NVIDIA這間公司 它其實是一間fabulous的公司 那在半導體業 他們會把那種在製作半導體的公司 在加工的這些公司稱作fab或是foundry 那像是台積電就是一個fab 所以一間fabulous的公司 就代表它沒有fab 什麼東西less就是沒有那個東西 所以fabulous就是沒有fab 也就代表它沒有製造晶片的能力 所以我們剛剛講到很多那些什麼 A100 H100那些NVIDIA的GPU NVIDIA都是它自己設計這些GPU 然後把這些設計丟給台積電 叫台積電幫它製造 所以說今天其他任何一間公司 可不可以自己也設計一個GPU 然後丟給台積電 然後讓台積電做 可以啊 然後它做出來會不會比NVIDIA好 有可能啊 只要你設計的比較好 然後台積電也做得到 當然就可以啊 所以遲早NVIDIA這個超額報酬 就是它在狂賺的這一波錢 一定會被其他人進來瓜分掉的
(27:37~28:37) 那些其他人是誰呢 欸基本上是所有人 首先第一個最直接的當然就是AMD 就是原本的GPU二巨頭之一 他們有沒有做自己的AI智能影片 有啊他們有一個系列叫做MI300 MI300的系列 這個系列他們好像一兩個月前才剛公布吧 然後現在都沒有什麼市場 都沒有什麼聲音啊 但他們是有在做AI晶片的 再來一大堆科技巨頭都有在做自己的晶片 Microsoft有沒有在做 有 他有在做自己的AI晶片 Amazon Yamahsune有沒有在做 有 他們有專門做跑生成式AI的晶片 然後要放在AWS 就是他們的雲端服務裡面 臉書有沒有自己的AI晶片 有 他們好像是三個月前還是兩個月前公布的吧 他們做了第一個自己的AI晶片 雖然說那個AI晶片主要是拿來跑推薦系統的 但他們未來會不會做給生成式AI的 也可能啊 蘋果有沒有自己的AI晶片 有啊 Apple Silicon超級有名啊 雖然說我們拿蘋果的晶片來 跟這些其他晶片比是不對的 因為蘋果是在邊緣裝置上跑 它是在你的筆電啊
(28:37~29:38) 你的手機上跑的晶片 然後我們其他在講的這些晶片 是在資料中心跑的 所以說蘋果的這些Apple Silicon 可不可以瓜分到這個NVIDIA的利潤 我覺得應該 可能應該不會吧 但我這邊必須要說 就是蘋果的chip 像是M1、M2 在現在機器學習的業內是很有名的 很多人在拿這些M1、M2在跑模型的哦 所以說有沒有可能未來 瓜分掉一些可能推論相關的運算 嗯 我也不知道 有可能哦 好 你不要以為到蘋果就結束囉 競爭者的list還有 而且有個大魔王 我還沒講 就是Google 其實這十年來啊 布局AI運算硬體的公司呢 除了NVIDIA以外 就是Google了 Google也布局非常多 其實早在2016年啊 Google就宣布了他們 製作了他們第一個 專門處理AI運算的AI處理器 叫做TPU Tensor Processing Unit 那你平時有在做機器學習的 你可能就對於Tensor這個字很熟悉嘛 因為Tensor基本上就是 就是一個很高維度的矩陣嘛 然後我們在跑機器學習模型的時候 我們在做那些矩陣懲罰什麼矩陣運算
(29:38~30:41) 我們就是在用Tensor在做哦 所以從名字你就可以很明顯看到 這個處理器就是專門在處理AI運算 然後在2016年之後呢 它一直在持續更新這個GPU 它現在已經有TPU V1、V2、V3 一直到V5了 說真的其實它們最新版的這個TPU呢 其實跟NVIDIA的H100比起來也是弱啊 但是它們至少已經證明了 它們在這個硬體的開發是很有實力的 甚至上禮拜呢 在AI圈子裡面有流傳這一篇文章是在說 Google會靠著它的這個TPU 訓練出它們一個超級無敵強的模型 叫做Gemini 然後那個Gemini會是GPU的五倍大 然後會吞噬全世界 任何其他沒有足夠GPU access的公司 都會被拋在後頭 當然也包括開源社群 我發現我剛剛前面講錯話 就是我說Gemini會是GPU的五倍大 這句話不make sense 我要講的其實是Gemini是GPT-4的五倍大 當然這篇文章我並不是完全同意 因為這篇文章是有一間叫做 Semai Analysis的公司寫出來的
(30:41~31:42) 這個Semai Analysis就是專門在研究半導體的一個顧問公司 所以裡面的分析師都有很多很強的這個硬體的背景 但我覺得他們在軟體這邊就沒有很了解 所以說他們就是 他們在講的基本上就是 你硬體強你就贏 你最終就贏 你就是這樣 就是沒有其他餘地 我覺得他這樣是有點太小看開源社群在軟體這邊的創新 但是不管那些 反正他在寫這篇文章的時候 他是有用很多他在半導體的supply chain這邊的關係 打聽到了很多Google這個訓練設施的一些數據 然後他覺得這些訓練設施 尤其是Google的這些TPU是非常可觀的訓練設施 而且文章裡面還有說到 就是Google有可能未來真的會把這個TPU拿來賣 不管是賣雲端的服務 就是雲端幫別人做計算 還是直接賣這個GPU給別人都有可能 所以我覺得Google真的有可能是NVIDIA的一大威脅 那我們剛剛講到這些其實都是在攻擊端 就是看有誰會想搶NVIDIA的飯碗 但是在需求端其實也是會影響到NVIDIA的利潤的
(31:42~32:45) 首先第一個就是很可能需求端目前的狀況是多買的狀況 意思就是說 你看市面上任何的公司 不管是新創公司還是大公司都一直在搶GPU 那他們真的每一塊這些GPU都用得到 而且每一塊都可以產生很大的經濟價值嗎 其實不一定 你真的要等到這個應用端穩定了 應用真的出現了 然後那個價值真的決定了 你才可以真的很確定的知道 你究竟要用到多少張GPU 所以現在很可能的是一大堆公司都多買了 然後未來很有可能這邊多買的需求會平衡下來 然後這邊需求就會下降一點 然後另外一個導致需求下降的一個很大的因素呢 就是軟體的增強 我覺得這邊是絕大部分分析師都會忽略的部分 因為分析師看的都是比較看那種supply chain 這是供應鏈 然後看真的是tangible的東西 就是硬體啊 看得到的東西啊 那軟體這邊的發展 你真的要了解 你就只能去看最新的論文嘛 但我覺得軟體這邊一樣是可以很大幅的影響需求的 比如說我在我的頻道常常講的今年兩大趨勢嘛 第一個是quantization
(32:45~33:45) 就是大家會把模型壓縮到很小 小到在一台電競筆電上都可以跑大型影院模型 第二個趨勢是Lora Lora是一種降低微調資源的微調方式 那我上一集有講到嘛 就是微調模型呢 就是你把一個模型做客製化的這個過程嘛 然後在過程中 你要拿你自己的資料去訓練這個模型 但是這個模型很大 你沒有辦法訓練的時候怎麼辦 你就訓練一個小小的東西叫做Lora 它的全名叫做Low-Rank Adaptation 它是一個這個有點太難了 但反正就是一個小的矩陣 然後那個矩陣被訓練完了之後呢 它就可以把這個它訓練的結果 再加回去到那個大的模型當中 讓模型也知道這些知識這樣 反正軟體這邊的方向很確定啦 就是有一批人 一定會有一批人一直在研究 如何更有效率更有效率的跑這些模型 我前幾天甚至還看到有一篇paper在講 2-bit quantization 就是它把那個模型壓到2-bit 意思就是說每一個模型的參數 我們不是說這些模型有幾百億個參數嗎
(33:45~34:46) 每一個參數它用兩個bit來代表 兩個bit就是一個0跟一個1 或者是一個1跟一個0這樣 但我覺得那個效果應該沒有很好 不然那篇paper怎麼沒有紅 反正軟體的革新也是會吃到NVIDIA的午餐的 好那以上的硬知識呢 大家就好好消化一下吧 我們接下來進入QA時間 好那我第三集呢 其實是比第一集第二集都紅蠻多的 所以說我聽眾也變多了 那這次的留言也變得比較多 所以這次我不能像前面兩集一樣 幾乎是每一則都可以念到 那我就挑幾則來念 首先Evelyn說 很優質的節目 很喜歡你的聲音 聽得出來對在座的事情充滿熱情 可以請問平常有哪些吸收新知的管道嗎 我平時有固定在座的就是 我每天早上起來會聽Watch3 Journal的podcast 這我在上一集有講到 就主要是聽兩檔 一檔是叫做What's News 那它那一檔就是在講一般的商業新聞 政治啊 比較偏商業啦 然後另外一檔是Tech News Briefing 那一檔主要是在講科技業的新聞這樣 然後除了Watch3 Journal以外
(34:46~35:48) 我還會看推特 現在叫做X 就是滑一下X上面有什麼東西這樣 然後其他基本上就是 有時候看YouTube會偶爾看到一些知識的頻道影片 那我就沒有特定在看誰 但就是它有時候演算法推薦給我 我覺得有興趣我就會看一下 這邊推薦一下就是 你如果對這些半導體啊 晶片產業有興趣啦 你可以去看CNBC在去年做了一系列的YouTube報導 他們有很深入的剖析 Intel、AMD、NVIDIA、TSMC這每一間公司 我覺得超棒 你打CNBC然後再加一個 隨便一個關節字比如說NVIDIA之類的 你就會看到很多那一系列的報導 超棒的 再來H.J. Popo 他說 一起來衝浪 真的很佩服哈利裸詞的勇氣和堅持 我也希望在科技時代衝著浪而不是被淹沒 當初哈利一出電子書 我就買了 對於數學恐懼的我來說真的受益良多 現在持續利用下班時間學習 並看哈利的IG和聽Podcast 你對科技的熱情真的會讓人有共鳴
(35:48~36:51) 每當累的時候就來看看我們的留言吧 真的謝謝你的優質好節目 哇太暖了吧 看到這種留言真的會很開心耶 謝謝H.J. Popo 而且你那時候我一出電子書你就買了 那個那你是蠻OG的粉絲耶 那個時候大概我才2萬粉還是多少吧 對謝謝你喔 再來高雄陳同學 他說這讓我有學習的動力 認為你的短影有兩個效益 一促使收看到的人想要學習 或者是更了解AI世界 二嚇唬人對未來更害怕 開個玩笑 我現在就讀本科字管系 今天聽到分析師可能不只要會Excel也要會Python 就有點怕怕的 但聽完Podcast確實想試試看了 想問問哈利 如果未來想從事資料分析師的目標前進 現在在大學應該去學好所有基礎能力 還是應該去多花時間 感現在流行的AI 和直接學習類似SQL資料的程式語言 肯定是五星的 好謝謝陳同學 好那我首先我必須跟你說 就是你剛剛講的這些所有東西 就是Excel、Python、AI、SQL 這些全部都是工具
(36:51~37:52) 你學會了這些工具就代表你學會資料分析了嗎 絕對不是 更重要的是資料分析的思維 就是包括了商業思維 你怎麼樣定義問題 你怎麼樣解決問題 還有商業洞察的能力 就是你怎麼從數據中看出商業的洞察 怎麼把這個數據解讀成有價值的資訊 並用有價值資訊做決策 就有點像是你在學畫畫的時候 你的工具就是畫筆 那你在學畫畫的時候 你是會把大多數的時間放在學習有哪幾種畫筆 然後每一種畫筆要怎麼用怎麼畫 還是你應該把大多數的時間放在 到底怎麼畫一張臉怎麼畫一個人 當然是你應該把時間放在後者 你才可以真正把畫畫這個技能學好對吧 但是那個陳同學你不要覺得傷心哦 就是這件事情其實是 我覺得是普遍人的錯誤認知 大多數人都有你這種錯誤認知 甚至是就是已經在從業的人 可能也有這種錯誤的認知 所以第一個給你的建議就是 記得要去多多培養你的資料分析的思維 那我覺得工具的部分 你其實真的不用擔心啊 這東西真的沒那麼難啊
(37:52~38:56) Python已經是最簡單的程式語言了 相信我你只要去找一個專案來做 你真正有要用到Python的時候 你再去學你會發現你學的超級快 SQL也是一樣 就是這些東西你沒有必要 一開始就花很多時間在學 然後學了放著這樣 不用你就大概知道這些東西是什麼 他可以做到什麼事情 然後之後再做專案的時候 要用到什麼再學那個東西就好了 然後最後你有講到AI嘛 就是AI工具你要不要碰 我覺得絕對要你一定要碰AI工具 因為這些AI工具 其實是未來大家使用這些所有工具的介面 就是未來這些所有工具 不管是Excel、Python、SQL什麼的 它都會有一層LLM的layer 然後我們大家是跟那層LLM在做互動 而不是直接使用這個工具了 這個就是未來 所以說對你一定要熟悉AI工具 不管任何人任何產業 不管是不是資料分析 你都要會用AI工具 然後都要學習 好那最後呢 真的是非常謝謝大家的支持 就是我們這個科技量的Podcast 其實在上禮拜有幸的進入了 這個Podcast的Apple Podcast綜合排行的前三名 但是呢我們現在又掉下去了
(38:56~39:43) 所以說真的是請大家多多留言多多評分 你就算只留一個字讚也可以 你就給我一個五星 然後留一個字讚就沒問題了 然後你喜歡的話 也可以跟你的好朋友們分享我這個Podcast 現在我想一定還是很多人不知道科技量這個Podcast 好東西就是要跟好朋友分享嘛對不對 除此之外呢 你如果對我的內容有任何建設性的意見 我也希望可以在留言區看到 就是不管是你覺得我講話的方式 有什麼地方可以調整 還是我的內容有哪些你不想聽到 哪些你覺得太難 哪些你覺得太簡單 還是哪些想聽到的我沒講到的 都可以留言給我知道好不好 畢竟我們現在才第四集 然後我希望每一集我們都有很多我可以進步的地方 所以說我每一集這個進步的迭代速度會非常快 這樣我才能夠在半年一年之內呢 趕上那些Top tier的Podcast對不對 好啦最後真的是謝謝大家收聽了 那我們就下禮拜再見囉
