(00:00~01:01) 【音樂】 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式 帶你了解時下最火的科技話題 本集節目由哈利本人贊助播出 對,就是沒有贊助上的意思啦 那說真的呢,我其實這禮拜有點想休假 就是不太想錄 因為說真的,我從開錄到現在,我每一週都有錄 中間有經過幾次連假,但我都沒有放假 我每一週都有錄 然後我就想說,不然這週又沒有贊助商 還是我來休息一週好了 那同時我這邊也有很多其他自媒體的事情要處理 所以說我想說這樣應該不錯 但是呢,我打開我的notion看一看,然後發現 哇天啊,我要講的主題已經堆得跟山一樣高了 我這集在休息,我很多主題可能到我真正開講的時候都已經過時了 所以說我想說,不行,那我還是要來講一下
(01:01~02:02) 那我們這集呢,一樣又要回來講AI的話題了 上禮拜是有一點差出去講這個半導體 所以說是差出去,也不太算是太出去啦 因為上禮拜講的是晶片禁令嘛 那晶片禁令主要在禁的也是AI晶片 所以你可以說這個科技浪此時此刻已經變成AI浪 對,沒錯,就是我們幾乎每一集都會講到AI相關的話題 那今天這個話題呢,應該是完全100%都是跟AI相關的 今天主要要講的話題是一個叫做state of AI的一個report 這個report算是一個蠻重要的report 而且我覺得算是寫得蠻好的一個report 它裡面總結了2023年整年的所有重要AI發展 那我們今天又是在這個所有的重要發展中呢 挑出幾個特別特別重要的發展 畢竟我們也就只有可能一小時左右的時間 我們也不可能講太多 但在我開講這個state of AI report是何方神聖 它究竟有什麼樣的內容之前 我想先跟大家聊一聊我最近PO出的一支影片 那如果你不知道的話
(02:02~03:02) 我平時有在經營一個IG的自媒體頻道叫做哈利說 這個哈利說的頻道呢 從我年初開頻道到現在 也已經經營到有一定的規模了 現在有18萬粉絲了 那我這個頻道PO的內容呢全部都是短影音 我就是用一分鐘左右的時間跟大家介紹一個 很重要、很容易吸收、很好take away的一個AI觀念 或者是一個AI工具 然後同時也會講一些AI新聞之類的 所以說如果你是podcast的聽眾 然後沒有看過我的IG的話 你可以去看一下 但這也不是我想要講的重點 重點是我上禮拜PO了一支影片是在講這個 有一個AI工具叫做Hagen 它可以把一個影片中講某一個語言的人 翻譯成講另外一個語言 而它的翻譯不是一般的翻譯喔 是完美的翻譯 意思就是說那個講影片 假設這個影片中的人是講中文 然後你把這個影片翻成西文 影片的人就會開始講西文 他講西文的聲音跟他講中文的聲音是一模一樣 聽出來是同一個人的聲音 同時影片中的嘴形
(03:02~04:02) 他講話的嘴形也會變成發那些西文的音的嘴形 然後他講出來的話 想當然一定是西文 然後他做的品質已經高到一個程度就是 你如果不認識這個人的話 你可能還真的會覺得他是中文跟西文雙通、雙語者 乍看之下是這樣 就是你如果看久了 然後很仔細的看 你會發現他嘴形就是會把下巴變得有點怪怪的 但這個是我們人類史上最強的影片翻譯工具嘛 在這之前最強的人類技術 就是找一個真正會這個外語的 比如說會西文的母語者 然後來進行配音 但是這樣配出來很明顯的嘛 你的西文是make sense的 然後聽起來也很自然 但是就是跟畫面中的人的嘴巴對不上啊 那這個Hagen的工具呢 不但可以做到很自然的語言 然後很自然的語氣 然後是你的聲音 還可以把嘴巴對上 真的就是完美的翻譯了 那這個Hagen的功能呢 其實也不是免費的啦 它有免費的嘗試 就是你可以放一個將近 你可以放一個一分鐘的影片讓它翻譯 然後是免費的
(04:02~05:03) 但基本上你沒有辦法這麼做 因為你把這個影片放上去之後上傳之後 它並不會直接幫你處理你的影片 而是會把你的影片排進他們的整個隊伍裡面 就是他們有一大堆人在排隊等這個翻譯的功能嘛 然後你會被排在最後面 那前面有幾個人呢 有二十幾萬人 所以你如果用免費版 你基本上是不太可能使用到 有可能你影片上傳 然後我真的不知道多久 我沒有用過 可能過一個月還是之類的吧 你才可以收到你的結果 所以說我那時候是直接付費啦 然後一次付費就要付一千塊 我真的覺得有點貴 所以我那時候還考慮了一下 就想說 哇一千塊 我要不要拍這支影片 萬一我花了一千塊 然後這支影片一點都不紅 我不是虧死了 結果沒想到這支影片爆紅了 所以我這個一千塊真的花得太划算了 截至目前我錄音的此時此刻 這個影片已經有七十一萬的觀看了 有三萬多個讚 然後還被分享超過一萬兩千次 然後我當然也因為這個影片長了不少粉 所以說非常感謝黑正 但大家不要會錯意
(05:03~06:03) 我不是要跟大家炫耀說 我這支影片多紅多紅 然後我長了多少粉 這些不是重點 重點是這部影片為什麼紅 因為我覺得它會紅 並不是單純是因為這個技術很猛而已 而是因為這個技術帶出了一些額外的討論 那我影片中呢 我自己有給出我對於這個工具的兩個看法 兩個很快速的觀點 當然你想我可能在三四十分 三四十秒內我要講出這些觀點 所以我不可能解釋得很詳細 但我主要就是講了兩件事 第一件事就是這個工具會大幅的改變 整個創作者的生態系 因為它基本上是把內容的這個語言隔閡直接消除了 對吧 所以說每個創作者都可以創作所有語言的內容 然後他們的觀眾直接變成了全世界的人 但同時他們的競爭者也會變成全世界的人 以後在台灣看這個3C產品開箱的人 並不一定要再看Jourman了 為什麼 因為他們可以看Marcus Brownlee Marcus Brownlee會講中文了 那在這種情況之下呢 觀眾看的內容絕對會改變 那也因為觀眾看的內容會改變 創作者創作的內容也會改變
(06:03~07:05) 那這兩者的行為都變了 平台的推薦演算法怎麼可能不變 一定也會變啊 當然這種事情不會一夕之間就發生啦 它一定是會慢慢的走 但是終究它單純靠著這項技術 整個創作者生態器就會走到一個跟現在完全不一樣的地方 就是given其他的因素完全沒有改變 單靠著這個因素這個技術 我們就會走到一個完全不一樣的地方了 那這邊其實是我自己蠻有興趣繼續討論的 畢竟我現在也是一個創作者 但是其實好像幾乎沒有人回應我這個部分的觀點 大部分人回應呢 是我第二個觀點 我的第二個觀點是在講說 有了這個技術之後 學語言的經濟價值又要降低了 那我覺得我有拋出這個觀點可能是 這部影片這麼爆紅的很大一個原因啦 很多人都在留言區討論相關的話題 那我覺得每次討論到這種主題 就是可能一個AI技術要取代某一些人的 或是某一種能力的這種主題 下面留言區最常出現這三種人 第一種人呢就是說 學語言還是有它的價值啊
(07:05~08:05) AI是沒有辦法完全取代人類講一種語言的 這點我自己是完全同意啊 這就是為什麼我在本文裡面我是說 AI會讓學語言的經濟價值變低 我沒有說AI會讓學語言的文化價值變低 這點其實我在我很久以前的一支影片 我就有講過了 就是學語言會分經濟價值跟文化價值嘛 那學語言的經濟價值 意思就是說這個語言作為一個技能 可以讓你產生多少的經濟產值 那這邊大家要知道一點就是 並不是最近的AI才讓這個經濟價值下降 學語言的經濟價值其實這幾十年來一直都在下降 你看幾十年前的台灣 那個時候還有一些洋行對不對 那麼那些洋行在做國際貿易嘛 那那個時候如果沒有你講這個語言 他們這些洋行的國際貿易就做不成 那這個國際貿易的經濟價值是極大的 所以說你會講這個語言 你產生的經濟價值是極大的 但是當然呢之後就是網際網路出現了嘛 那網際網路出現了讓國際貿易變得更好做
(08:05~09:05) 然後同時你要做國際貿易你的語言門檻也下降了 因為翻譯的技術出現了 然後同時大家學語言的難易程度也下降了 因為就是網路上很容易學嘛 所以學語言的經濟價值本來就是隨著科技的成長會慢慢走下坡的 而且它已經走下坡一陣子了 那這個非常正常嘛 這個就是科技在做的事情啊 任何科技在做的事情都是提升人的生產力 然後取代舊時代的技能 但我覺得如果你把這個學語言的經濟價值 下降的這個曲線畫出來的話 它可能一直到2017年之前呢 它都是緩緩下降緩緩下降 但是在接下來的幾年 我覺得它會開始陡降 就直接掉下去這樣 原因很簡單嘛當然就是因為生成是AI 那其實呢我覺得語言翻譯這件事情 在2017年的時候就已經被AI解決了 解決的意思就是說AI已經可以把一種語言翻譯的 跟一個訓練有素的人類一模一樣好 那為什麼呢當然就是因為2017年Google的那篇論文啊 Attention is all you need 它介紹了這個叫做Transformer的架構
(09:05~10:05) 也就是說從2017年開始 人類其實就已經有了 可以把一種語言的文字完美翻譯成 另外一種語言的文字的技術的AI技術了 那這邊我們有實際數據啦 如果有人有實際數據可以提出來 但我覺得2017年之後的這個 純文字的翻譯工作一定比 2017年之前的這種工作少非常非常多 但是很明顯的這個純文字的翻譯呢 只是學語言這個技能能做的工作的其中一環嘛 所以說它並沒有取代非常大的經濟價值 然後同時雖然說這個Google翻譯 有因為這個技術變好很多 但是因為一些Engineering的問題 Google沒有辦法提供最好的模型來使用Google翻譯 來提供給所有幾十億的用戶 畢竟你不可能每次大家把文字丟到Google翻譯裡面 你就用最好的模型跑給它 畢竟這些模型還是要吃蒜粒啊 它又不是免費可以無限跑的 那越好的模型就通常越大 那越大就吃越多蒜粒 當然這邊一部分是我自己的猜測 我其實不太知道Google翻譯背後的AI模型是哪一個
(10:05~11:05) 我也不確定他們有沒有公開講這件事情 但是就我現在使用這個工具 我偶爾還是會覺得它翻得有點爛 就是絕對是比ChatGPD爛非常多 但是我要講的是 可能因為一些Engineering的問題 最好的技術並不是所有人都可以立刻使用在生活中的 所以這個技術對於學語言的經濟價值的影響 它並不會一開始就直接最大化 它影響的程度影響的速度 是隨著這個技術的普及率跟影響範圍慢慢變大的 那這也是為什麼我說從2023年之後 這個學語言的經濟價值會直接陡降 因為2023年之後 這個技術的普及率跟它的影響範圍 是直接變大數倍的 影響範圍變大很明顯嘛 就是我們從原本的純文字翻成純文字 我們現在可以做各種各樣的翻譯 連Hagen這種能翻譯影片的AI都已經出現了 更不要說這個 文字到語音,語音到語音,語音到文字 這邊最明顯的例子就是Meta的Similus M4T 同時除了這個影響範圍變大以外
(11:05~12:06) 它的普及率也會急速上升 因為這個生成實力AI就是現在大家的焦點 全部的投資人的熱錢全部都丟在這邊 你說它進步能不快嗎 所以這邊學語言的經濟價值絕對會開始非常快速的降低 最直接的經濟價值就是那些語言的工作 這些機會會越來越少 像是即時翻譯、口譯 這邊都有機會會直接被AI取代 間接的經濟價值就是提升你的國際競爭力 就是你可以看懂國外的一些論文 國外的一些新聞之類的 這邊語言的隔閡也會開始非常快速的降低 當這種直接跟間接的經濟產值降低 都被開始觀察到了之後 接下來教育部才會開始做出一些相應的改變 教育部做出了這些改變之後 學校才會開始變 老師怎麼教才會開始變 然後之後補習班要怎麼補也才會開始變 到最後學生怎麼學才會開始改變 所以我覺得你如果是教育界的人 或是你是學生的話 你要知道這些事情遲早會發生在你的身上 而且當這些改變發生在你身上之後
(12:06~13:07) 通常是已經非常晚了 所以我才會在我的影片裡面說 學語言的經濟價值要降低了 學校老師學生應該要怎麼因應 因為這件事情是你們現在應該就要開始思考的 OK我這邊好像不小心講得有點太起勁了 有點講到其他地方去了 那我們話說回來 學語言的經濟價值會歸零嗎 我覺得絕對不會啊 為什麼 因為學語言還有它的文化價值存在啊 然後有文化價值 它就可以產生一定程度的經濟價值 語言當中是蘊藏了非常多深厚的文化的 就連我這個每天在看AI的人 我也不想把這些文化全部都交給AI 就像是未來 如果所有的動漫全部都會講中文 我還是會想聽日文版的啊 中文版多奇怪啊 我根本就沒辦法想像 而且人與人之間的交流真的 如果你能講對方的語言 你真的是可以講到對方的心裡 所以說說真的啦 我覺得學語言的文化價值會持續存在 但是它的經濟價值一定會持續降低 欸等一下 我覺得我們這個開場閒聊呢 好像講得有點太久了 所以我原本還想多聊一下 就是我在留言區看到的第二種人跟第三種人
(13:07~14:09) 但我覺得我現在就簡單的評論一下就好了 那第一種人我剛剛講了嘛 就是它說學語言還是有其他價值的這些人 這些人的核心想法就是這個啦 但是他們可能表達的方式都不盡相同 有些人可能就聽不懂我在講什麼 然後可能也沒有想過 學語言會有分文化價值跟經濟價值 所以他們就會罵我傻逼之類的 那我剛剛講這麼多 我就是把我的想法表達清楚啦 然後也回應他們一下這樣 那第二種人呢 他就是會去抓說 欸這個AI他哪一句話翻錯了 然後重點是他抓出來之後他會說 欸你看這個AI不夠好 它絕對不可能取代人類 然後他們有些人還會舉例子喔 就是他會舉說 你看日文跟英文的語序是完全不一樣的 一個主詞在前一個主詞在後 AI怎麼可能翻得出這種東西 那我覺得這種人就是眼光比較狹隘的那一群人 他們通常會低估這個科技成長的速度 甚至會認為因為一些這個他們自認為的barrier 然後就成長不下去了 但這個很明顯就是錯誤的嘛 而且那個語序的問題早就2017年就被那個Transformer解決了
(14:09~15:09) 但每次講這些話題真的都是還是會看到一群這些 可能比較skeptical的人 最後一群人呢是有優越感的人 就他們可能是自己離這些科技產業比較近的人 然後他們就會說一些垃圾話 就是說什麼 哎呀那些讀外語學系的真的是可悲啊 文組直接下去啦 白痴才讀文組 我覺得這種人也真的是挺討厭的 根本就沒有人在跟你比嘛 你是自卑還是怎麼樣 為什麼一定要找人家比較 我覺得如果你單純的講說讀這些語言科系出來 出入然後平均薪資會比你差非常多 而且這個出入可能有越來越差的趨勢 這個是事實以及非常合理的猜測 所以說講這個我覺得沒有問題 但你真的沒有必要人身攻擊 就是你一旦踏入這個人身攻擊的範圍 就是說他們笨啊或者是說他們白痴啊 我覺得你的論點品質會直接被降到最低 因為真的沒有必要這樣講 那這個學員的話題呢 我覺得其實還有很多可以聊的啦 但我們就先簡單討論到這邊 那接下來就進入正題啦 我們要開始講我們的State of AI Report 那這個State of AI Report
(15:09~16:09) 翻成中文呢應該是AI現狀報告 顧名思義這個Report就是要讓大家對於AI的現狀有一個概念 那這個Report的作者呢是一間叫做Air Street Capital的VC VC就是創投公司嘛 就是一些投資一些早期新創的公司 那這間公司主要就是在投資AI相關的project 所以他每一年都會出一份這個State of AI Report 那他已經連續出了六年了 那我覺得現在這個State of AI Report已經變成了 每一年學界跟業界的人都會很關注的一個Report 因為不得不說他內容真的蠻有料的 非常完整幾乎涵蓋了所有AI的重要話題 他主要有分成四個部分 第一個部分是research 這邊就是在講AI技術的演進 第二個部分是industry 這邊是在講整個AI的供應鏈資金鏈跟應用端的發展 第三個部分是politics 這邊就是在講一些政府官員怎麼參與AI 然後還有一些國際政治地緣政治的東西 最後是safety 這邊就是在講我們怎麼規範AI 怎麼把AI做得更安全 然後整份報告有163頁 然後內容我真的覺得蠻不錯的
(16:09~17:10) 就是有給你一個大方向 但同時也會幫你深入細節 那我覺得其實很多人可能不知道這個Report 是因為媒體沒有什麼在報 不管是主流媒體還是自媒體都是 然後媒體不講的原因很簡單嘛 就是這篇Report非常完整 然後非常細節 但他沒有什麼爆點啊 就是我覺得他們如果在預測那邊 如果講出一些非常大膽的預測 可能會比較多人在講他 但他們並沒有這麼做 我覺得就蠻中規中矩的啦 所以說媒體也不怎麼鳥他們 但我覺得業界的人多少都還是會看啦 所以說我今天也帶大家看一下 但當然我不可能把所有的內容都講完嘛 所以說我在他的這幾個大Category下面呢 各列了幾點我覺得我想聊的比較重要的 然後同時呢 我也不確定我們是否有可能在這一集 把我想聊的全部都聊完 因為說真的這每一個話題呢 其實都可以深入聊 聊到非常深 所以我們今天呢就是從Research開始聊 然後再來聊Industry Industry聊完再來聊這個 最後再聊一些他的Prediction 那中間勢必有一些部分
(17:10~18:10) 我會聊的比較多然後比較深入 然後有一些部分我會比較輕鬆帶過 好那我們廢話不多說 趕快先從Research開始吧 那Research這邊開門見山 最重要的話題就是現在的模型王者是誰 意思就是說現在最強的這些AI模型究竟是誰 那這邊必須先說就是這邊講的AI模型 其實都講的是大型語言模型 那當然AI有非常多種嘛 尤其像是Diffusion這種製圖模型 就真的比較少在這個State of AI Report中被提到 但這也是無可厚非啦 畢竟這個2023年有最大經濟價值的就是LLM 也就是大型語言模型 好那所有大型語言模型當中最強的模型是誰 這邊State of AI Report跟我的答案一樣 就是GPT-4 GPT-4是OpenAI3月的時候釋出的一個大型語言模型 那我們會說它最強的是因為它在幾乎各種事情 各種方面上綜合表現它都是最好的 然後一般來說它也有比其他模型更強的邏輯推理能力 然後它講出來的話是更factual的 更正確事實正確的
(18:10~19:11) 那我們知道其實現在的GPT-4 跟我們3月的時候看到那個GPT-4比起來 現在的好像是比較弱了一點 這我記得是Berkeley跟Stanford的一個論文在講的事情 然後我自己也有觀察到這件事情 那大部分人對於這件事情的共識呢 是覺得應該是OpenAI持續的在這半年 有一直在tuneGPT-4這個模型 然後他們在tune的方向是把它tune得越來越安全 安全的意思就是說它不會講出一些危險害人的話 最簡單的例子就是你叫它做一個炸彈 它不會真的跟你講這個炸彈要怎麼做 但是在這個過程中你犧牲的往往是這個GPT-4 它的實際能夠解決問題的能力 這是蠻常見的一個叫做安全性跟實用性的trade off 但我覺得真的是儘管如此啊 其實GPT-4應該還是現在最強的大型語言模型 那現在跟GPT-4比起來比較強的競爭對手呢 應該是Anthropic的Claw 2 但我本人是還沒有在用這個Anthropic的Claw 2啦 因為不得不說我現在真的是被OpenAI給綁住了 就是因為GPT-4真的是太好用了
(19:11~20:12) 然後我也知道它現在大概是最強的 而且我每個月都有付600塊 所以我有想到什麼AI的問題我就會直接問GPT-4 但現在Claw有開放台灣的人使用了嘛 所以說我應該最近也會去辦個帳號 然後去玩玩看看說是GPT-4比較好還是Claw 2比較好 但至少對於AirStreet Capital來說 他們仍然認為GPT-4是現在最強的LLM 那再來我們知道大型語言模型 雖然說都很大啦 但是他們還是有分大小嘛對不對 還是有非常巨大的大型語言模型 跟比較小的大型語言模型 這邊的大小的比較啊 當然就是比較這個模型的參數的多寡 這些參數呢我覺得你不懂的話 你可以把它想像成這些模型儲存他們知識的地方 一個模型的參數越多 它能儲存的知識就越多 它能學會的事情就越多 但同時它也會需要比較多的算力跟記憶體來訓練 然後也需要比較多的算力跟記憶體來使用 那這個GPT-4絕對算是非常大的模型 因為它是有8個2200億個參數的模型組合成的
(20:12~21:12) 那我覺得現在我自己的感受 就是沒有人真的做過這種排名 但是我自己的感受是GPT-3以上的模型 就是你的參數在1700億個參數以上的模型 我覺得算是比較大的大型語言模型 然後你的參數是介於600多億到700多億這邊的模型 就像是LAMA270B 我覺得算是中型的模型 然後你的參數是介於70億到100多億這邊的參數的模型 我個人覺得算是偏小的大型語言模型 那我們接下來就講講這個偏小的大型語言模型當中誰最強 會想特別聊聊就是小模型誰最強 是因為這些小模型跟這些中模型或是大模型有一個很大的差別 就是這些小模型可以在邊緣裝置上面跑 意思就是說你用一台有GPU的電競筆電 或甚至是沒有GPU只要CPU的RAM夠的一般筆電 你就可以自己在家裡跑這些模型 像我最近有在用LAMA的13B在build一些application LAMA13B就是LAMA然後有130億個參數的模型
(21:12~22:14) 就我們剛剛分類它算小模型 然後我記得我在build的時候如果沒記錯的話 就是如果你把這個模型壓縮到一定的程度 它只要佔差不多7、8GB左右的記憶體 這個壓縮英文叫做Quantization這個是一定會做的事情 然後你可以把模型最少壓的小兩倍 而且過程中的loss是很少的 意思就是說它不會失去很多的知識或者是能力 所以這些小模型我覺得一直以來都是開源社群非常注意的一些模型 因為網路上的橡皮筆本家裡又不可能有個A100、H100可以使用 當然就是只能玩這些模型 那這個小模型當中誰是最強的呢 答案是上個月才剛出來的Mistral 7B 那這個Mistral 7B是一間叫做Mistral AI的公司推出的一個大型元模型 那這個Mistral AI不得不講一下 真的是很酷的一間公司 他們在今年五月的時候才剛成立 然後成立之後過了四個禮拜而已喔 他們任何產品都沒有 然後他們網上也只有一行字 就連其他的Tab都沒有
(22:14~23:19) 它就是一片白的然後就一行字寫說我們正在徵財 它基本上是什麼東西都沒有然後只有一個夢想的狀態 他們有說一句話就是說我們要挑戰OpenAI 但就是這樣而已他們有這樣子的一個夢想 他們在這種狀態之下竟然募到了一億多美金的種子輪募資 那這間公司的Founder有三個啦 基本上都是Google跟Meta AI出來的人 所以他們背景都很硬沒錯啦 但是哇才四個禮拜然後你啥都沒有竟然可以募到一億多美金 那他們原本預計呢好像是要在2024年才釋出他們的大型圓模型 但他們是提前了他們在今年九月的時候也就上個月 他們釋出了Mistral 7B 那他們那時候釋出這個Mistral 7B呢 它最大的賣點就是它是現在最強的小的大型圓模型 它在所有的Benchmark也就是所有的測驗上面 所有的方面它都比LAMA 2 13B還好 LAMA 2 13B喔 也就是將近比它大兩倍的模型喔 它竟然在所有方面都比它好 然後他們還有另外一個賣點就是它可以跑得更快然後更有效率
(23:19~24:21) 因為他們在這個模型的架構上他們調整了一下注意力機制這邊的implementation 注意力機制在一個對於一個大型圓模型來說是非常重要的一個部分 然後同時也常常是運算的一個bottleneck一個瓶頸 注意力機制主要在做的事情就是讓這個大型圓模型在看一個字的時候 它可以同時知道這個字跟其他任何整個句子中所有的其他字之間的關聯 那我們前面一開始說就是翻譯的時候兩種語言它與續不一樣的問題已經被解決了 它就是被這個注意力機制解決的 那這個注意力機制常常是一個模型在跑的時候的速度的很大的一個bottleneck 這是因為對於一個大型圓模型來說 除了它這個整個神經網路的運算以外 它運算最密集的地方就是注意力機制的運算 那這個Mistral 7b就有針對這個注意力機制運算做一些優化 它們有做一些很fancy的attention叫做group query attention跟sliding window attention 那這邊的基數細節我就先跳過好了 這邊要講下去可能這集就結束了
(24:21~25:23) 那同時這個Mistral 7b除了它這個在benchmark的成績很好 以及它有這些fancy的attention以外 它有個最大亮點是它的license是apache 2.0的license 意思就是說這個模型算是開源的 就是任何的個人或是公司都可以拿這個模型來進行商用 你可以把它下載下來自己在自己的電腦上跑 或者是在自家公司的伺服器上面跑 然後都是免費的 至少我目前的認知是這樣 我不確定細節的部分我有沒有了解正確 因為說真的現在這些模型的licensing已經有點太複雜了 然後我也不是法律專業的 所以我也不會很想認真的研究這些東西 而且我有聽說就是有人說Mistral AI他們的license好像有一些cavia 就是該怎麼講有一些附帶條件 然後是你好像沒辦法很直覺看得出來的一些附帶條件 一些隱藏條件 這部分我沒有了解非常清楚 那就等我哪天真的想要用Mistral 7b來build一個startup的時候 我再來跟大家分享我的研究結果 但我自己是覺得如果你真的想要build一個startup
(25:23~26:24) 或是想要build這個東西進你的產品當中 只要你的產品沒有紅到海外 然後紅到紅翻天然後賺爆多錢 我覺得這種在網路上公開可以下載的模型 你就直接下載下來用 真的應該不會怎樣 只有你的app如果變成是那種instagram或者是tinder之類的這種超級大app 那他們可能就會派人來聯絡你 然後不知道可以用什麼方法告你 但我覺得如果你沒有做到這種程度應該都不會出問題 不過我這邊也要說一下這絕對不是法律建議 這只是我自己的想法 反正這就是Mistral 7b 它是非常好厲害的一個模型 然後它是開源的 然後它背後的公司是很瘋狂的 對了這邊我也要講一下 就是我覺得大家對於這些模型能力的比較 應該要抱持一點點的懷疑 因為這些模型比較都是拿這些公開的benchmark在比 那這些benchmark其實是蠻糟糕的一個評比方式 因為它很好作弊 而且它也很難真正體現出一個模型它的能力 好作弊的原因是因為 當然你在訓練模型的時候 你如果直接把這些benchmark的資料 直接放到你的訓練資料當中
(26:24~27:26) 那你的模型不就直接把答案背起來了嗎 或者是就算你不這麼做 但你訓練資料中出現很多類似的訓練資料 你的模型也算是某種程度上在作弊 因為比如說你拿這個Leco的問題來train這個模型好了 Leco就是一些軟體工程師要申請工作的時候 要刷的一種題目一種考試啦 那Leco的問題你可以抓出一千題 但其實這一千題呢 你可以提煉出大概可能六七種問題的形式 這一千題都是從那六七種形式中變化出來的 那你拿另外一千題去訓練你的模型 儘管這一千題跟考試的一千題是不一樣的一千題 但它還是可以把那六七種這個問題的形式給抓出來 經手 那這個模型最後在那一千題這個考試的Leco問題中 它就可以回答得非常好 但它不這不代表它寫扣能力真的變強了 所以我覺得大家在看這些benchmark的時候 真的也要有一點懷疑之心 就像我一開始在比較GP4跟Claw2的時候 我大可用一些benchmark的成績來比
(27:26~28:27) 但說真的我還是會想要自己去用過 然後感受過了之後我再判斷誰比較好 好那我們模型王者先講到這邊 再來一點呢我要講RLHF變成主流這件事情 RLHF是什麼 它是reinforcement learning from human feedback 簡單來說就是人類用某種方式給一個模型它的反饋 讓這個模型變得更好的過程 那這個state of mind report它是說 RLHF現在已經變成了大家在訓練這些模型最主流的方法 那這個state of mind report也有說 RLHF這個方法是從是被OpenAI帶起來的風潮 因為我們知道第一代的ChatGPT 它剛出來震驚全世界的那個ChatGPT 它就是靠RLHF訓練出來的 那我們知道這個ChatGPT它背後的腦袋就是GPT3.5 那GPT3.5基本上就是GPT3透過RLHF訓練出來的 那這個GPT3兩年前就已經出來了 那那個時候它出來的時候還沒有紅出圈外 就只有在machine learning圈子裡面的人在看而已
(28:27~29:27) 那那時候的GPT3其實我已經覺得蠻強了啦 就是它有展示一些reasoning的能力 然後寫故事的能力之類的 但那時候它就沒有經過RLHF 所以說那時候的GPT3它純粹就是一個接話模型 最簡單的使用方法就是你先打一些字 然後它幫你把整個東西接完 就比如說你打once upon a time 然後它就會說once upon a time a pig in a house blah blah blah 但是經過了這個RLHF的過程 OpenAI就把這個GPT3給tune成了一個你可以跟它問答的一個模型 那整個RLHF的過程可以簡單分成三個步驟 第一個步驟是supervised learning 這邊就是你會直接請一些真人 然後根據這些prompt這個提示寫出最適合的回答 然後直接拿這個prompt跟回答的pair直接丟進去訓練模型 那訓練過了這一遍之後 第二個步驟呢你要訓練一個獎勵模型 這個獎勵模型基本上就是你丟一個回答進去 它會跟你講這回答是好還是不好 那我們訓練這個獎勵模型的方式就是要靠人工啦
(29:27~30:29) 這邊就是你會拿已經經過第一個步驟簡單訓練過的那個模型 然後讓它根據一個prompt產生四種不同的回答 然後你請一些人把這個四種不同的回答做一個ranking 排除說哪個回答最好哪個回答最爛 然後把這些ranking的資料丟進去訓練那個reward獎勵模型 那最後一個步驟呢就是用這個獎勵模型來訓練你的AI模型 你的AI模型沒講出一個答案 獎勵模型就跟它說這個答案是好還是不好 然後根據這個結果你的AI會再去做調整 那我們其實不只是可以使用這個rlhf的方法 讓模型變得更容易 更能夠知道怎麼樣最好的回答人類的問題 你還可以使用rlhf讓模型變得更安全 讓它可以不回答你不想讓它回答的問題 或者是用更符合你的價值觀的方式回答這些問題 那在machine learning的圈子裡面我們是把這個 讓AI可以做出符合我們期待的行為 講出符合我們期待的話 不要講出預料之外會危險會害到人類的這些話 的這樣子的一個問題我們把它稱作alignment problem
(30:29~31:29) 那這個rlhf就是我們現在在做這個 大型圓模型的alignment最重要的武器 但是這個state of the art report裡面有講到 儘管大家儘管現在這個rlhf是主流 大家仍然在尋找rlhf的替代品 因為這個rlhf還是有一些問題 最主要就是兩個 第一個就是它很難scalable 因為你在做rlhf的過程中 你要有hf啊你要有human feedback 那拿到human feedback是一個 很花資源的一件事情 你真的要請人來rate這些回答 真的很花時間然後也花錢 再來另一個很大的問題就是 rlhf其實不是reinforcement learning from human feedback 是reinforcement learning from a very small subset of humans feedback 也就是說這個模型只會有一小撮人 在進行rlhf在align這個model 那這一小撮人當然不代表全人類啊 他們有他們自己的偏見 但是因為只有他們在給反饋 所以這個模型就會學到他們所有的偏見
(31:29~32:31) 所以今年也看到很多公司想辦法在找別的方法 比較有名的就是anthropic這間公司 他們做了這個rl-aif 就是reinforcement learning from ai feedback 顧名思義就是我們不要讓人類來align 我們讓ai來align 我們人類只要寫一個非常高層次的規則 或是他們叫做constitution 給這個ai 讓這個ai根據這個constitution 給你現在在訓練的這個ai feedback 或甚至meta ai有提出另外一個做法 是我們直接不要rlhf了 我們直接去抓非常少量但是很高品質的資料 直接餵給模型就好了 臉書是有發現用這種方式做出來的模型 其實真的不會比rlhf差很多 只要你的資料品質夠高真的就很好了 那資料品質高的意思是什麼呢 當然啦你就想像你最想得到的回答是什麼 就是這個回答要很完整 然後很容易理解嘛之類的 那臉書他們是在網路上很詳細的挑過 然後甚至還有自己寫一部分的回答
(32:31~33:31) 然後拿這個高品質資料去train這個lm 然後那這邊就是rlhf的部分 再來這個state of value report有提到 大家在追求context length這件事情 context length在講的就是 你一次可以輸入多少字的問題給這個ai 其實嚴格來說是你的input跟output加起來在算 才是你的這個完整的context length 那你常常看到一些模型 然後後面有寫說什麼8k 32k 那個8k 32k他在講的就是那個模型的context length 那這個context length算的那個token呢 它不是字啊 它不是一比一的字 但是有個大概規則就是 差不多100個token是75個字這樣 當然這邊是英文的啦 那你根據這個法則下去算 你就可以大概算出說可能8k的context length 你最多可以在問題這邊打幾個字 然後今年當然是一大堆人在想辦法增加這個lm的context length嘛 理由很簡單啊 如果這個lm的context length夠大 你可以直接把一本書丟進去然後問他任何問題
(33:31~34:31) 這樣不是用起來很爽嗎很方便啊 而且這個lm呢有很強的fuse shot能力 fuse shot的意思就是說儘管是這個lm沒有做過的事情 你只要先給他幾個例子 他就可以做得非常好 那你這個context length夠大的時候 你就給他一堆例子啊 然後他就可以做任何事情做得很好 那目前最有名的這個context length的例子呢 就是anthropic的clawed 他有把clawedscale到100k的context length 100k的context length基本上就是一本書了 就你真的是可以把一本書放進去 那大家在scale這個context length的時候 通常是有兩個瓶頸 一個是position encoding 一個就是注意力機制我們剛剛有講到 position encoding在做的事情就是 你要告訴這個模型這個字在整個句子中 在整整個整篇文章中是在哪個位置 那這件事情當然你的文章越來越長 他就越來越難嘛 主要是你的計算量會變大 再來注意力機制一樣嘛 就是你是要跟這個模型說 這個字跟其他每一個字的關係是什麼
(34:31~35:33) 尤其這個注意力機制 因為他有牽涉到一些矩陣的懲罰 所以說他的time and memory complexity 是大歐的n平方 這邊如果你沒有學過軟體工程 你不懂這句話是什麼意思 你只要記得就是 假設今天context length乘了兩倍 你計算所需的時間 跟記憶體的用量會乘四倍 所以這兩件事情很讓人頭痛嘛 這也是很多研究員研究的方向 比如說我們現在就有很多 很fancy的這些注意力機制的implementation 像是有一個最有名的叫做flash attention 他可以讓這個注意力機制的time complexity 變成大歐的n 也就是說你這個context length變成兩倍的話 你的所需的計算時間跟記憶體 也只會變成兩倍而已 現在還有最新的flash attention 2 在position encoding這邊 也有很多很fancy的方法 什麼positional interpolation 什麼rope之類的 反正大家都在想辦法讓這個context length越長越好 但是有一個問題
(35:33~36:34) 當你這個context length真的長到一個很誇張的程度的時候 你的模型真的可以好好的運用這麼多的文字嗎 當然其實是不行 這也是我們今年發現的事情 就是模型的能力 他會跟著context length的長度而衰退 尤其是你給他context非常長的時候 模型通常會比較注意 這個context最一開始的那一段話 跟最後面的那一段話 但你如果今天問他的問題是 在整段話的中間某一個小小的問題 他可能就答不出來 當然這個問題現在也是很多人想要再改善的地方 然後也有很多更fancy的一些attention的方式出來之類的 那這邊我們就繼續看下去 就是看一下這些researcher可以想出什麼方法 再來這個research這邊我還想談一點就是 CETAVI report裡面有講到 他們有看到有一些模型在以小博大的情況 這其實主要從微軟的一篇論文叫做 Textbook is all you need 他們發現說 用一個小模型 當小模型用少量但是高品質的資料去訓練的時候
(36:34~37:34) 他的表現可以跟比他大50倍的模型一樣好 那這篇論文的標題 Textbook is all you need 裡面的Textbook 他在講的就是 跟Textbook一樣品質這麼高的訓練資料 就是假設你要讓這個模型訓練的是程式碼的資料的話 你要用的是像那種教科書等級的程式碼 就是一行一行寫得漂漂亮亮的 甚至還有完整的註解 而不是使用那種GitHub某一個鄉民隨便寫出來的 亂七八糟的一個程式碼 那個變數都亂設啊 或者是用一些白痴很hard code的方式 一大堆if else在那邊寫啊 你只要用這個教科書等級這麼乾淨的資料 你下去訓練一個模型儘管那個模型非常小 他們在這邊訓練的一個模型是叫做FiveOne 然後他的參數呢是十幾億個參數而已 就是比我們剛剛講到的那個Mistral AI 已經最小的Mistral AI 也至少有七十幾億個參數 他只有十幾億個參數 他竟然在Coding的表現是非常好的喔 所以說好的資料真的很重要
(37:34~38:34) 我覺得有些人說資料就是接下來的石油 這句話真的不假 你網站如果真的有很大量很高品質的資料 你真的是爽歪歪了 除非你這些資料想你早就被別人扒光了 好那我們research的部分 我們就先講到這邊就好了 其實大家如果去看我們的報告 他們還有講很多其他東西啦 但是我主要挑這幾點啦 然後其實我剛剛講了很多這些 可能偏運作原理相關的內容 都是我自己補充的 就他們沒有講的那麼細啦 他們都是assume看報告的人都已經懂這些東西了 好啦我必須承認就是 這個research確實是講的有點久了 我原本還想說我們這一集 可能research,industry regulation and safety 然後prediction全部都要講完 想也知道應該是不太可能 尤其在industry這邊啊 我覺得很有料很多可以講的 講到industry又可以聊我最愛聊的一些話題 就是包括NVIDIA 那我覺得industry這邊還有接下來這個 regulation and safety 我先買一個伏筆啦 不知道是下禮拜還是哪一次
(38:34~39:34) 可能是下禮拜吧 我就再把這個主題給完整的講完 這樣其實也比較好啦 因為我真的覺得industry應該要給他一整集的時間 那今天最後我就 再講一些我對於AI research的看法好了 首先我第一個想講的就是 我們剛剛就真的只碰到冰山一角而已啦 AI research有太多太多方向可以討論了 就是包含 PFT 對吧 parameter efficient fine tuning agent quantization retrieval augmentation 這些都是我們沒講到 那當然啦我覺得真的蠻難在 這個所有的AI研究 子領域都維持在最前面 尤其你要知道我剛剛講的這些喔 真的全部都只是LLM的 研究領域而已 就是video跟image還有audio 那邊都有超級多其他的研究領域 尤其在diffusion模型這邊 我自己覺得這邊的論文數量 可能不會比這個LM少 只是他們就是可能比較 沒有像LM這麼大的經濟價值 所以說比較容易被忽略
(39:34~40:34) 所以真的我承認真的太難了 幾乎不太可能在 這每一個領域都維持在最前面 但這是我目前努力的方向 當然絕對不可能我每一篇論文都看 絕對不可能 但至少看個標題嘛 對不對就當論文新出問論文出來的時候 OK至少刷個標題啊 看一下 會想要盡量跟上所有的research 因為如果未來想要在這個 AI要開始產生極大量經濟價值之前 你先看到苗頭 你可以看到對的方向 然後趕快進去卡位 你想要做到這件事情的話 當然你跟在所有research的最前面 當然是最好的 因為產品這些AI工具一定都是落後指標 一定是有這個技術先出來了 才會有人把這個技術做成工具 所以你能跟到最新的research 當然是最好的 但是問題來了假設你今天是一個科技小白 AI小白 你要跟上現在最新的AIresearch 根本就是不可能的嘛 因為你的根底不夠深厚啊 那我覺得現在你可以做的事情就幾種啊
(40:34~41:34) 第一個就是你要先懂得分辨research 跟product的差別 我知道現在有些粉絲可能會很生氣 然後說哈利你倒白痴喔 我怎麼可能分辨不出research跟product 我們來舉個有可能會混淆的例子 首先有兩件事情給你比較 第一個是我兩集前有講過的 這個Lava模型 是一個可以吃圖片跟文字的AI模型 這個AI模型跟第二件事情 ChatGPT現在多了語音功能 它可以講話 這兩件事情哪一個是research的progress 哪一個是product的progress 答案是第一個是research的progress 因為他們是想出了一個方法 讓一個語言模型 同時具有視覺能力 然後同時第二個openAI那個 它是純粹的product的progress 因為你並沒有用到任何新的技術 你只是把現有的技術用API串在一起而已 所以我覺得第一件事是 大家要能夠分辨哪一些部分是research的progress 哪一些部分是product的progress 我並不是說product的progress這邊就不重要 就不用太去了解 兩邊都非常重要喔
(41:34~42:34) 但我覺得至少你要先知道要怎麼分辨 你才可以知道下一步要怎麼看下去 如果是product這邊的progress 你接下來要看下去的方向就是 消費者會怎麼反應 公司要做這個東西 你現在要怎麼看下去 消費者會怎麼反應 公司要做這件事情的成本是什麼 公司怎麼賺錢之類的 那如果這是research的progress 你要看的方向就是 這個技術會帶來多大的impact 他的cavia是什麼 就是他在什麼條件下才會work 他未來有可能會被怎麼應用之類的 我覺得你懂得分辨這件事情之後 你也比較看得懂現在這些AI的新聞 那當然如果你是從我的頻道這邊聽 你是不用太擔心這件事情 因為我都把所有事情講得非常清楚 但是現在市面上確實充斥著一些 不是很懂AI的人在講 然後他們可能就會有點混淆你的觀念 所以我覺得大家真的可以先從這件事情開始努力 那說到新聞這個東西 我其實對於科技浪的下一個階段 有一個想像 我希望未來的科技浪每個禮拜會有兩集 一集就是像我們現在這樣
(42:34~43:34) 每個禮拜做一兩個主題的deep dive 那另外一集呢就是討論 那一個禮拜最重要的科技新聞 討論的方式我希望是 延續我這個方式 就是我們可以用淺顯易懂的方式講 但是又講出這件事情最重要的重點 那這邊我還在規劃當中 但是我現在已經知道一件事情 就是我不可能一個人做這件事情 我覺得大部分人低估了自媒體的工作量 自媒體的工作量其實非常大 尤其我現在一個人在管這個 兩個平台嘛 IG跟Podcast 真的有點忙不過來 所以呢我不久之後應該會開始找一個 共同主持人 那這邊的細節就還沒有講完 就是整個recruiting的管道我都還沒有設定好 所以說請大家先不要寄信給我好不好 絕對不要就算你很有興趣 有很高興趣也先不要寄信給我 我今天會先跟大家說這件事情 一方面是單純分享啦 另一方面也是讓那些可能 有興趣可能想要跟我 一起共同主持科技浪節目的那些人 可以先做個心理準備這樣 好那最後還是老話一句啦
(43:34~44:04) 就是還是請大家多多幫我分享 科技浪給你身邊的朋友們 畢竟現在科技浪已經開始了 科技浪給你身邊的朋友們 畢竟現在科技浪我真的是每個禮拜 我都花了非常大心血 非常努力在做 然後目前也全部都是免費的 所以大家能回饋我的方式就是幫我分享 科技浪給你的朋友們 最後如果你是贊助廠商的話你也可以考慮一下 科技浪喔 雖然說我們才12集但是我們現在流量已經非常可觀了 想要知道詳細數據或是報價 都可以直接email給我
