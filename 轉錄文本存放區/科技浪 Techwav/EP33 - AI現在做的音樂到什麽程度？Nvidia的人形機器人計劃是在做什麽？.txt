(00:00~01:02) 【音樂】 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式 帶你了解時下最火的科技話題 本集節目由天下雜誌贊助播出 今天主要要跟大家推薦的是天下雜誌的每日報APP 早上的通勤時間、工作的零碎時間你是怎麼運用的呢? 你會放空,還是會在各種社群媒體之間跳來跳去 漫無目的地滑呢? 天下雜誌的每日報APP會幫助你在資訊爆炸的時代中 整理出八大全球政治經濟產業重點 不會失焦,也不會鑽牛角尖 給你剛剛好的深度,輕鬆就能掌握全世界的全新動態 讓你在快節奏的生活中依然保持與世界同步的觀察力 我自己覺得天下每日報APP有幾個優點 首先第一個就是它有非常乾淨漂亮的使用者介面
(01:02~02:03) 這個對我來說是非常重要的一件事情 因為我自己在看新聞的時候,尤其是拿手機在看的時候 我覺得一個使用者介面它的乾淨程度,它的排版好壞 確實是會影響到我吸收這篇文章資訊的效率 假設這個使用者介面真的是非常凌亂 一大堆廣告,然後這個字也很小什麼東西 看了就看得很難受 我在看的時候呢,我就會一直分心 沒辦法很好的吸收這篇文章的資訊 那這個天下每日報APP沒有這個問題 因為它們的UI是非常乾淨漂亮的 看文章的時候我是感到非常舒服的 然後我也可以非常專注的在吸收這個文章的資訊 那這個每日報APP還有另外一個優點 就是它的文章是天下雜誌的文章 那我覺得很多這些天下雜誌的文章呢 這個文筆真的是非常好 我覺得他們這個寫手啊,這些記者應該是有挑過文筆 讀起來真的是跟一些其他媒體的文章不太一樣 這個等級高了一層 那這個每日報APP還有最後一個優點
(02:03~03:03) 就是它們有AI語音功能,可以把文章給唸出來 所以說你如果懶得用看的 或者是你在車上看可能會暈車 然後你也不介意這個聽AI幫你報新聞的話 你就可以讓這個AI把文章唸給你聽 那這次天下雜誌跟我們科技量合作呢 也有推出免費體驗兩個月的活動 你只要使用我們資訊欄裡面的連結去申請的話 你就可以免費體驗天下每日報APP兩個月 這個是價值360塊免費送給你的概念 那我覺得如果你想要妥善的利用你的零碎時間 去學一點東西,去增廣見聞的話 很建議你去用我們的連結免費體驗這個天下每日報APP兩個月 體驗之後喜歡再決定要不要付費訂閱下去就好了 本集業配就到這邊結束,謝謝天下雜誌的贊助 好的,歡迎大家收聽科技量EP33刮 刮什麼呢?因為留言區有一個人說 可不可以在開頭說刮,所以... OK,我說了,但這應該不是什麼奇怪的梗吧
(03:03~04:03) 就我的了解啊,就是刮應該就是 就是青蛙的叫聲吧,就除了這個以外還有什麼其他意思嗎? 我不知道,那如果這個真的是很糟糕的一個梗的話 那不干我事,那是留言那位先生或是小姐的事 那這禮拜呢,我覺得在科技圈應該算是 比較沒有那麼多科技新聞的一個禮拜,比較慢的一個禮拜 所以說呢,我們今天的主題呢,就一樣是來聊上禮拜沒聊完的這個 機器人的主題,更精確的來說呢 是人型機器人的主題,但是在那之前啊 我覺得還是有一些近期的一些比較小的AI新聞 是蠻值得聊一聊的,挺有趣的 不是什麼太大的東西啊,但就是蠻有趣的這樣 那不管是在這個LLM這一邊,就是大型元模型 聊天機器人這一邊,還是在其他一些比較酷的AI 都有一些小發展這樣 那我覺得先從這些比較酷的AI開始好了 就以免講大型元模型 有一些人可能第一次聽就覺得啊,無聊,whatever
(04:03~05:04) 那我們先從比較酷的東西開始 那首先呢,不知道大家對於AI生成音樂這件事情有什麼看法 你有知道哪些模型或是公司在做這件事情嗎? 那我自己追蹤到現在啊 我自己是覺得最厲害的一間公司叫做SunoAI S-U-N-O-A-I SunoAI他們做出來的音樂 我覺得真的是,真的可以被稱作音樂 那我問過很多其他這些開源的AI音樂模型 像是臉書前一陣子不是有開源一個叫什麼 叫做這個MusicGen的模型 那我自己有載下來用,然後我覺得真的是蠻爛的 蠻爛的 就是它產出來的那個音樂呢 我覺得還沒有跨過我們所謂的Uncanny Valley 就是聽的時候會覺得有點讓你起雞皮疙瘩 你會覺得有點詭異的感覺 但是這個SunoAI它是可以產生認真的音樂的 就是連歌詞都有的音樂 就是一首歌這樣,完整的一首歌 那你產生音樂的方式呢
(05:04~06:08) 當然也就是用文字就可以產生了 你去跟它講說,用文字敘述你想產生什麼樣子的一首歌 不管是你的主題是什麼 然後你的音樂的類型是什麼 你直接跟它講,它就會產生一首非常符合你敘述的一首歌 完整的一首歌喔,兩分鐘三分鐘的一首歌這樣 那這個SunoAI我其實已經關注了一陣子了 我一直以來都知道他們應該是這個音樂生成的State of the Art 就是這個音樂生成的最厲害的模型 但是我一直沒有聊是因為沒有一個特別好的契機可以聊 他們就沒有什麼特別大的新聞可以講 然後這個音樂生成AI的部分呢 我覺得大部分人也沒有什麼特別在關注的 所以我一直以來都沒講他們 但是他們最近啊,就在上禮拜 他們釋出了他們最新版的SunoAI模型,叫做V3 所以說我自己就是有去測試了一下 然後我發現,哇,真的是跟V2比起來是有差的喔 所以說我就想說今天可以趁這個機會 來聊一下這間公司這樣
(06:08~07:08) 那就是用講的真的沒有辦法好好地敘述音樂的好壞 所以說呢,我就直接產生了幾個例子讓大家聽一下 那我們科技浪是在每個禮拜一的中午更新嘛 所以說很多人呢,其實是在禮拜一的這個 回家的通勤路上呢,就已經把這個 我們就已經開始聽我們這個禮拜的科技浪了 那我想說我們今天呢,就做一首 首先做一首這個關於禮拜一的痛苦的一首歌 因為大家可能剛剛過完禮拜一就是很有共鳴這樣 那在聽之前呢,先跟大家說就是 這首歌100%完全都是AI生成的 不管是歌詞、歌聲、還是背景的旋律、音樂 全部都是AI生成的 然後我打給他的prompt就是 請寫一首關於痛苦的禮拜一的歌 那以下呢,就是他給我的歌曲
(07:08~08:30) 心情意的痛苦 我真的不能忍受 心情意我不想傷疤 心情意我想要自由 心情意這感覺太糟糕 心情意好像留在窗上 好,我們就聽到這邊 那不知道大家覺得如何呢 我自己是覺得蠻不錯的啊 就是他這個聲音算是蠻清脆的 然後,算是說還是聽得出來有一點點AI感 但已經是蠻清脆的 然後是整個旋律的配合啊什麼的 我覺得真的跟這個市面上的一個 華語流行歌曲是真的是蠻像的 聽起來很像喔 好,那我們接下來呢 我們再來聽另外一首 就是我叫他幫科技浪做一個主題曲 那這一次呢,他的發音就沒有那麼準 大家可能會聽不懂他的歌詞在講什麼 但反正大家先聽聽看
(08:30~09:31) 科技星夜 他mi AI技術帶你穿梭未來 要升息數科技的奇跡 跟著我們一起走科技浪 好,我們就聽到這邊 那這一次呢,你就可以聽得出來 就是他的聲音就沒有那麼清脆 他們有時候就是會這樣 感覺好像聽起來像是在合唱的感覺 或者是有回音的感覺 那我覺得這個當然不是他們 就是故意要做出來的效果啦 我覺得就是AI還沒有辦法做得很好的部分 那另外一點呢,就是大家有發現 就是他的中文發音其實不是非常好 那我自己有看歌詞,我知道他哪裡翻錯 我覺得大家直接用聽的 應該很多地方根本就聽不懂他在講什麼吧 但反正他就像是他要把行業念成行業
(09:31~10:56) 那這個也是一個就是 音樂AI比較容易出錯的地方 那我們最後再聽另外一首好了 就是我覺得我還是要做一首英文的歌 因為我覺得他做英文歌的能力呢 其實是比中文歌的能力更強的 那我就做了一首一樣是關於科技浪的主題曲 但是這次是用英文 然後是用這個鄉村搖滾的風格這樣 那我們來聽聽看 來聽聽看 來聽聽看
(10:56~11:56) Country Rock Melodies Guiding me and you When the AI seems complex They make it simple and clear Techway Podcast We're cheering and we're cheering 好,那我不知道你怎麼想啊 但我覺得這應該是三首裡面最好的一首 那這個確實也就是他在產生英文的歌的時候呢 我覺得他是做得比較好的這樣 那任何人呢其實都可以免費玩這個AI喔 你直接在網路上打SunoAI 然後就可以找到他們的官網 那你只要免費辦一個帳戶呢 你就可以直接免費試用他們的V3模型 就是他們最強的這個模型 免費試用可能五次還是幾次吧 四五次這樣 那我自己是覺得 我覺得蠻值得玩玩看的啦 很有趣就是 你想到的任何東西 你知道全世界沒有一個人會因為這個東西 寫一首歌做一首歌的東西
(11:56~12:57) 你都可以立刻為他產生一首歌 好像是科技浪 我現在連科技浪都有主題曲 我覺得真的是 是我們前所未見的一個科技 很酷 那針對他們的技術呢 我也很快的做一個common 那很明顯的他們在使用的模型呢 就一樣是一個transformer 那架構上我覺得他們應該沒有什麼特別的地方啦 就跟其他的可能隨便一個 拉馬的架構就沒有差非常多 但最重要的呢他們的secret sauce 就是他們使用的tokenizer 跟他們的embedding model 那這個tokenizer跟embedding model 在做的事情呢就是 他們會把一段音樂呢 拆成一小塊一小塊的這個token 然後再把它變成一個一個的向量這樣 那這個向量就是一串數字啦 那這個模型呢 最後就是看向量 就是吃向量進去這樣 因為這個模型呢只能跟 只能處理數字嘛 那說真的這個音樂的tokenization 跟文字的tokenization比起來 真的是困難非常多的一件事情
(12:57~13:57) 就是比如說whatever這個字 你要把它tokenize 你會怎麼tokenize 你要嘛就whatever這個字 就當作一個token這樣 要嘛你就拆成what跟ever 那你還有什麼其他拆法 其實沒有什麼特別多的拆法 但今天你要tokenize一串旋律 你要怎麼tokenize 這邊就是真的比較難的地方 然後也是他們這個 有secret sauce的地方 那至於這首歌的歌詞啊 其實是一個大型元模型做出來的 這個suno AI的這個音樂model呢 並不會產生歌詞 它是先用一個大型元模型產出歌詞之後 然後這個suno AI 再幫它加上這個背景的配樂 跟這個歌聲這樣 好那以上是suno的部分 大家可以去玩玩看 我也會把這個suno的連結 放在本集的資訊欄最下面 那接下來我想講的呢 接下來我想講的是一個叫做EV的AI模型 EVI 那這是由一間叫做Hume的公司 Hume AI的公司做出來的模型 那這個Hume呢 我以前是從來都沒有聽過 但是他們這次呢
(13:57~14:58) 做出來這個EV的模型呢 在X上面有蠻多人在討論的 那這個EVI這三個字 其實是Empathic Voice Interface的簡稱 那你聽這個名字你就知道 它是一個跟這個同情心同理心 有相關的一個AI模型 那就跟我前一陣子聊到的這個Py 是有一點像 那EVI呢 是一個用語言跟它溝通的聊天機器人 就是你沒辦法用打字的方式跟它聊天 你是要真正就是跟它講話這樣 那這個語音聊天的模式呢 其實其他的這個聊天機器人也都做得到嘛 像這個ChatGPT呢 這個它手機App也有這個語音模式嘛 然後這個Py也有語音模式嘛 尤其是我蠻喜歡用Py的語音模式的 真的是非常療癒 那但這個EVI不一樣的地方在哪裡呢 它不一樣的地方在於 它可以理解你講話的時候的情緒 那像是這個ChatGPT跟這個Py 它沒有辦法了解情緒 是因為你講完話之後
(14:58~15:59) 它就有個模型把你講的話直接翻成文字 然後它是在理解你的文字 但是這個EVI它可以了解你的情緒 就舉一個很簡單的例子 就是比如說一句很簡單的話 這個Tony又來了這一句話 你可以講說Tony又來了 或是你也可以講說Tony又來了 這兩種講法它的文字是一模一樣的 都是Tony又來了這幾個字 那如果是ChatGPT或者是Py 它就沒有辦法聽出你的情緒是什麼 但是EVI可以了解 它你用不同的講法它就會說 你用第一種講法它就會說 喔真的嗎Tony帶了什麼好東西給你 那你用第二種講法呢 那你用第二種講法呢 它就會說 Tony做了什麼事情你怎麼討厭他這樣 那我自己是試用了一陣子 我是覺得真的還蠻準的 雖然說它其實你在使用的時候你只能講英文 你沒有辦法講中文 那它的運作原理呢我自己的猜測是這樣 就是首先這個ChatGPT跟Py這些模型呢 你要做到這種聊天的介面 它就是會用到三個AI模型
(15:59~17:01) 第一個AI模型是一個ASR模型 我們稱作Automatic Speech Recognition 這個就是把語音轉成文字 把你講的話變成文字的模型 第二個模型呢是一個LLM 這邊就是ChatGPT這個大型元模型的部分 把你這個文字給出一個回答這樣 那第三個模型呢是一個TTS模型 我們叫做Text to Speech的模型 就是把ChatGPT的回覆這個文字呢轉變成語音 那我猜EVI基本上應該就是這三個模型 然後除了它們以外又再加一個新的模型 是一個情緒的Classifier 我們在這個機器學習裡面 我們說一個Classifier就是 中文叫做分類器嘛 就是你可以把你這個輸入的資料呢進行分類 那猜在這邊做的事情就是把你的語音進行分類 分成很多種不同情緒的類別 比如說你是生氣、焦慮、還是開心、還是興奮 很多很多種不同類別 你們去玩他們的網站你們會看到 你每講出一句話它都會標註說
(17:01~18:03) 你這句話是用什麼樣的情緒講出來的 然後每一種情緒的佔有比例有多少這樣 所以它做的事情基本上就是我猜啦 應該就是你講完這句話之後 它同時會把你這句話丟給ASR模型翻成文字 也把這句話丟給一個情緒Classifier 把你的情緒給抓出來這些Label抓出來這樣 然後再把這兩個東西一併丟給LLM讓他處理 那我自己看到這個Eevee的專案呢 我其實是蠻開心的 因為我覺得首先用語音跟AI互動 我自己覺得是非常正確的一個方向 我覺得在不久的將來很快的喔 就可能一兩年兩三年之內喔 我們很多人就會開始使用這個語音跟AI互動了 就現在來看呢 絕大多數人使用AI都還是在打字 但是我覺得語音這邊一定會非常快速的成長 因為語音真的就是比傳訊息更自然的一個互動的方式 然後就是很多的這種應用場景呢
(18:03~19:06) 也是用打字是沒有辦法做得很好的 就比如說你今天要跟一個AI聊心情的話 比起打字用講的絕對是更好的吧 那我覺得現在還沒有非常多人在使用這個語音的方式跟AI互動呢 是因為這整個體驗呢還沒有做到非常好 我覺得現在最好的應該就是OpenAI的ChatGPT的語音跟Py嘛 那你有用過就知道 有時候真的是很神奇喔 真的會有一種得到陪伴的感覺 就是你覺得他真的有在聽你講話 然後你隨時就可以找到他這樣子 但有時候你講一講呢 你立刻就會被各種產品的缺陷呢 去破壞掉你的體驗 就是我覺得最明顯的一個就是 他們很可能就是你還沒講完話 你還沒講完你想講的 他們就已經就回下一句 就開始插你的話了 因為他們不知道你什麼時候才算是講完 那這真的蠻破壞體驗的 那我覺得這個EV呢是沒有特別去解決這個插話的問題啊
(19:06~20:06) 但我覺得他們解決的這個AI抓不到情緒的這個問題 我覺得也是挺不錯的一個問題 雖然說他其實真的沒有影響體驗那麼大 因為說真的你很多時候 你就是在生氣的時候你講的句子本身 就跟你開心的時候講的句子本身就不太一樣 所以大部分情況之下呢 我認為AI模型是可以單從你講的文字 去判斷你的情緒現在如何 但確實有一些這個可能真的有很細膩差別的這些地方 是需要透過你的情緒來表達 那這個AI能夠抓到這件事情真的非常好 好那我覺得我們今天的閒聊也算是挺久的 尤其我們還有聽了好幾首AI的音樂這樣 但是我覺得在進入這個機器人的主題之前呢 我還是快速給大家一個這個LLM 也就是這個大型元模型呢 目前最新發展的一個update 好那我們分成這個開源 也就是這個免費公布在網路上給大家使用的這些模型 跟幣源來討論好了
(20:06~21:09) 先從開源開始 開源模型這一邊呢 我們在短短的兩個禮拜之內呢 我們就看到了這個State of the Art的模型 換了兩次 我們說State of the Art就是現在最強的模型嘛 那最強的模型呢 原本在這兩個禮拜之前呢 是一個叫做Mixtral的模型 Mixtral 8x7B 它是由Mistral這間法國的公司做出來的模型這樣 那在上禮拜呢 馬斯克開源了他們的Grock模型嘛 這個我上禮拜也有講 那這個Grock模型呢 它就是比Mixtral 8x7B更強 雖然說它的參數量比Mixtral 8x7B多七倍 所以說 就是我覺得大家可以把這個參數量想像成這個模型的腦容量 你的參數量越大 你的腦容量越大 你的這個模型就應該更強嘛 那這個Grock是大了人家七倍 但它確實 然後它確實也是有比較強 但它只有強一點點
(21:09~22:09) 但是呢這個Grock它的開源模型的王者的寶座呢 其實座位之後還沒坐熱 還沒坐一個禮拜 它下個禮拜就立刻被Dethrown了 那新出來的這個模型呢是DBRX 這是Databricks這間公司出的一個大型源模型 那Databricks這間公司就是 它去年的時候有收購一間AI公司叫做 叫什麼 叫MosaicML MosaicML 它收購了它們之後呢 它們就有了這個做大型源模型的能力 然後它們這次就做出了DBRX 那這個DBRX呢 它的參數大概是Grock的40% 但它的表現就是比Grock還好這樣 那當然然後它就變成了就是現在的這個State of the Art的Open LLM 但是當然啦 就是我們這些比較呢 全部都是用這些大家常用的這些LLM的Benchmark 那你如果是科技上的聽眾 你應該聽到煩了 就是我很常說這些Benchmark其實真的沒有那麼好
(22:09~23:09) 所以說我覺得這邊的排名呢 大家也是參考一下就好了 但是我自己也是覺得大致上排名應該是這樣沒錯 那開源模型這邊呢還有一個很酷的模型出來了 叫做Jamba 那這個就是一個Transformer加Mamba加MOE的architecture 那這邊啊 我覺得就比較技術一點 但這邊其實是很有趣的 我自己是覺得 然後這是我們人類第一次有一個比較大規模 比較production grade的State Space Model的測試 那這邊啊 我覺得就等到下一次我們有比較多時間 我們再來做一個Technical Deep Dive 把這邊的技術都講一講 那目前啊這邊還沒有特別需要立刻去講解的必要 因為我覺得這是一個很棒的嘗試 但是目前還沒有算是有很大的影響出來 那最後呢 最後呢在閉源模型這邊呢就只有一個更新 就是Claw 3 Opus變成了最新的LLM王者了 就是他終於把GPT-4T給打敗了
(23:09~24:09) 那有聽我的Podcast就知道 我原本就是覺得Claw可能就是跟這個GPT-4差不多 然後可能比他爛一點點這樣 但沒想到呢現在一樣他是跟GPT-4差不多 但是他是比GPT-4好一點點了這樣 那這個比較的基準呢是我覺得最公平的一個benchmark 也就是這個Opus跟GPT-4T他們在Chatbot Arena的成績 這個Chatbot Arena就是大家很多人很多人進行盲測投票出來的結果 所以說我覺得跟其他的benchmark來說是比較可信的 那除了這個Claw 3的Opus變成王者以外 他們Claw 3還有其他這個size的模型嗎 他們最小的那個模型叫做Claw 3 Haiku 那這個Haiku最近也是討論度非常高喔 大家都覺得這個Haiku是CP值最讚模型 因為他們發現這個Haiku他不但比GPT-3.5強 他還比GPT-3.5便宜非常多 所以說他的這個CP值真的是最高的
(24:09~25:11) 大家都覺得他很好用 那我這邊講的便宜不便宜當然是指API的價格啦 所以說就是可能對於有在build這個LLM的APP的人 會比較有感的一個這個價格這樣 那一般的使用者呢就是應該就是用Sony 或者是你訂閱的話就是用Opus 好的那前面的話題就大概聊到這邊 我們接下來呢就進入今天的正題 就是這個人形機器人Humanoid Robot 那其實很多人在最近就在這個X上面就是說 2024年呢是The Year of Humanoid 人形機器人之年 或者你說這個人形機器人的元年喔 因為從年初到現在呢這個人形機器人他的發展 真的是太快了 從最一開始就是年初的這個Tesla Optimus Gen2的出現 嚴格來說應該是去年12月 但是差不多那時候嘛 那這個Optimus Gen2呢我們看到他現在已經可以拿起一顆蛋了
(25:11~26:13) 他的這個手指的細膩程度也大幅的上升了 是變得很厲害 然後再來呢就是引起很多人討論的一間新創公司 叫Figure AI 他們也展示了很多他們機器人的update嘛 從最一開始的他們可以自己泡咖啡到現在 他可以聽得懂人類講的話 因為他們接了這個ChatGPT 嚴格來說是GPT-4 他們接了GPT-4之後可以聽懂人類講話 可以看得到東西 然後可以去幫人類放就是把碗盤歸位這樣 然後其他的比較少人在討論的也有Google的這個Robotics Transformer 然後還有一些像是這個Mobile Loja這樣子的專案 那反正呢我覺得很明顯的可以看到就是大家已經很認真的看待人型機器人這件事情了 然後尤其是在AI的投資領域呢 Embody AI當中 也就是這個有實體的AI當中 或是你可以把它想像成就是AI機器人 在AI機器人當中呢 人型機器人已經無庸置疑的變成了大家的焦點這樣
(26:13~27:13) 那我覺得這個就跟前兩年兩三年前是不太一樣的 那個時候很多人還會在講說什麼 機器人就造就是 你就為了一個應用造特定的機器人就好了 為什麼要造一個人型機器人 你想要洗碗就造一個洗碗機就好了 你想要搬東西你就造一個機械手臂就好了 你幹嘛要造一個人型的機器人讓他做所有事情呢 一個人的形狀一個人形態的一個機器人呢 他搬東西不會比一個機械手臂強啊 但是我覺得這種論點在最近真的是已經沒有聽到了 因為就是AI的發展很快嘛 最近這一兩年然後大家也發現說 照這個趨勢呢 我們很可能可以造出一個通用型的人型機器人 就是可以讓他學會做任何事情任何人類做的事情 那這種情況之下呢 一個人的形狀是最好的 因為我們這個世界就是為人設計的嘛 我們所有的按鈕開關 所有的室內的這個設計 全部都是為人類而設計的
(27:13~28:16) 那今天我們快要有一個可以通用的AI模型的時候 我們一定要把這個AI模型放在一個人型機器人裡面 他才可以幫我們做到最多的事情嘛 那如今呢人型機器人已經成為AI研究領域最熱門的一個領域了 我們的這個AI一哥NVIDIA當然不可能錯過 那NVIDIA呢就是在上禮拜的GTC大會之中 對我來說是上禮拜對你們來說是上上禮拜這樣 他們在這個GTC大會之中呢 發表了很多關於這個AI機器人的update 那我覺得我現在就先幫大家整理一下NVIDIA在AI機器人這邊做的事情 尤其是人型機器人這邊做的事情 因為他們真的是做了很多 然後之後呢我們再來討論一些比較高層次的問題 這些比較大方向的問題 那首先呢這個我覺得要講到NVIDIA在人型機器人這邊的努力呢 我們要先從他們在這次GTC大會的這個GTC大會 我們先從他們在這次GTC大會全新發表的這個Groot Foundation Model 我接下來講了很多東西
(28:16~29:16) 有一些是這個GTC大會他們新發表的東西 有一些是他們原本就有在做的東西的一個小更新這樣 那這個Groot呢是一個全新的東西 這個Groot呢他是寫作GR00T 他中間那兩個O其實是0這樣 那他的全名呢是Generalist Robot 00 Technology 那這個Groot是什麼東西呢 我覺得先從一個非常白話的角度來解釋的話 你可以把它想像成一個裡面充滿了一個基本人型機器人知識的人型機器人大腦 那基本人型機器人知識是什麼呢 基本上就是一個你想一個人型機器人會對於了解這個世界所需要的知識 就是包括怎麼辨識物體啊然後怎麼做一些基本的事情這樣 那從專有名詞來看呢 NVIDIA是把Groot稱作一個General Purpose Foundation Model for Humanoid Robot 那這是什麼意思呢 首先這個Foundation Model我們是把它稱作一個基礎模型
(29:16~30:16) 我不確定中文是不是這樣翻啦 但你聽英文的名字你就知道 他是一個算是一個墊腳石的一種模型 他是一個基本的模型這樣 那他就是經過非常大量的資料做我們所謂的預訓練 就是用非常大量的資料訓練過一輪之後 我們得到了這個模型 那我們用的資料是非常大量 而且是跨非常多不同的領域的資料 所以說這個模型通常會就是很多事情都會做一點點 然後都也可以從這所有事情之中呢 Generalize出一些基本對於世界的理解 那有了這個什麼事情都會做一點 而且對於世界有基本理解的一個模型之後呢 我們會再進行一些其他的fine tuning 這些post training的部分 再去持續的加強這個模型在某一些特定領域的能力 或者是我們想要讓他在身上 我們想要在他身上看到的特定的表現這樣 那舉一個大型語言模型的例子呢 就像是臉書的拉馬模型對吧
(30:16~31:18) 臉書的拉馬2 他就是一個Foundation Model 他什麼語言都會講 然後他什麼事情都會做 你要叫他寫code也可以 你要叫他寫一首詩也可以 你要叫他回答一個基本的問題也可以這樣 那之後呢 有了這個Foundation Model 有些人會再把他根據他們的需求去tune成其他的模型 像是你想要有一個寫code的模型 你就再給他更多的coding的資料 把它tune成一個叫做code拉馬 那你想要加強他某一些特定的語言的能力呢 你也可以就是再train這件事情 就像是台灣有一些人有train這個Taiwan拉馬對吧 就是讓他更懂這個台灣的文化 台灣的用詞 那這個Groot呢 他就是機器人的Foundation Model 那這邊雖然說這個NVIDIA沒有公開太多的消息 我這樣講太客氣他們了 他們幾乎沒有公布什麼消息 他們只有跟大家說這個Groot 他的input output的模態大概有哪幾種
(31:18~32:19) 然後他是怎麼樣被訓練的whatever 那我們不知道這個模型他能做什麼事情 而且說真的NVIDIA其實也還沒開發出這個模型 所以他們搞不好真的沒有什麼太多可以share的 但是我覺得他們想做的事情呢 很明顯就是他們想讓這個Groot Foundation Model 就是可以做基本上一個機器人 人型機器人會做的一些基本所有事情 就是你叫他拿起桌上的這個水瓶 他就會這樣做 然後你叫他把這顆球踢到門內 他就會這樣做這樣 然後我想他們應該也是可以generalize到 各種不同的人型機器人上面 因為我們知道人型機器人很多種很多公司都在做 那每一家的其實都不太一樣 他們的關節的地方他們的這個手臂的長度 他們的這個關節的數量也都不一樣 那我是猜說這個Groot呢 他經過一些基本的tuning 他就可以在任何的人型機器人上面運作了 因為就我所知這個NVIDIA他們自己沒有在做人型機器人
(32:19~33:22) 就是他們沒有在設計這個人型機器人這個硬體出來 他們是跟很多的機器人公司合作 那你開發這個Groot一定要在就是各種機器人上面都可以運作嘛 那我覺得這個Groot這個模型呢 如果真的有做到我剛剛說的這幾件事情的話 他就真的是一個general purpose的humanoid foundation model了 因為他就跟這個大型圓模型的 foundation model一樣 大型圓模型的 foundation model 他什麼事情都會做他會翻譯會寫詩會寫code嘛 但是沒有每件事情都沒有做到非常專精 那這個Groot foundation model一樣 他會拿起水瓶會踢皮球會搬東西嘛 然後這個LM的 foundation model 他每一種語言都會講但是並沒有每一種語言都精通嘛 那這個就對應到Groot他每一種人型機器人都會操控 但他並沒有特別為每一某一種這個人型機器人設計這樣 也就是說未來當這個Groot真的開發完成了 這些人型機器人公司呢
(33:22~34:23) 就可以先把這個Groot tune成他們這個的自己機器人專屬的一個模型 然後tune完了之後呢 再根據你想要讓他做的事情 再去把那幾件事情tune成這個機器人最擅長做的幾件事情這樣 那我也要再次重申就是NVIDIA還沒做到這件事情 Groot還不是一個真的是一個已經現成已經可以用的這個general purpose foundation model 他們現在他們其實為了Groot創立了這個叫做GearLab 他是可能三個月前才創的嗎 這個Lab三個月前才創出來他們不可能已經有Groot了這樣 但我覺得距離他們真的有Groot這個模型呢 就是應該說有一個可以真的可以使用的production level的Groot模型 因為嚴格來說他們搞不好現在已經有Groot了 但只是這個Groot只是一個什麼東西什麼事情都做不好的Groot 那距離他們有一個production level的Groot 我覺得其實應該很快就會來了 為什麼呢
(34:23~35:25) 因為他們有超厲害的各種訓練Groot的技術 這邊有很多很多技術 但我們先從最重要的開始講起 最重要的當然就是NVIDIA的Omniverse 這個Omniverse平台它有一個非常高擬真 然後有非常好的物理模擬的一個3D的環境 在這個環境中因為它真的是模擬的跟現實世界太像了 所以你可以在裡面做很多輕鬆的做到 很多你現實世界中很難做到的事情 就是比如說你可能要測試一個產品 你就把這個產品它所有的零組件全部匯入Omniverse 然後在Omniverse裡面把這個產品組起來 然後在這個Omniverse裡面測試 這樣你就不用在現實世界中去把這些零組件組起來 然後實際的去用勞力去測試這樣 因為Omniverse的環境跟現實世界是基本上沒差的 那你也可以做到很多其他的事情 像是你可以就是直接把你的工廠給模擬出來 然後在你然後測試一下你的工廠這個運作可不可以順利
(35:25~36:26) 或者是你也可以在裡面做這個3D動畫這樣 那它可以做很多事情 反正它最主要的就是它是一個高擬真 然後有好的物理模擬系統的一個環境這樣 那基於這個Omniverse平台呢 這個NVIDIA有開發出很多很多不同的應用程式了 有些可能是用來做動畫 有些可能是用來測試什麼東西 那為了這個機器人呢 NVIDIA有做一個環境叫做ISAAC SIM 這個ISAAC SIM就是專門為了機器人打造 為了訓練機器人 或者你說讓機器人自己訓練的一個環境 那這個環境呢並不是專門為這個人型機器人設計的 是任何機器人都可以這樣 那你就當你要訓練一個機器人的時候 你就在ISAAC SIM裡面設計出一個就是 你機器人會運作的一個場景這樣 然後你就直接讓你的機器人在裡面 不斷的試錯不斷的進行訓練 就是假設你今天要讓機器人學會上樓梯 你就建出一個樓梯的場景 然後把機器人放在裡面
(36:26~37:27) 讓他不斷的上下樓梯上下樓梯 然後他可能會跌倒什麼東西 他會再透過這個reinforcement learning的方法 一次一次的去調整他的模型 那同時呢這個ISAAC SIM也有支援這個GPU加速 廢話就是這個NVIDIA的東西怎麼可以沒有GPU加速 所以說你是可以加速這個simulation 然後同時你可以讓這個機器人使用影分身之主 就是你分身出幾百個甚至上千個這樣子的機器人 然後在同一個環境中不停的同時進行訓練 那這一千個機器人他們訓練出來的這些經驗呢 當然會互相溝通然後會不斷的累加這樣 不斷的累積 那就變成你可以說精神時光污啦 就等於是你已經把時間加速了一千倍 那我這邊必須要再次強調就是 Omniverse ISAAC SIM的這個環境呢 他真的是非常非常高擬真的 就是擬真的連這個ray tracing都有
(37:27~38:27) 就是這個光影怎麼樣變化啊 然後各種小細節真的都做得沒有破綻 所以說這個機器人在Omniverse ISAAC SIM裡面訓練 真的就跟他在現實世界中的場地去訓練是一樣的道理 那這個ISAAC SIM其實不是新的東西啦 就是在這之前就是NVIDIA就已經有了 但是這次GTC他們有發表一個新的東西 叫做ISAAC LAB 那這個ISAAC LAB呢就是ISAAC SIM裡面 專門為了Humanoid Robot人型機器人所設計的一個訓練環境 那他的概念基本上就跟ISAAC SIM一樣 但他就是專門為了人型機器人所設計的 那麼你可想而知的就是你在使用這些ISAAC SIM的環境 訓練一個GROOT這樣子的模型的時候 一定會需要非常非常大量的算力對吧 而且這個算力要求並不是非常單純的一種算力喔 你就是會需要同時運用很多種不同的算力這樣
(38:27~39:29) 我們在英文裡面會把它稱作Heterogeneous Compute 那會這樣子就是因為比起你在訓練一個大型語言模型 就是所有東西都是Text 然後你也不會需要一個模擬的環境出來來訓練大型語言模型嘛 所以說你的這個算力要求可能就比較單純一點 但你今天是在訓練一個機器人 然後是在ISAAC SIM裡面訓練的話 你跑ISAAC SIM的這個算力跟你在Update這個模型的參數的這些算力 其實是不太一樣的 你會同時需要用到可能OMNIVORS的運算OMNIVORS的伺服器 跟運算AI的伺服器這樣 那這個就比可能訓練一個大型語言模型的這個算力是更複雜一點 雖然說嚴格來說啦 就是這個運算大型語言模型呢 一樣也是會用到這個Heterogeneous Compute 但是就是它實在是沒有像這個訓練機器人這麼複雜這樣
(39:29~40:30) 反正呢就是你在訓練一個AI機器人的時候 你會真的會需要用到很多很多種不同的電腦 然後就是用很多很多種不同的方式去安排這個訓練工作這樣 所以說呢他們專門為這個工作的安排 訓練工作的安排設計出了一個軟體 或者你說一個平台叫做OSMO 那這個OSMO在做的事情呢就是 一個工程師呢他就可以使用這個OSMO 很輕易的在NVIDIA的可能 用來訓練AI模型update AI模型的這些DGX的System 跟可能在跑Omniverse的這個OVX的System 在這兩者之間呢 很好的去安排他的訓練工作 那這個也是NVIDIA這次在GTC新發表的東西這樣 那反正我剛剛講了這麼多 從Omniverse講到OSMO 都是這個幫助Groot訓練的一個非常好的基礎設施這樣
(40:30~41:31) 所以說NVIDIA在訓練Groot這邊真的是有很大的優勢 那我們知道講到AI訓練是一部分 推論又是另外一個部分 推論就是使用這個AI的部分 當這個AI已經train好了 我們使用他的這個部分 那推論這邊呢NVIDIA當然也是沒有放過 他們這次GTC有發表了新的這個JSONTHOR晶片 JSONTHOR晶片呢就是專門為了人型機器人設計的一個邊緣運算晶片 意思就是說他是最後會實際去裝在這些人型機器人上面 然後實際去跑Groot這個模型的這些晶片這樣 那這些晶片呢現在都是也都是 就是follow他們最新的這個Blackwell的晶片architecture 那你如果不知道這個Blackwell的架構是什麼 你就去聽上一集就好了 我幾乎花了整集在講這個東西 所以這次NVIDIAGTC他跟大家說的事情是什麼 就是首先機器人的大腦我們有了 我們應該說我們有在開發了一個叫做Groot的大腦
(41:31~42:31) 那這個訓練這個大腦的訓練場呢 我們已經有了就是這個NVIDIA的Omniverse 尤其是這個ISAAC SIM裡面的ISAAC LAB 那我們要就是實際的去訓練這件事情的算力呢 以及這個算力的安排呢 我們也有了我們有OSMO 我們有DGX我們有OVX 那這個機器人訓練這個大腦訓練完之後呢 實際要跑的這個晶片呢 我們也有了就是這個Jetson Thor的晶片 那我們只缺什麼 我們只缺機器人的身體本身而已 或者是換言之啊 就是你今天是一個機器人公司 你只要帶著你的機器人身體他的設計 帶給NVIDIA NVIDIA就可以給他一個靈魂 就可以讓他動起來而且讓他聽你的話 那有哪些機器人公司在跟NVIDIA做這件事情呢 我覺得基本上你想到的都有 就是除了TESLA OPTIMUS以外 除了最有名的這一間以外 你想到的都有 包括這個BOSTON DYNAMICS
(42:31~43:34) 波士頓動力 包括FIGURE AI 我前面講的就是最近很紅的這一間 包括大陸的這個UNITREE 跟小鵬小鵬好像也有這樣 然後還有這個AGILETY ROBOT 最近也是挺紅的一間 當然啦他們用到的NVIDIA技術 可能每一間都不太一樣 可能有些人只會用NVIDIA的這個 OMNIVERSE跟OSMO在做訓練 有些人呢是想要跟NVIDIA一起開發這個Groot的大腦 然後有些人呢可能是想要這個JESSE AND THOR的晶片whatever 但反正就是NVIDIA已經把這整個生態系建出來了 那你只要帶著你的東西來找NVIDIA就好了 NVIDIA基本上就是除了機器人本身的設計以外 你要什麼東西都有這樣 那這邊其實我也不要講得太絕啦 就是我不確定NVIDIA有沒有自己在設計這個機器人的硬體的部分 這邊我就不知道了 但就我所知是沒有
(43:34~44:35) 那我自己看到NVIDIA有這麼多對於HUMANOID ROBOT的這些解決方案 我真的覺得是非常好的一件事情 我覺得它會加速這個人型機器人的發展進度 因為首先他們提供這麼好的訓練設施 讓有一些可能Robot的新創可能只有機器人本身 跟只有機器人的大腦就是這個AI的軟體 他們只有這些東西的人也可以很快的去train這個機器人這樣 所以說當然這個會加速機器人的發展 然後另外一點就是我覺得NVIDIA甚至可能會開源Groot 他們當然是沒有講到這件事情 但我覺得他們有可能會做這件事情 因為我自己是這樣覺得啦 就是NVIDIA他們開源Groot對NVIDIA來說也是一個好事 因為他們沒有辦法靠Groot賺錢 他們沒有在賣人型機器人的 他們是在賣他們的computing他們的算力 那才是他們真正賺錢的business 所以對於NVIDIA來說Groot越來越好 然後越來越多人開始用Groot才是他們賺錢的方式
(44:35~45:37) 那你要怎麼讓這個東西變得越來越好 然後越來越多人用 當然就是讓它開源 所以就跟臉書開源他們很多的大型音樂模型 很多的AI研究是一樣的道理 他們不是靠這個東西賺錢的 不是像Google Google真的是靠Gemini在賺錢 臉書沒有在靠LAMA賺錢 但是對於臉書來說 LAMA越來越好或者說AI越來越好 對於他們真正賺錢的事業也就是這些社群媒體是好事 然後我覺得NVIDIA加速人型機器人的發展這件事情 我覺得還有第一點的延伸 就是說這些新創公司只要帶著他們的人型機器人跟他們的大腦 甚至連大腦都不用 他就可以去NVIDIA這邊讓這個機器人注入靈魂 那其實我覺得這不只會造福現在很多可能資金比較少的這些新創公司 還可以讓新的新創公司出現喔 我覺得這個就有點像是 其實就蠻好笑的
(45:37~46:40) 蠻好笑的就有點像是當初TSMC造就了NVIDIA這樣子的感覺 就是那個台積電他就是很創新的用這個Foundry的business model 就是他們只代工不會去設計這件事情 就是有了他們這個business model NVIDIA這種fabulous的公司design的公司才可以出現嘛 因為NVIDIA他們自己沒有製造晶片的能力 但他們設計的能力很強 那沒有台積電幫他們製造的話他們也不會出現 雖然說NVIDIA現在的市值已經好幾個台積電了 反正今天就是跟大家介紹一下NVIDIA在機器人這邊他們在搞什麼 大家不要小看他們他們搞很多東西 但是就是講回來了 在帶領這一整波人型機器人的趨勢的公司 還是要回到那幾家就是特斯拉嘛 然後還有這個一些新興的figure AI
(46:40~47:41) 跟一些可能比較舊時代但是現在就是拼命要轉型的像是Boston Dynamics 然後我今天講的所有的這些人型機器人 他們全部都是AI人型機器人 全部都是machine learning base的人型機器人 他們跟傳統的機器人其實是有一點不一樣的 那如果你想要清楚的知道這兩者的差別在哪裡 你可以去聽科技浪的EP22 我有滿就是完整的解說這樣 好啦那今天的科技浪呢我覺得就先聊到這邊 因為我在錄音的同時呢 我其實明天早上要趕早上的飛機要飛去日本 所以我現在其實已經很晚了啦 已經大概12點半了吧 所以我的行李都還沒整理 我應該是要趕快去整理行李這樣 那最後一樣如果你喜歡今天這集節目 你可以幫我五星評分然後可以留言跟我互動一下 你叫我開頭說瓜我就說瓜了好不好 那同時也感謝今天的贊助商天下雜誌 有想要試用這個每日報APP的
(47:41~47:53) 就直接使用資訊欄裡面的連結去註冊就行了 我們科技浪的專屬連結可以讓你免費試用兩個月 那最後呢就祝大家有一個愉快的一週 那連假好好放鬆好好玩
