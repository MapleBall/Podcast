(00:00~01:00) 【音樂】 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式 帶你了解時下最火的科技話題 本集節目由Speak贊助播出 那我覺得台灣人的英文聽說讀寫裡面 通常最弱的就是說這個能力 那這並不是因為台灣人有什麼問題喔 並不是什麼天生口語就比較弱之類的 我覺得純粹就是因為口語的練習資源 本來就是比較不足的 因為你看,你如果要練習英文聽力的話 你就去聽一堆英文Podcast就好了 你如果要練習英文寫作的話 你就去寫一堆英文文章就好了 你如果要練習英文閱讀的話 你就去買一堆英文小說來看就好了 這些英文學習資源都是隨時隨地都可以取得的 而且基本上是用之不盡 你隨時想要練習都可以,想練多久都可以這樣 但是口說呢,你必須要找一個人來跟你練習
(01:00~02:01) 那這件事情就相對困難很多嘛 就儘管你不是實體界面 你是在網路上約這個課程 你也是要去跟對方喬時間 然後也是要找到一個可能場地啊設備啊 是可以做這件事情的 但是現在有了大型元模型之後呢 這個英文口說練習資源不足的問題 已經被解決了 因為這些大型元模型 他們基本上已經通過圖靈測試了 也就是說他們講出來的話 已經跟一個人講出來的話是沒有什麼太大差別了 一般人是分辨不太出來的 而且你任何的話題都可以跟他們聊 然後隨時隨地都可以跟他們練習口說 所以說這個口說練習資源不足的問題 真的是已經解決了 但是呢我必須說 並不是隨便一個AI都可以讓你練習口說 因為真正好的練習 我覺得是在你講完了之後呢 你可以得到一個反饋 知道你哪裡講得好,哪裡講得不好 這樣子你才會進步的最快 那我覺得Speak 這個英文口說APP 就把這一點做得非常好
(02:01~03:01) 那在這個Speak的APP裡面呢 你可以跟AI聊任何的話題 它有非常多他們預設的模板 預設的情境,預設的角色 從這個生活上面的旅遊的啊 點餐用的啊 到商用的,面試的啊 跟同事聊天的啊 這些所有的情境他們都有 那如果你真的找不到你想要練習的情境的話 你也可以自己去設計 自己給AI一個角色,你一個角色 然後情境一個context 然後就可以開始練習了 那在整個練習的過程之中呢 這些所有的AI背後 都是有OpenAI的語言模型 作為他們的大腦 所以這個模型的品質呢是不用太擔心的 那你在跟這些AI聊完天了之後呢 Speak會深入的幫你分析說 你哪一句話講得不太好 或是怎麼講會更好 然後也會列出一些你需要再加強練習的句型 把他們變成一堂一堂的微課程 你還可以再點進去做複習 所以我覺得你透過Speak來練習英文口語 真的是會進步非常快
(03:01~04:02) 那這也是為什麼發跡於舊金山的Speak 可以快速成為韓國的第一名英文口說學習app 那如果你也想要使用Speak的話 正好他們現在有一個非常好的折扣 就是年訂閱4折的優惠 這個真的是一個非常好的折扣 所以說我覺得 如果想要學習語言的話可以參考一下 那我會把這個Speak app的連結 直接放在本集的資訊欄裡面 大家點進去就可以下載了 或是你從這個App Store裡面 也可以直接下載 也是可以使用這個4折優惠這樣 本集的配就要這邊結束 謝謝Speak的贊助 那這禮拜的科技量呢 我想跟大家聊一個我想聊很久的話題 也就是這個State Space Model 那我想聊很久呢 就是因為這個話題我覺得它很有意思 它就是那種還不確定會不會成功 但是一旦成功了 就會改變一切的那種技術 所以說我非常喜歡聊這種技術 因為我覺得這些東西 如果你在非常初期就關注了 那他們當他們要開始崛起的時候 你就可以很快的承上這一波浪
(04:02~05:02) 這就是科技浪的初衷嘛 就是帶大家承上這個科技的浪潮 所以說這些東西是 我覺得是我有義務要跟大家講的 但是呢 我一直以來都沒有找到一個 很好的機會來聊它 因為就是它 雖然說它有很大的Promise 有很大的這種可以改變一切的潛力 但是一直以來它都沒有 佔到很大的新聞版面 然後也比較少有那種大新聞出來 所以說我基本上 那個禮拜有什麼大新聞我就是會 還是先講那些大新聞為主 就是有TESSA的股東會我去講 TESSA然後有這個Apple的 發表會我去講Apple但是呢 這個禮拜我覺得沒有什麼太 大的新聞所以說我覺得 很適合來聊一下State Space Model 然後確實State Space Model這邊 也是有一些近期的發展 可以聊一聊所以說我覺得現在這個 Timing是蠻Perfect的 但我覺得在講之前啊我想 先跟大家聊一些最近的一些 AI新聞那首先是 來自Anthropic的一系列發表
(05:02~06:02) 他們在上禮拜呢不但發表了 一個新的模型然後也發表了 一系列他們這些UI 上面的一些小功能 挺實用挺酷的一些小玩意 那首先這個模型的發表 他們是發表了一個叫做 Clawed 3.5 Sonnet 的模型這個3.5 在講就是它是第幾代的 模型那在這之前最新一代 是Clawed 3然後第三代 所以說3.5是 最新一代的這樣然後 這個Sonnet這個字呢 是指的就是這個模型的 大小那通常這個Clawed 的模型都會有三種大小 一個是最小的叫做Hiku 那中間的就是Sonnet 然後最大的是叫做Opus 所以他們這次發表的就是 第三點五代最新一代的 中階模型這樣那 這個模型有多強呢 依照Anthropic他們自己的Benchmark 的講法他們是說這個 3.5 Sonnet 現在是世界上最強的模型 它比GPD-4O的成績都還高
(06:02~07:02) 一點當然也是有輸的部分 但是普遍來講它在蠻多 Benchmark上都是比GPD-4O 更高但是你如果看這個Chapbar Arena 的結果呢其實還是 GPD-4O高一點點 這個Chapbar Arena呢就是網友們 盲測出來的結果盲測出來 的一個E-Low rating這樣然後 你如果看網路上的一些聲量 的話我覺得好像 稍微比較多一點點的人 是覺得Clawed 3.5 Sonnet是比較 強的但是 也是有一些人說其實他們也沒有 比GPD-4O好到哪裡去這樣 所以說我覺得綜合來看啦 這個Clawed 3.5 Sonnet 應該就是跟GPD-4O是差不多等級的 模型這點我們是很確定的 但究竟誰比較好 我覺得這邊就大家自由 行政吧因為其實真的 就算有差也只有差一點點 那真的不重要 這邊真正重要的呢其實是 一個討論聲量超高的一個新 功能叫做Artifacts Artifacts呢基本上就是你在 跟Clawed聊天的時候你如果
(07:02~08:02) 叫他寫到code不管你是明確叫他寫 還是你間接的讓他寫到code 這些code都會被放在一個 獨立的視窗這邊展示 然後如果這些code正好是可以被 就是被Render出來的 被展示出來的話就比如說 是前端的code像是HTML CSS JavaScript 那他就會直接把你的code給 Render出來像一個瀏覽器一樣 也就是說呢你能做到的事情就像是 最直接的你叫他寫一個小 遊戲你叫他寫一個Flappy Bird的遊戲 一個俄羅斯方塊的遊戲 或者是一個貪吃蛇的遊戲 那沒有Artifacts功能的一個聊天機器人 像是ChargePD或者是 之前的Clawed他可能就是 會把這個程式碼一併的 放在這個回答之中給你嘛 就是放在你們的聊天記錄裡面 但是有Artifacts的話這個程式碼 就會被獨立放在一個視窗之中 然後同時因為這個遊戲呢他可能 是用JavaScript跟React下去 寫的所以說他是可以被 ArtifactsRender出來的 所以你直接在這個獨立視窗裡面 可以直接玩這個遊戲了
(08:02~09:02) 你可以自由切換這個遊戲的畫面還有 你的Code的畫面這樣子 那這個Artifacts他技術上面是蠻單純的嘛 他就是一個內建的 瀏覽器可以Display網頁 然後可能可以做一些簡單的版本控制這樣 但我必須說他 真的是一個很聰明然後 很漂亮的一個UI設計 然後在某一些應用上面呢 確實是有蠻大的體驗 的提升的那我這邊整理了一些 我覺得蠻有價值的應用給大家 來參考一下 首先第一個呢就是把一篇非常長的 財報或者是論文變成一個 互動式筆記 所謂的互動式筆記呢就是指 他把所有的內容整理成 幾個不同的分頁 然後每個分頁裡面有很多 Bullet points的內容然後還有一些圖表 然後那種圖表都是那種 你這個滑鼠Hover過去 他會顯示出一些詳細數據 之類的就是你實際是可以跟他 互動的然後也有更互動式的 比如說有一些按鈕啊 一些拉桿啊 可以去C去按去拉
(09:02~10:02) 然後改變那個結果這樣子 然後除此之外還可能會有一個小測驗 就是一個小選擇題 來考你這整個 論文裡面的內容這樣 我不知道大家有沒有看過一個網站叫做Brilliant 他們就是專門在做這種 STEM學科的互動式學習 微課程 Artifacts呢 基本上就是你丟給他任何論文 然後就變成一個互動式學習 Brilliant style的微課程這樣 那我覺得這個功能真的很酷 因為他對於你吸收知識的效率 絕對有非常大的幫助的 你看這種互動式的筆記 絕對是比你叫一個Chart GPT幫你總結幾個Bullet points 有用非常多對不對 那原本的Chart GPT 你其實要他做這件事情 應該也是做得到 就是你Prompt打詳細一點 然後叫他產生這種互動式的筆記啊 然後他可能就丟給你一個HTML 然後再自己把這個HTML file給存下來 然後在你的browser裡面開啟 你也是可以做到一樣的事情 但是這個Artifacts就立刻Render在你眼前 這個就是使用者體驗上是非常好的
(10:02~11:02) 然後第二個我覺得很有價值的應用呢 就是Prototyping 尤其是在網頁開發這一邊 就比如說你現在是一個前端工程師 然後你想要很快的做一個 新的網頁 新的頁面的一個prototype出來 那這個時候呢 你就可以直接用Clanget Prompt 然後直接把它Render出來 那這樣就是非常快非常舒服嘛 然後同時你如果覺得這個大方向 不太對的話你也可以很快的 迭代下一個版本 你就直接叫他改一些地方 或者是叫他重新做一個 他就立刻重新做出來一個給你看這樣 然後這個版本控制也會做好嘛 然後除此之外你也可以 給他一個condition 就是你可以先去找一個你理想中 的頁面然後丟給他 跟他說幫我做出一個這樣子的頁面 然後他就會參考你丟給他的圖片 做出來這樣 所以說我覺得這個對於前端開發 覺得是有幫助的 但是只僅限於prototyping的階段 之後你實際在開發的時候 你不可能透過artifact在開發的
(11:02~12:02) 因為你是沒有辦法在artifact上面 直接改直接code 然後他也只能一次處理一個 一個file他沒有辦法一次 處理多個file 所以說你還是得用你的ID跟browser 所以你如果講這個 一個前端開發者 有artifact跟沒artifact的 productivity的差異我覺得不會到 很大啦說真的 大不了就是最一開始 的那個步驟可以比較舒服 一點點這樣而已然後第三個我覺得 蠻有價值的應用呢是你可以用 artifact來做一些簡單的生活 小專案像是 clod裡面的員工他們有一個人 就tweet了一個應用就是說 他是用artifact很快的做出 一個書桌的螢幕規劃app 就是你可能有很多不同 大小的螢幕然後你在想要 怎麼把他們排在一起是比較好的 所以你可以用這個app就是很快的 先排一下然後看一下這個layout 好不好這樣子那像是這種 小app就是他還蠻好 用的然後他也不難開發 但是沒有人會特別去開發
(12:02~13:02) 他你在app store裡面你應該找不到 這種app因為這個賺不了 錢的沒有人會特別去開發這種東西 然後就算你自己有開發能力 你也應該也很懶得自己去 自己去把這個東西給寫出來 因為你可能你買了一個螢幕 你只需要規劃那一次嘛 你不會常常使用這個東西 但現在有了clod artifacts 你就可以很快的把這個東西 做出來我想要另外一個例子就是 比如說過年期間大家打麻將 還是玩遊戲在賭錢 那這時候賭錢通常都要 有一個記籌碼的東西 然後有時候你們沒有真的 籌碼然後也不想拿真錢 出來在那邊一來一去的麻煩 那這時候你就可以用artifacts 做一個app來 記錄每個人的籌碼 然後你也可以就是叫他改變 一下你的UI把它做得漂亮一點 然後甚至你在給籌碼的時候 還有那個動畫有沒有 你可以把這些東西做出來 那這個東西就真的是沒有artifacts 的話這個app永遠都不會被開發出來 因為大家就拿一張紙
(13:02~14:02) 記一記就好了嘛 但是像有artifacts就 一個prompt這個東西就出來了 何樂而不為呢 所以我真的覺得artifacts是蠻酷的一個功能 我應該不會常常用 但是如果有用到的話我就會覺得 哇好舒服啊這樣子 但我覺得它還是有些缺點啦 那也就是因為這些缺點讓它變成 只是一個酷功能而不是一個 真的可以大幅提升生產力的工具 那這些缺點就像是 首先我剛剛有說了 你沒有辦法直接改它寫出來的code 然後你如果就是 口頭叫他改某一些地方的話 他整篇code都要重寫 儘管他只有改裡面的一行 他整篇都要自己重寫一遍這樣子 然後最後一個就是他只能執行 一個file的程式碼 他不能有一個資料夾然後裡面寫 很多不同的file然後 就是直接跑全部這樣他沒有辦法 他只能跑一個 那就是因為這些事情呢就讓他 沒有辦法真的成為一個 前端工程師的開發工具 因為這個前端工程師你
(14:02~15:02) 在開發一個網頁你不可能 一個file啦你一定就是可能 這個網頁的骨架就是用 一個HTML的file然後網頁的功能 就是用JavaScript跟 React可能很多個file這樣 然後你的網頁的styling也就是 這個CSS的檔案也是 一個file所以你是很多這種 file加起來才變成一個網頁 你不可能全部的東西全部code 全部都塞在同一個file裡面 雖然嚴格來說你可以這麼做 但是沒有人會這麼做 因為這個就是非常非常 糟糕的engineering practice 然後同時你不能直接改他的code 然後每次就是叫他改一個東西 他就要全部重寫這個也讓 這個迭代速度真的是太慢了 慢到無法接受然後你 也沒有一個terminal可以使用所以說 你如果想要用到一些他們沒有 pre-installed套件的話 你就做不了了 所以說我真的覺得這個artifacts對於 已經有在用AI寫code的這種 前端開發者來說 真的是沒有什麼太大的用處啦 那當然我這段聽起來
(15:02~16:02) 有點像是在雞蛋裡挑骨頭嘛 因為說真的這個artifacts 出來Anthropic原本就沒有說 他是一個為前端開發者 設計的工具他甚至他的 這個這個announcement的block post 前端開發這個字完全沒有提到 他就是說這是一個酷酷的 可以display更高互動性的 這種小功能好所以說 這當然他這邊沒有支援 那麼多可能是他們原本就沒有 再這樣子想了他們覺得這個是 可能ID要去做他們的extension 他們的這些事情這樣子 那我會特別講這個part 是因為我是有看到 蠻多的言論在講 前端已死啊或者是 前端工程師完全不用做事啊 這種我覺得蠻誇張的 這種言論好所以說 我覺得還是要把這段給講清楚 這樣好的那麼接下來呢 我們就進入State Space Model的討論 這個今天的主角 那我們接下來呢全部都把State Space Model 簡稱SSM好了這樣子比較好念 那我相信大家在這個 生成式AI爆發之後呢
(16:02~17:02) 一定常常有聽到transformer 這個字嘛那這個transformer呢 他在講的就是現在所有 主流的這些大型原模型 他背後的這個神經網路 的架構他背後的這個架構 呢就是一個transformer 不管是ChatGPT還是GoogleGemini 還是CloD他們全部都是 transformer based的那我們今天要 介紹這個SSM呢他也是一種 神經網路的架構但是他 跟transformer是截然不同的 架構那現在基本上沒有任何一個 原模型是使用SSM的 嘛但是這個SSM就像我一開始 所說的他有非常 高的潛力因為從一些初步的 研究跟理論上我們可以看出 他有機會解決掉transformer 的一大硬傷然後取代 transformer變成最主流 的神經網路架構好那我們先來講 講這個transformer的硬傷好了 他這個硬傷呢就是非常 惡名昭彰的大歐的N平方的 computational complexity 好那這個 這句話你如果聽不懂沒有關係我們 白話解釋一下白話來講
(17:02~18:02) 就是當你今天要丟進這個transformer 的文章長度增加了的時候 你的運算量是會暴增的 就是儘管你的文章長度 是線性的上升 你的運算量卻會是這個 指數型的上升更具體的來說 的話就是當你的文章長度提升 了X倍你會需要 使用到的運算量就提升了 X平方倍 假設你今天這個文章長度 提升了8倍的話你需要 做的運算量呢是變成了64 倍不是8倍喔 不過當然啦我這邊講的所有的運算 的提升啊在講的都只是 一部分的運算會提升 就是自注意力機制這邊的運算嘛 那他其實在 注意力機制之後呢 他這邊主要的運算呢是不會 提升的這麼快的沒有大歐的N 平方這樣子但是 注意力機制這邊的運算提升的這麼快 就已經足夠讓這個問題 造成很多人的頭痛了 因為儘管自注意力機制 只是這個整個模型運算的一小部分 這個指數上升果然
(18:02~19:02) 還是太恐怖了就是我剛剛 講的是8倍變成64倍 假設今天你的文章長度變成了 1000倍呢那你自 注意力機制這邊運算量會變成100 萬倍耶那儘管 他原本沒有很大變成100萬倍 但是變得很恐怖嘛 那這個印章就有點限制了 Transformer它的context length 你一次能丟進去的文章 的長度因為你長到一定程度 的時候這個Transformer的運算 量太大了會需要花很久的時間 才可以算出下一個字這樣 然後可能也會佔更多的 記憶體這樣所以說是 蠻讓人頭痛的那當然啦 最近這一兩年真的是大家都在 研究Transformer所以說大家 也是有研究出非常多可以優化 這個attention的time complexity 的一些方法 包括這些比較有名的像這個 flash attention group query attention然後一些kvcache 的一些方式啊 那這些東西我們今天先不要講 因為我們今天要講這個SSM 它如果真的成功了的話
(19:02~20:02) 它會凌駕在所有 這些attention的optimization 之上因為它直接把這個問題 給解決掉了或者更精準 的來說就是它本來 就不會有這種 complexity scale很快的問題 它的complexity呢 通常是這個大O的nlog n 或者是大O的n 之類的所以說就是 會有點接近線性 或是直接線性的成長 就是你資料上升八倍 你的需要的運算量就是八倍 不會多很多所以假設 今天這個SSM它在任何的 參數等級都可以表現的 跟Transformer一樣好那它 就會取代所有的Transformer了 因為它沒有這個天生的硬傷嘛 然後這也就代表說 所有的這些最厲害的大型 元模型包括ChadGBT, Cloud Gemini全部都要重train了 現在train的這些全部都 變成legacy你們要重train了 因為現在有這個新的更強的 架構了嘛那這也是為什麼說 SSM有這麼大的潛力因為他們
(20:02~21:02) 是真的有機會可以造成 一整個典範的轉移 把這個以Transformer 主宰的世界變成一個SSM主宰的世界 我覺得現在 就是聊SSM的一個非常 好的時間點 因為這個SSM它現在的發展的進程 基本上就是一個正要擴大 實驗規模的時間點 這個實驗的規模一旦 擴大到一定的程度 就可以非常明顯的看出說 這個SSM究竟有沒有比Transformer 更好,更具體來說 SSM是在去年年底 一篇叫做Mamba的論文出來 之後才開始爆紅的 在他們爆紅之後 各大AI lab 就開始做一些實驗 像Google他們也有做一些SSM的實驗 然後也有一些其他人在做 我相信其他人應該都有 在做類似的實驗這樣 然後也有一些論文被publish 不過這邊所有人在做的都是比較小 規模的實驗就是可能建一個 1 billion到3 billion參數的 Mamba來實驗一下看有沒有跟
(21:02~22:02) Transformer一樣好 在去年三月的時候 終於有了一個比較大規模的嘗試 這個嘗試是來自一間叫做 AI21 Labs的以色列公司 他們做出了一個模型 叫做Jamba 這個Jamba它其實也不是 一個純粹的SSM 它是一個SSM跟Transformer的 混合體 混合的比例大概是8比1 就是每8層SSM layer 會有一個Transformer layer 然後它的權重是示出來給大家看的 總共有52 billion的parameter 但它是一個MOE model 所以說它每一次在跑的時候 Active的parameter只有12 billion 那這個嘗試呢 我覺得可以算是SSM的第一次勝利 因為這個Jamba是蠻成功的 它跟差不多同樣等級參數的 Transformer model比起來 它的表現是差不多的 甚至有比較好一點點 然後它的throughput 就是你可以把它想像成 這個一個通道 就是你可以把它想像成
(22:02~23:02) 這個tokens per second 也就是它產生這個文字的速度 是其他Transformer base 模型的3倍 在同一個hardware上面跑是3倍快 哪會快這麼多呢?當然就是因為 它這個模型裡面 所有的Mamba layer都不會有 大歐的N平方的complexity 它只有那些少數的Transformer layer還會有這個毛病而已 所以說它真的是會比Transformer 模型快很多 這是第一次的勝利 第二次的勝利呢其實是在上一個月 有一間叫做Cartizia的公司 他們釋出了一個模型叫做Sonic 這個Sonic主要是在做TTS的 也就是文字轉語音 然後這個Sonic yes你猜到了 它就是一個SSM base的模型 那這也是為什麼Sonic 它現在是延遲最低的TTS 模型它平均的 延遲是135毫秒 也就是差不多0.1秒 左右也就是你打完這些字 然後按生成語音 然後0.1秒左右AI就會把這串文字 給念出來了
(23:02~24:02) 所以基本上已經是real time了 就是快沒有延遲了 而且這個Sonic它產生語音的品質 真的非常好喔 就絕對不輸其他那種Transformer base的這些TTS 真的是很讚 那他們在他們的官網也有放一個這個Playground 給大家玩大家可以去玩玩看 就是試試看不同聲音啊 讓他講不同的話啊然後看一下那個 品質究竟有多快 讓他講出來的品質究竟有多好 那除了讓大家實際體驗以外呢 他們當然也是有給出一些數據來支持的 他們是說這個Sonic 它的文字錯誤率呢 比一般的Transformer model是低了 兩倍但同時呢他們的 latency也是比別人好1.5倍 也就是說它平均 比別人快1.5倍就可以 產生第一個音了然後 同時呢產生完整個句子的時間 也是別人的 比別人少了4倍 很明顯這是非常好的結果嘛 但你如果知道了這個Cartesia 它背後的Founder是哪些人之後呢 你就會覺得其實也不意外啦
(24:02~25:02) 因為它這個Cartesia 這間公司雖然說我相信 絕大多數的聽眾都沒有 聽過因為沒有幾乎沒有 媒體在報這件事情它就是一個 非常非常小的一個發表 這樣就只有可能 Machine Learning X的人會 會有追到這個新聞這樣而已 但是呢Cartesia背後的這兩個 Founder他們基本上就是 發明了SSM的人 尤其是其中一個人叫做Albert Gould 他基本上你看任何 這種SSM的重要論文 全部都有他每一篇都有他 他就是最OG的SSM 始祖其實我今天會講 SSM一部分的原因也是因為 我前幾天正好 聽了一個他的訪談 就是他上一個叫做No Priors 的節目然後去聊 然後Cartesia然後聊SSM這樣子 然後就突然想到對齁我還沒講 SSM所以我這一半就來 講一下這樣好所以呢 我們從去年年底有了一篇 SSM的革命性論文叫做Mamba 在那之後呢
(25:02~26:02) 過了幾個月大家都開始進行 小規模的實驗然後到了 三月開始有一次比較大的嘗試 然後五月這個SSM 的OG始祖呢 自己主動跳出來做了一個Product給大家 看然後現在時間 就到了六月我們就不確定接下來 這個SSM的發展會如何 但我們從前面這幾個月的發展 我們就可以看到說這個技術 真的是成長的很快 而且每一次的實驗規模的提升 好像都有完成 這個SSM的Promise 就是他確實有跟Transformer 差不多好的成果 而且他確實有比Transformer快 很多所以這個SSM 真的是大家可以現在開始 稍微關注的東西 你不用密切的去追蹤他啦 但是你至少要在你的 雷達裡面有放這個東西這樣 好那接下來呢我們來講講 這個SSM具體來說 究竟是怎麼運作的 那我想這個部分可能會 有一點點困難一點儘管 我已經去找出了一個
(26:02~27:02) 我覺得是最容易解釋的方式 但是還是 會相對有點困難 因為SSM這個東西真的爆難 我一開始念了好幾次我都念不懂 我第一次嘗試我直接看論文 完全看不懂然後我去看各方的解說 也都看不太懂 真的是超級難 但是呢我最後發現了一個 一個YouTube頻道他在講這個方法 他講完了我終於 通了你知道嗎 因為他解釋SSM的這個途徑 是跟其他人解釋的途徑 是不一樣的其他人呢 都是一個比較正規的解釋的方式 因為這個SSM呢 他其實最早是用在 Control Theory裡面 然後有一些Machine Learning的人呢 就包括這個Albert Gu 就把Control Theory用在Machine Learning上面 用在AI上面這樣子 然後他們那個時候呢 把這個整個Theory搬過來呢 其實要做非常非常多不同的這種加工處理 才可以讓他能夠處理 Machine Learning的資料 最重要的原因就是因為
(27:02~28:02) 原本這個Control Theory呢 它是一個Continuous的一個model 但是這個Machine Learning的資料呢 都是離散的 所以說他要想辦法把這個Continuous Model Discretize 變成離散化的版本這樣子 然後過程中呢 又多了很多新的問題 又有很多很多要優化的架構 然後又有很多很多甚至硬體這邊要優化的地方 所以他們是 從這個Control Theory的SSM 一步一步一步優化 經過了大概四五個重要步驟之後 才變成今天的Mamba 那我看網路上的一些教材 解釋的方式呢就是 他們都是從這個最一開始的SSM 一步一步推導到Mamba 然後整個過程 就超級無敵複雜 我覺得裡面的數學超爆難的 我實在是沒有足夠的 腦細胞可以理解這個東西 但是呢我前一陣子看到一個 YouTube影片 這個影片裡面呢這個高手 他是用另外一條途徑 在解釋這個SSM
(28:02~29:02) 他這條途徑呢就是 他直接從RNN出發 RNN就是Recurrent Neural Network 他也是一種神經網路的架構 他從這個RNN出發 然後一步一步把這個RNN 變成SSM讓他走到 SSM這一步 這邊我就很熟了嘛 因為這個RNN就是本來就是Machine Learning的東西 然後他只是 多加一點點的數學多加一點點的數學 把它變成SSM這樣我就可以理解 那為什麼這樣子可以解釋 SSM呢其實是因為 SSM基本上就是 RNN的一種變化而已 他是一種叫做Linear RNN的RNN 這樣子 然後就連Mamba他也是一個 在這個Linear RNN之上 再多加一些Component這樣子而已 但神奇的就是他並不是從 RNN演化來的 他是從一個Control Theory的一個 Architecture慢慢演化過來的 只是他最後這個 終點呢碰巧就是 RNN的一種變形這樣子 所以說這個YouTube頻道
(29:02~30:02) 他就直接從RNN開始推到 然後就 雖然Albert Gould 可能一開始不是這麼想的 中間也跳過了超多複雜的數學 步驟但是Everything makes sense 所以說我就 決定用這個方式來 大概講給大家聽 那這個YouTube影片的連結 我會放在本集的資訊欄最下方 大家可以去看一下 接下來的我的介紹 主軸都會是Follow這個YouTube影片 但是過程中我會增加一些 我自己的解釋 我自己消化過的一些內容 然後數學的部分我可能就會跳過 因為大家去看影片會 比較好理解 那我們就一樣先從這個RNN開始解釋 這個RNN Recurred Neural Network 他是在Transformer 出來之前大家在使用的 神經網路的架構 他跟Transformer一樣都可以處理 語言的資料 不過他處理這個資料的方式跟Transformer是差 非常多的 那我們就拿一個非常簡單的句子 填空的例子來講好了
(30:02~31:02) 假設今天你給 RNN跟Transformer一個句子 叫做科技浪是一個 很好的Podcast結 然後後面那個字 叫他填上讓他結聾這樣子 那這個Transformer的做法 他會直接把你目前 給他的整句話直接吃進去 科技浪是一個很好的Podcast結 這整句話全部 吃進去,然後同時 為這每一個字算一個Attention Score 也就是說 這邊就是我們講的這個 自注意力機制在做的事情 就是他會算出說 每一個字之間互相的關聯 究竟有多強 然後他除了算這個以外 他也會把每一個字他們的位置 記錄一下,他是第一個字 還是第二個字還是第六個字之類的 把這些東西全部記錄起來 然後再包含這些字 原本他自己的語意 這個字原本就有他自己的意思 把這些東西全部 一包一包丟進他的 神經網路之中
(31:02~32:02) 神經網路就是有非常多密密麻麻的權重 在process這些東西 然後最後會process出一個結果 就是他覺得下一個字 最有可能的是哪一些字 然後通常大家去選這個 可能性最高的那個字 作為最後的選擇 這樣子 他可能算完了之後 最後的結果就是 MU出現的可能性最高 科技量是一個很好的Pockets結MU 那今天這個RNN 就很不一樣了 RNN他沒有辦法一次把 科技量是一個很好的Pockets結 這整句話直接吃進去 他其實需要從第一個字一個字一個字來 也就是說你要先從Ker這個字 開始 然後Ker這個字放進去之後 這個模型會從Ker這個字提取出一些資訊 然後放在他的記憶體當中 不是記憶體啊 他的一個記憶當中 然後接下來你再把G這個字丟進去 然後一樣他會從G裡面 提取出一些資訊然後update 他的hidden state
(32:02~33:02) 就更新他的記憶 因為他現在就是看過了Ker也看過了G 所以這個記憶要更新一下 然後再來他是把浪丟進去 然後一樣再更新一下這個記憶 他這個記憶呢 存放了Ker 記 浪這三個字的 資訊 然後接下來呢就一個字一個字不停的放進去 直到你放到最後一個字 Ker 記 浪是一個很好的podcast 結你結放進去 之後這個記憶又更新了之後呢 你接下來你要predict 這個Mu這個字的時候呢 你就是靠目前你更新到 最新版的這個記憶去判斷說 下一個字應該是出現什麼 比較好因為現在最新版的這個記憶 照理來說已經看過了 Ker 記 浪是一個很好的結 這些所有字了 所以他已經有前後文的概念了 所以他知道下一個字要出現Mu會比較好 那從這兩種模型的架構上的差異呢 你就可以很明顯的看出說 這兩種模型他們各自的好壞在哪裡 首先很明顯這個RNN有個致命的弱點 就是他處理整句話的時候
(33:02~34:02) 他必須從第一個字開始 一個字一個字的處理 他沒有辦法做平行的處理 像Transformer他就可以完全 平行的直接處理整句話 那今天我是給一句話的例子喔 但你要知道現在Transformer的context 可能都最少的就是32K起跳 然後最高甚至Gemini 1.5 Pro 有到這個2Million 200萬的這個tokens 你200萬個tokens 不要說200萬 100萬個tokens直接放進去 這個Transformer呢 是可以直接同時處理這100萬個tokens 然後算出接下來的tokens會是什麼 那你如果是使用RNN的話 你必須從第一個token開始 不停的update你的hidden state update100萬次 算100萬次你才可以去 算下一個字是什麼 所以這就是為什麼Transformer 現在會主宰一切嘛對不對 就是因為他可以平行處理他的input 所以他才能夠進行 這個極大量資料的預訓練 也就是說你只要有
(34:02~35:02) 更多的算力 你就可以train更大的模型 有更多的算力就可以train 那這件事情很明顯在RNN上是不可能發生的嘛 就是你如果要拿2trillion個tokens 來訓練RNN的話 你要訓練到什麼時候 他一個一個token慢慢來算 你要算到什麼時候不可能啊 但同時啊我們剛剛有說Transformer 也是有他的致命缺點 也就是大歐的N平方這個缺點嘛 那回到剛剛的例子就是 科技量是一個很好的podcast節 這整句話呢 你要算他的attention score 他要算的方式是 他要算的方式是 每一個字都要跟每一個字 算一個attention score 包括他自己都要喔 所以說科要跟科技量是一個很好的podcast節 都算一次attention score 然後G要跟科技量是一個很好的podcast節 都算一次attention score 所以你應該懂了吧 每一個字都要跟每一個字算 那這個就是大歐的N平方 他N平方是怎麼來的嘛 對不對
(35:02~36:02) 因為N就是你的context的長度 你的文章長度 你的文章長度有N 你就要做N平方次attention score的計算 雖然說很明顯 這些計算都是可以被平行化的 但是這些運算量呢 真的就是增加的很快 但是RN呢 他就不會有這個問題囉 因為你不管今天context length 有多長 你下一個字的運算量一定都是維持一樣 完全不會變 因為你在做的事情就是 你把下一個字的一些資料提取出來 然後更新你的記憶嘛 更新你的hidden state 所以前面的所有的 這種context的 資訊啊早就已經被壓縮在 你那個hidden state裡面了 你不用再重新算他們之類的 你只要把下一個字的一些資料 更新進去而已 所以說每一次的運算 他們運算量是持平的 也就是說他們的complexity呢 是大歐的N 你只要你那個context length有多長
(36:02~37:02) 你就做幾次運算就這樣而已 所以這就是為什麼有些人說理論上 RNN是有無限的context length的 但實際上 實務上RNN是完全做不到這件事情的 RNN甚至幾乎 完全沒有任何實務上的價值 那這個就是因為training RNN的training呢 幾乎是不可能的任務 那這是因為RNN有兩個超級大的 缺點嘛 第一個我剛剛已經講了就是 它是一個解決方法平行化的 它一定要一個字一個字來 那另外一個致命的缺點呢 是一個叫做 那這個是在講什麼呢 首先大家要知道就是 你在訓練一個AI模型的時候 不管它是一個深度學習 這種神經網路的AI 還是一個傳統的這種統計 based的AI之類的 你都是使用一個演算法 叫做gradient descent 這個T度下降 就是要持續的微調每一個權重 然後把它調到 學習完成的階段這樣子
(37:02~38:02) 那它怎麼調的呢 首先它會上出每一個權重的T度是多少 這個T度呢 其實就是一個數字啦 可能是正的可能是負的 那正負呢就代表了 這個權重要往哪一個方向去調 然後這個數字的大小呢 就代表這個要調多少這樣子 然後這個T度呢 接下來就會直接拿去 調整權重 然後調完了之後呢 這個權重就等於是在這一次的訓練結束了 它已經就是學到了這些資訊這樣子 當然就是 過程中有些細節被我省略 就包括learning rate 然後還有一些 partial derivative之類的 這些我就先不講啦 那我剛剛有說這個RNN它在處理資料的時候 它是一個字一個字去算嘛 但是我有個地方沒講到 就是它在處理每一個字的時候 它用的都是同一套的權重 同一組權重 它一直重複的使用這樣子 也就是說呢 你今天在算這個gradient
(38:02~39:02) 這個T度的時候呢 有一些項它會有 這個權重反覆相乘 非常多次的狀況發生 那我們講的是可能 假設你今天是拿一個 一千字的文章給它好了 一千字好像太多 一百字的文章 它就會反覆相乘一百次 然後這個時候如果你的權重大於1 它這100次就會越乘越大 越乘越大越乘越大 乘到最後變成超爆大 然後大到你算出一個超爆大的gradient 然後這個gradient就完全 沒有辦法拿來更新你的權重 因為你每次更新 它都直接從-200 變成正200 然後下一次更新從正200變成-200 那這樣沒有意義啊 它就是從它就是在這邊跳來跳去 它的最佳值呢 可能是0.1還是0.75之類的 但你從-100正200-100正200 這樣跳來跳去你永遠跳不到0.75 然後同時呢 如果你今天你的權重是比1還小的 是0.幾的話
(39:02~40:02) 它相乘100次之後呢 你的gradient算出來 會變得超級小 接近是0 假設你initialize 你初始化的這個權重 數值是可能5好了 然後最佳值是0.75嘛 那你每次調整都只調成 接近0 你調整了100次你訓練了100個step 它還是在5 還是停在5 它永遠到不了0.75 所以這也是完全沒有辦法train 那transformer當然就不會有這個問題嘛 它的每一個layer可能這個權重 有大有小有大有小 然後乘來乘去乘來乘去 就數字還是可能維持在正常的level 這樣子它不會像RNA一樣 它會重複的使用重複的使用 重複使用很多次 所以因為這兩個問題 也就是它沒有辦法平心化的訓練 以及有 exploding跟vanishing gradients的problem 因為這兩個問題呢 RNN基本上在實務上是完全不能用的 因為你根本就不能train
(40:02~41:02) 那最早呢 大家是發明了一個新的 進階版的RNN架構叫做 LSTM 這個LSTM那陣子很火嘛可能2016年 2015年那時候很火 那那個時候呢 LSTM就是解決了其中一個問題 就是這個exploding跟vanishing gradients的問題 但是它還是沒有辦法解決 這個平心化訓練的問題 直到有一個叫做linear RNN的架構出來 這個linear RNN就是可以同時解決這兩個問題 那首先 它解決這個無法平心訓練這個問題呢 是透過一個非常簡單的方式 非常單純 不簡單啦不簡單 非常單純但是是一個很巧妙的方式 它就是把那個你原本要從每一個字裡面提取資料 放到你的記憶裡面的這個神經網路 原本這個RNN是用一個神經網路在做這件事情 它把這個神經網路 換成一個linear transformation 就是一個線性的一個算法 就這樣子
(41:02~42:02) 做了這件事情之後 然後再用一些很巧妙的一些數學的方法呢 你就可以同時平行的計算 每一個step的hidden state 它的值是多少 因為原本這個hidden state 就是這個記憶的部分 你真的要一個字一個字來 你才會算得出來嗎 因為後面那個字是取決於上面那個字 它的hidden state 所以你一定要一個階段一個階段來 但透過這個方式呢 它其實可以在幾個簡單的步驟之中 就把全部的步驟的hidden state 全部直接算出來 那具體來說 這個巧妙的方法究竟是什麼呢 大家就去看那個YouTube頻道吧 因為我在這邊要解釋 太難了啦 這個我沒有白板是很難解釋這種概念 然後大家去看它就好了 因為它講得非常明白這樣 那第二個缺點是怎麼解決的呢 這個exploding Vatish ingredients的問題 是怎麼解決的 他們解決的方法其實也蠻單純的 他們就是盡量
(42:02~43:02) 讓所有的群眾一開始在初始化的時候 就接近1 因為這個越接近1 它explode跟Vatish的 可能性就越小 那具體來說它怎麼做到這件事情呢 其實也是有一些數學在裡面 大家同樣也是去看影片 但反正它做到這件事情之後呢 確實這個 RNN的訓練就穩定了非常多了 那這個就是所謂的linear RNN 那我們到底什麼時候會講到SSM 我們今天不是在講SSM嗎 怎麼都在講RNN呢 這就來了 這個linear RNN呢 其實就是SSM 或者應該說一個SSM呢 就是一個linear RNN 只是它在initialize 它在這個初始化它的群眾的時候呢 它有用一點 比較不一樣的方式 但基本上它就是一個linear RNN 其他所有東西都一樣 但是這種跟linear RNN 87%像的SSM呢 它還不是SSM的最終形態 應該說不是最強的SSM
(43:02~44:02) 那我們這邊 最一開始都在跟大家說這個 所謂的mamba 這個mamba才是現在最強的SSM 那這個mamba呢 其實也跟這個linear RNN是87% 但它額外又做了 一些改進 除了它這個 一開始初始化群眾這邊不太一樣以外 它也做了兩個蠻大的改進 那我們剛剛不是有說 linear RNN就是它做了這個linear呢 就是把原本這個 RNN在從一個文字裡面 提取出資訊放到 記憶的過程之中呢 原本是使用一個神經網路 然後它把它改成一個linear transformation 對不對 就是一個純線性的變換啦 那它把它變成了 這個linear的function之後呢 這個mamba呢 又把它增加了一個新的東西 它仍然把它維持linear 但是它現在每一個input token 都會用不一樣的群眾來算 就原本剛剛都說 它都是用同樣的群眾
(44:02~45:02) 不斷的一次乘 一直乘下去嘛 那它這一次呢是會根據你的input資料的不同 使用不同的群眾 下去算 那它會做這個優化呢 其實是因為我們剛剛講的linear RNN 或者是你說的這種初步的 一些SSM 像是S4這種SSM 它其實確實喔 是因為它是用RNN它那兩個最大的問題 所以說它是可以train的 然後他們一開始呢大家也train出了一些 初步的實驗結果 然後看起來也都不錯 甚至在某一些非常非常特別的 事情上面呢 它的表現是比transformer還好的 但是呢 它在最重要的這個語言處理的 task上面呢還是比不上transformer 那mamba的這些人呢 當然就包括albergoo 他們就是想說 比不上transformer 應該是因為這些語言的資料呢 它每一個字的這個 裡面的訊息度的變化量 真的是太大了
(45:02~46:02) 有一些字真的是沒什麼意義 有一些字就是充滿了意義 然後就是這種變化非常大 所以說你單純你用同一個 同一組群眾呢 是沒有辦法很好的學出這種變化的 所以說他們才加了這個selective 的元素進去 讓這個mamba呢 能夠針對每一個字的input 使用不一樣的群眾 下去更新它的hidden state 那另外這個mamba還有做另外一個更新 其實還有很多其他小的 但這兩個是最主要的 那另外這個更新呢 就是他們用了一個 hardware aware的方式去訓練它 那這邊呢就是比較牽涉到 軟硬整合這邊的部分啦 就是你怎麼樣在 使用一個GPU訓練一個mamba的時候呢 你讓最多的事情 在SRAM上面解決掉 然後再傳到這個 HBM裡面那這邊呢 如果要再講下去的話又是一個兔子洞 所以我們就先不要跳進去了 那現在呢大家應該都知道這個 mamba呢真的可以說是
(46:02~47:02) 集合了這個RNN所有的 優點但是克服了 所有的缺點的一個 架構那我們從mamba這邊論文 的一些實驗結果 我們也可以看得到這一點 首先它的這個推論 速度絕對是比transformer快非常多的 它是比transformer快五倍 至少而且它的這個 當你今天給更長的context length的話 它的 運算的複雜度是 線性上升的絕對不是像transformer 一樣這樣直數上升 嚴格來說是quadratic的上升 這樣子那這個硬傷 已經克服了接下來重點來了 它的表現有跟transformer一樣 好嗎因為如果一樣好的話 這沒道理繼續用transformer了嘛 對不對 從mamba這邊論文來看 確實它是跟transformer一樣好 甚至還更好喔他們測出來的 結果是一個同樣參數的 mamba跟transformer比起來mamba 會比較好一點它的成效 就是它對於語言的理解 都不管它這個
(47:02~48:02) context length的scaling 不管它這個inference speed它連成效都比較好 然後它甚至可以跟 幾乎比它參數比較大 然後它可以用兩倍的語言模型下去 比較這樣子 但老實說這種比較其實好像不是很公平 因為你仔細點進paper裡面看 你會發現它都是拿 很早期的transformer model 下去比較 臉書很早的opt 的模型 它使用的benchmark我也都沒看過 假設它今天是用 用jama 去跟它比google正好出jama 2 用jama 2下去跟它比 現在大家常見的 mlu這種benchmark下去比 這個結果會更有說服力 但是無論如何 這些結果都顯示了ssm 絕對是值得持續探索下去的 一個領域所以我們接下來就來聊聊 ssm的未來究竟如何 我自己是有幾個想法 首先第一個 我覺得mamba跟transformer這種
(48:02~49:02) 混合的模型其實 有可能是一種趨勢 我們從jamba 這邊也可以看到這個現象 它是用8比1 的比例下去 混合mamba跟transformer 我覺得這種方法可能是一種 趨勢是因為 mamba的這種記憶 不斷更新它記憶的這種方式 它跟transformer的 注意力機制 比起來呢雖然說它的 complexity是linear 在scale的是輕很多 但它總是有犧牲掉一點東西 它犧牲掉的就是一些 資訊量像是transformer 的attention 每一個字都要跟每一個字算attention score 它已經是 包山包海的 讓這個模型把每一個字跟 每一個字都想過一遍了 所以說資訊量絕對是最足的 但是mamba 每看一個字就把這個字提取 出一些資訊放到它的記憶裡面 這個動作
(49:02~50:02) 因為這個記憶不可能無限增大 所以它這個記憶其實是 有一定的大小的 這個動作它本身就是一個壓縮的動作 它有在進行壓縮 attention呢transformer的attention 是沒有在壓縮的 它就是包山包海把所有資訊都算出來 所以mamba為了追求速度 還是會丟掉一些資訊的 那如果你 塞一些transformer layer進去 然後想辦法把這些東西撿起來 我覺得是蠻不錯的 另外一點呢是我覺得很有可能 未來這個SSM 至少在短期 他們會先佔領某一些 模態他們可能不會直接 挑戰語言的模態然後把 這個transformer在 chai gbt這種等級的模型 直接打敗他們可能是先從 一些其他的模態開始他們比較 擅長處理的模態因為根據 Albert Gou 我不知道這個Gou是Gou還是 Gou反正它可能是任何一個 所以Albert Gou 在no priors的interview裡面
(50:02~51:02) 他裡面正好有說到這邊 他就是說這個 SSM呢他其實 擅長處理的模態跟transformer 有一點點不一樣 SSM他最擅長處理的模態呢是那些 這個資訊量呢 並沒有很dense是很sparse 的那種資料 就是他這種資訊量是很分散的 就像是可能 audio video這一種 像是text文字 他其實就是非常information dense因為他一個token 他就是裡面就裝 有很多很多的information 對不對所以這個也是為什麼 Cartesia他們會先從這個 聲音的模態開始下手 他們最後是想要就是 擴展到所有模態但他們從聲音的 模態開始下手因為他們發現這個SSM 在聲音這個模態呢 真的是比transformer強非常多 這樣所以很有可能呢在接下來 的這幾年我們會看到 SSM呢開始在某一些 特定的模態開始霸榜 就像是其實現在
(51:02~52:02) 我們現在在這個產生圖像 什麼東西我們也都不是用transformer 我們都是用diffusion model diffusion model就是在AI產生圖像 AI產生影片這邊霸榜 那可能接下來霸榜的呢 就是這個SSM 在audio這邊 最後一點呢就是這同時也是 我聽這個Albergoo在 NoPriors的訪談提到的 就是他們反覆提到 邊緣運算這個概念 因為這個SSM真的是太適合 邊緣運算了這個邊緣運算最 需要的就是一個模型他 算很快然後同時他不會 佔那麼大的記憶體 這個就是非常適合SSM 甚至在這個interview裡面呢 Albergoo他的partner也直接拿出了 一個Macbook然後他上面跑的 就是他們的Sonic模型 然後就直接在大家面前 就是展示這個Sonic模型他的 跑在Macbook上面的latency究竟有多短 這樣子 真的是蠻短的蠻厲害的 所以如果有在關注這個邊緣AI的話 你也可以關注一下SSM
(52:02~52:14) 好那這個本集SSM的內容 就講到這邊 最後呢一樣感謝一下今天的贊助商 Speak你如果想要學好英文口說的話 就找他們就對了 最後呢就祝大家有個愉快的一週
