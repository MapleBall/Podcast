(00:00~01:02) 【音樂】 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式 帶你了解時下最火的科技話題 本集節目由NordVPN贊助播出 那我覺得VPN這個服務啊,真的就是每個人都用得到 每個人用的方法可能不太一樣,用到的功能也不太一樣 但大家一定都用得到 像我自己本人常用VPN的情況呢 就是首先我在連公共Wi-Fi的時候 我就會開個VPN,那這個當然就是為了避免我的個人資料洩漏 我的個人資料是非常值錢的,至少對我來說 那有開VPN的話,就算有人截取了我傳出去的資料 他能看到的就是亂碼而已,所以說可以很好的保護 那另外一個我很常用的功能呢,就是使用一些國外服務 像是上禮拜有跟大家說臉書推出Meta.ai這個網站
(01:02~02:03) 這網站上面有host他們的Lama 3模型 然後也有這個圖像生成模型 然後全部都是免費的,非常強大 但是他只有在美國可以使用 那這個時候呢,我就直接透過VPN跨到美國 就可以立刻使用了 那以上是我比較常用的用法啦 但我知道很多人呢,也會用VPN來看一些國外的影集 玩一些國外的遊戲 註冊一些國外的帳號 尤其現在很多人會用VPN來省錢 因為很多的服務呢,可能在國外買是比較便宜的 有些機票呢,可能跨區買也是比較便宜的 那如果你也需要用到這些VPN的功能呢 我會推薦你購買NordVPN 原因很簡單,就是因為我覺得NordVPN就是 市面上連線速度最快,然後最可靠的一個品牌 你如果想購買的話,現在到本集的資訊欄裡面 你就可以看到科技量的專屬優惠連結喔 你用這個連結購買呢,你可以得到獨家優惠方案 加贈四個月 或是你也可以輸入我的優惠碼來得到這個優惠
(02:03~03:05) 我的優惠碼呢,是全部都是小寫的 T-E-C-H-W-A-V-E 中間沒有空格 T-E-C-H-W-A-V-E Techwave 那同時呢,你也不用怕,買了之後覺得不滿意會後悔 因為NordVPN30天內都可以無條件退費的 你如果不滿意的話,隨時可以取消申請退款 想要購買的人,就趕快使用科技量的專屬連結跟優惠碼吧 本集業配就到這邊結束,謝謝NordVPN的贊助 那我上禮拜在跟大家聊這個LAMA3的時候 我有跟大家說到一個蠻驚人的比較對不對 我就跟大家說這個LAMA370B這個模型啊 它已經打敗了去年三月推出的GPT-4模型 也就是說過了一年,一個70 billion參數的模型 已經可以打敗一個1.8 trillion參數的一個模型了 那這個參數量呢,你可以把它想成腦容量 那也就是說呢,今天的一個AI模型 可以打敗去年腦容量比它大25倍的AI模型
(03:05~04:05) 或是你說頭腦size比它大25倍的模型 但是其實呢,這個比較並沒有說真的那麼公平啦 因為這個GPT-4的這個參數量呢 首先我們不確定 我們不確定它到底是不是1.8 trillion 雖然說現在幾乎9乘9的source都這樣講 那我自己也是覺得大概是這樣啦 那另外一個點呢,就是這個GPT-4它就算真的是1.8 trillion模型 它其實是一個MOE模型 也就是這個混合專家的一個模型 也就是說它1.8 trillion的參數呢 其實是平均分配給8個專家 或是你說8個比較小的模型這樣 雖然說嚴格來說它們不算是獨立的模型 所以我們今天來做一個更好的比較 那首先我們要先把時間倒回2022年底 那那個時候呢,有一個歷史性的事件發生了嘛 就是這個ChatGPT問世了
(04:05~05:05) 那它是在這個11月30號我記得那一週出來 然後在12月呢,立刻就開始爆紅了 然後到這個隔年2023年大概12月的時候呢 全世界都已經知道ChatGPT了 然後有大部分的人都已經用過了 就是那時候不是有一張很有名的圖嗎 就是在說ChatGPT是有史以來成長最快速的一個產品 比iPhone,比TikTok,比Instagram都還快很多 那我相信絕大多數人第一次使用ChatGPT的時候 一定都有被它驚艷到對不對 我想當初我那時候,我第一次用的時候 我真的是太震驚了 然後震驚完之後立刻就有辭職的念頭 就想說天啊,世界進步這麼快 GenAI進步這麼快 為什麼我還在這邊搞一些Data Analysis Traditional Machine Learning的東西 但是啊,你知道嗎 這個震驚全世界的ChatGPT 在一年半之後,也就是今天
(05:05~06:05) 它已經被一個size比它小140倍的AI模型打敗了 那個時候ChatGPT剛出來的時候 它背後的模型是GPT 3.5對不對 那GPT 3.5我們大家都知道是一個175 billion參數的模型 這個OpenAI他們自己有公開講 但是微軟在上禮拜推出的這個Fy3 mini模型 Fy就是P-H-I的那個Fy Fy3 mini模型它只有3.8 billion個參數 然後它已經可以打敗GPT 3.5了 這個參數的差距大概是46倍 但是模型的大小可以差到更多 模型的大小可以差到140倍 這個GPT 3.5 也就是剛開始的ChatGPT 它的模型大小是350GB 350GB 那Fy3的模型只有2.5GB 所以說這個就是140倍的差距 那我們拿一個實際的例子來比較好了 你當初要跑這個GPT 3.5的時候 這個350GB這麼大的模型
(06:05~07:05) 你會需要花5張A100的GPU A100就是NVIDIA上上代的GPU 現在是這個B200啦 那A100的GPU呢 它有80GB的RAM 或者你說High Bandwidth Memory這樣 那一張80GB 5張就是400GB 400GB就夠跑一個350GB的模型了對不對 然後一張A100的GPU 售價大概是台幣30萬 所以說你會需要花150萬台幣 然後還要加上一些其他的Cost 比如說Server Rack 然後電腦的這些其他的Cost 你才可以跑一個 你才可以組一個能夠跑GPT 3.5的一台電腦 但是今天這個跟GPT 3.5差不多強的Fy3 mini模型呢 在一台手機上就可以跑了 因為它的大小只有2.5GB嘛 這個很多的手機的RAM都超過10GB了 你有看到這個GPU嗎 手機的RAM都超過10GB了 你有看過任何的一項技術 是可以在一年半之內成長140倍的嗎
(07:05~08:05) 我自己是沒有看過啦 然後我覺得這個AI 很有可能是人類歷史上進步最快速的一項技術 因為我們其實從2012年開始 比較認真的開始發展Deep Learning 就是開始發展AI這樣 那發展到可能2022年 ChaiGPT問世 只花了10年 10年之內 我們就已經發展出了ChaiGPT 當然在2012年之前 還有非常非常多年的AI的研究 但那個時候呢 可能是剛起步 現在深度學習的路線也還沒被確定 Anyways 反正從2012年到2022年 10年之內 我們就發展出了ChaiGPT 然後從2022年到2024年 一年半之內 我們又進步了140倍 很明顯的現在就是AI技術 要開始爆發性成長的起點 我們現在還在起點而已 真的是非常誇張
(08:05~09:05) 而且在這一年半之內 我覺得除了我們剛剛講的這個 我覺得可以把它稱作Intelligence per Gigabyte 除了這個指標以外 其他很多的指標 AI也是進步了非常多 AI有更強的推理能力 AI有開發出了使用工具的能力 AI有更強的推理能力 AI有開發出了使用工具的能力 有Agent的能力 AI也變得更加有效率 可以跑得更快之類的 然後也有更長的Context Length 能夠一次處理更大量的資料 然後也有更多模態的能力 開始有視覺、聽覺等等 我覺得真的可以說是 短短一年半 AI的世界已經恍如隔世了 在其他的技術上 我們真的很少看到 這樣子的情況 我把它這個半導體來比 IC來比好了 IC就是我們可能 每一年半積一點牙膏 積一點牙膏這樣 感覺一年兩年之間 感覺就不太出來
(09:05~10:05) 有多大的進步 但是你放長遠看可能五年十年 你就會發現說 隔了好幾代的處理器產品 就真的差很多這樣 但是AI一年半就有這種 恍如隔世的感覺了 到這邊很多人應該都會有兩個問題 第一個問題就是 我們究竟是如何做到這140倍的進步的 第二個問題就是 那這代表什麼 未來會怎麼樣 這個成長會持續下去嗎 還是不會,那這個世界會怎麼樣改變呢 所以說我覺得今天這一集 我們就來聊聊這個話題 在開始之前 我覺得我還是先明確定一下 我說Five 3 mini 跟GBT 3.5比起來差不多好 究竟是怎麼樣的差不多好 我用的一些 評斷的標準究竟是什麼 首先就是你去看 微軟這個Five 3 mini的 Technical Report 它的論文,它這一開始就有說 Five 3 mini它的表現跟GBT 3.5 是可以相提並論的
(10:05~11:05) 這是他們微軟自己 官方下的結論 然後他們得到這個結論的方式 就是透過比較 Five 3 mini跟GBT 3.5的 Benchmark成績 所謂的Benchmark就是這些大型圓模型的 測驗成績啦 他們有各種Benchmark各種測驗 有些是測驗這個 你對於各個學科的基本知識 有一些是 專門測驗你的數學的知識 有一些是專門測驗你 Coding的知識這樣 在各個Benchmark 比較之下呢 其實Five 3 mini是比GBT 3.5 稍微低分一點點 現在這個大家最常用的 MMLU Benchmark 也就是測驗這個大型圓模型 橫跨各個學科 然後各個等級 包括國中國小高中大學之類的 所有學科所有等級的 這個能力 Benchmark的成績呢 Five 3 mini是68.8分 然後GBT 3.5是
(11:05~12:05) 71.4分 所以Five 3 mini確實還是有弱一點 但是是在同一個級距之間 其他的科很多的Benchmark 成績也差不多 然後在有一些Benchmark 其實也是Five 3 mini是比GBT 3.5 更高分的 像是這個GSM 8K 也就是測試這個模型的 小學數學能力 這個Five 3 mini的小學數學能力 是82.5分GBT 3.5 是78.1分 所以總體來看這個Five 3 mini 跟GBT 3.5我們只能說他們是 差不多的表現 然後甚至可能還稍微弱一點點 這樣 但是他只有2.5G 然後GBT 3.5有100 講錯350G 所以說這個Size的差距呢 跟這個成績差距 是完全不成正比的 好那我們回到我們原本的話題 究竟為什麼AI的Intelligence per GB 或者你說這個 每GB的知識量 或者你說這個知識密度
(12:05~13:05) 可以在一年半之內進步 進步這麼多 那我們知道一個AI模型他的檔案大小 就是由他的參數數量決定的 他的參數數量越多這個檔案就越大 那你今天 想要提升你的這個 Intelligence per GB 你主要就是有兩個方法 第一個方法就是你把更多的知識量 塞進同樣數量的參數之中 換言之就是 你用更少的參數量 你就可以就是 接近更大參數的一個 知識量了 另外一個方式呢就是你降低 每一個參數他所佔有的 記憶體量 過去這一年半呢我們主要就是用 這兩個方法來提升這些 模型的Intelligence per GB 那我們先從第一個方法 開始講起好了就是 我們在同樣數量的參數之中 塞入更多的知識 那或者是你也可以說就是 把同樣參數的一個模型讓他變得 更聰明或者你說讓一個 小型的模型變得非常聰明
(13:05~14:05) 這樣 因為這個知識其實 他也不是一個可以量化的 東西啦我會說這個 塞入知識我覺得就是一個比較 生動的講法 他並不是一個物理上是 可以把他塞進模型的 的東西好那要做到這一點呢 其實也很簡單就是從 訓練資料下手就好了 怎麼樣下手呢就是提升訓練 資料的質跟量 那我們先從質開始好了 這邊微軟自己也有說了 這些Fy series的模型 之所以可以靠著這麼少的參數 然後跟這麼大的 模型去相提並論 就是因為這個資料品質的 提升資料品質就是 一切就是我們今天講的這個 Fy 3 mini模型是Fy系列 模型的第三代嘛那他第一 代出來Fy 1出來的時候呢 他那一篇論文很有名喔 是叫做Textbook is all you need這個中文翻譯 就是你只需要教科書 就好了那這邊指的
(14:05~15:05) 教科書其實就是他們 是說這個你要用的訓練資料 就是要跟教科書一樣 高品質的訓練資料這是 因為教科書他不但蘊含了非常 高的這個知識量 他還有助於這個這個大訓練 模型增強他們的 邏輯推理能力那這其實 是非常直覺的一個結論嘛 因為對人來說也是一樣啊 就你每天看一大堆教科書 一大堆什麼生物數學 物理化學的課本 跟你每天都看一堆垃圾動漫 比起來你 一定是看課本會變得比較聰明一點 那大型圓模型當然也是一樣 只不過微軟他這些 Fy系列模型呢他在證明 其實是我們竟然可以 聰明這麼多就是我們 大家都知道用高品質的訓練 資料這個模型一定會比較好 但是他竟然可以好這麼多 那他們的做法呢就是他們 從網路上爬了這些訓練資料下來 之後他們會先進行一個非常 嚴格的篩選 只篩選出教科書等級的
(15:05~16:05) 非常好的這個訓練資料 這樣那篩選的方式 其實也是透過這個 GPT-4來做判斷 就是他們會先叫GPT-4 為一部分的這些訓練 資料上一個標註 標註說這是一個好訓練資料 或者是這是一個糟糕的訓練 他再把這些已經被標註過後的訓練資料 再拿去train一個 Transformer Based Classifier 也就是再去train一個AI模型 讓這個AI模型 學會如何判斷這個資料 是好是壞那再來呢 他當然就是用這個學會判斷的AI模型 去為所有的訓練資料 去上這個標註然後去進行 篩選這樣那為什麼 不從頭到尾都用GPT-4就好了 因為GPT-4很貴 除了這個篩選以外呢 他們還有自己產生這個 Synthetic Data也就是合成資料 那這邊呢他們就是 直接用GPT-3.5 來產生他們所謂的教科書 等級的資料這樣
(16:05~17:05) 那整個過程呢最重要的就是 誒這個教科書等級的 資料是怎麼定義的 他們對於這個資料品質的標準 究竟在哪裡 那也就是說他們這個 GPT-4究竟是下了什麼的prompt GPT-3.5是下了什麼prompt 去產生這些資料這樣 那這些他們都沒有公佈 這些可能就是他們的secret sauce 他們只有大概說一下 他們的頻道標準大概 是怎麼樣這樣就是有給一些 例子啊就比如說 一筆可能會被他們filter掉的 一個比較爛的資料就 像是這個胡人隊在 某某天他某一場比賽 的比賽表現 這個訓練資料 訓練資料對於語言模型來說 實在是沒有什麼 知識價值這樣 那一筆比較好的資料 就可能像是這個一個 coding的教科書的一頁 比如說這一頁他上面 有很多行的自然語言的敘述 就是說誒接下來呢
(17:05~18:05) 我們要寫一個什麼什麼樣的程式 那這個程式呢首先我們第一步 我們要先定義某個function 這個function之下呢 有哪一些變數什麼什麼whatever 那在這些自然語言的指示 之下呢就有這個實際的code 這樣那phi系列模型 看完了這個訓練資料之後呢 他就是可以提升他的 邏輯推理能力好那我覺得 直覺的來理解這件事情呢 你可以把它想像成就是假設你 今天的訓練資料裡面參雜了 很多這種很沒有意義 的資料像是這個什麼胡人隊 某一天的比數之類的 很參雜很多這種資料 那這些資料也是會被模型學起來 這個模型也是會拿他一部分的 參數去學這些東西 也就是說他能夠學習 真正有意義的知識的這個 參數量就變少了 那今天假設你的訓練資料 從頭到尾全部都是非常高品質的 教科書的資料 那今天呢你就可以非常 有效的利用你所有的 參數去把這個
(18:05~19:05) 很大量的知識量給存進去 所以結果是什麼 就是你同樣參數量你能夠存的 知識量是更多的嘛 你能夠變得更聰明 那我剛剛有說就是除了這個 資料品質的增加 訓練資料量的增加也是有 幫助的那這邊我覺得 最好的例子就是那個 LAMA3的模型那你如果 聽上一集你就會大概知道我 接下來要講什麼了但我還是 大概非常快速的簡介一下 LAMA3這個模型啦 這個LAMA3系列的模型呢 是臉書最新推出的大型原 模型在兩三個禮拜前才推出這樣 那他們這些模型剛 出來就非常令人驚艷 因為他們的表現真的是太 好了就是跟同等級 同樣大小的模型的表現比起來 他們真的是太厲害了 那他們之所以會這麼厲害呢 很大一部分是來自於他們拿 極大量的訓練資料來訓練 這些模型就是以一個 70 billion參數量的大 巡研模型來看其他人可能
(19:05~20:05) 都拿2 trillion 1 trillion 訓練的token來訓練他 但是臉書這次是 拿14 trillion 訓練資料來訓練 然後甚至 比較小的這個8 billion 的模型他們也是直接 拿14 trillion 的token來訓練然後在這個訓練 的過程中臉書就有發現 這些模型完全沒有 這個plateau的跡象 沒有converge的跡象 意思就是說他們的成效一直 在持續的變好就算是他們 訓練到了最後這14個trillion token都用完了這個 模型還是絲毫沒有這個 停止進步的情況 也就是說他們繼續用更多的資料 用15 trillion用16 17 18 甚至20 trillion token 這個這些模型呢還是會 持續的進步他們之所以 沒有這麼做呢是因為他們要把這個 運算資源拿來訓練下一 代的模型了所以做一個簡單的 小節你今天要把更多的知識 量塞進一個模型之中
(20:05~21:05) 你就是用更高品質的資料 或者是你用更多的資料 這兩者都可以讓你做到 這件事情其實一直以來在 機器學習領域都有一句非常有 名的話叫做garbage in garbage out 對不對這個你的 訓練資料如果是垃圾你的模型 就是垃圾言下之意就是 訓練資料非常重要 那這句話呢在現在這個大型 圓模型的時代也是成立的 但我覺得很多人啊 雖然說他們都知道訓練資料很重要 但他們都低估了訓練資料 究竟有多重要 那前一陣子我有看到 一個部落格文 這個部落格文是一個OpenAI的 工程師寫的然後他就寫說 他在訓練過了這麼多三十 隻AI模型之後他有一個很 驚人的發現他發現這些 這個這個模型的架構 模型的超參數 模型的optimizer choice全部 都是浮雲啊最重要 的還是資料就他說 如果你的訓練資料不變的話 不管你用哪一個模型不管你是
(21:05~22:05) 用這個Transformer還是一些 Confnet還是其他的這些架構 不管你用哪一個模型只要你的 參數量是夠的這些 所有的模型最終都會收斂到 同一個狀態就是 他們基本上是同一個模型的 你不管丟什麼input給他他的 output就是差不多那其他的這些 像是模型的架構然後你用 什麼hyperparameter超參數 你有什麼optimizer這些東西 全部都是去 調整你收斂到最終 狀態狀態的速度而已 你把這些東西調好他就是 比較快的收斂但無論 如何不管你是用哪一個模型 不管他收斂的快還是慢 他最終全部都會收斂到 你訓練資料提供的那個狀態 所以說他甚至 有說一句話就是說 當你在講ChatGPT在講Bard 在講Claw這些模型的時候 你在講的不是模型的權重 你在講的是他們的訓練資料 我覺得這算是一個蠻有意義的 一個洞察喔 因為我覺得很多人講到這個Transformer
(22:05~23:05) 的這個模型架構都會說 哇這個Transformer就是特別強啊 什麼東西就是跟以前的那些 可能比較舊的 模型架構就是比如說在自然 源處理這邊有像是這個 RNN LSTM這些模型 然後在這個 電腦視覺這邊有這些像是 Covolutional Neural Networks 這種模型嘛CNN 跟這些比較舊的模型架構 比起來呢這個Transformer 就是一個比較強的架構 但我們後來發現Transformer 他並不是天生比較強 他只是比較好Scale而已 他只是比較好規模化的訓練 而已像是這個去年 Google DeepMind就有出一篇論文在 比較這個在給 定同樣的訓練資源 的情況之下一個Transformer 跟一個Convenet 他們的表現其實是差不多的喔 那這個Transformer之所以 現在變成所有這個 厲害的模型他背後的 架構呢就是因為他真的太好 Scale了你丟給他的訓練資料
(23:05~24:05) 被他拆成一個一個Token之後 他可以同時拿著所有的 Token進行訓練 就比如說你丟給他的句子是 Why is the sky blue 他同時會訓練說喔這個 is要接在Y後面 Sale要接在is後面 Sky要接在the後面 他會同時訓練這每一個Token 所以你可以說是當這個 每一間公司他們在 模型架構的了解這些硬體 上面的了解 Optimizer Hyperparameter這些東西 這些可能比較方法論 的了解都已經到達一致的 程度的時候AI 真的就是一個資料的遊戲而已 就是這麼簡單好那我們現在知道了 其中一個讓我們在 一年半內大幅提升AI模型的 Intelligence per gigabyte 的原因 資料品質跟數量的提升 我們現在來講另外一個原因 也就是每一個參數 所佔有的記憶體量的 下降那我們知道一台電腦上 所有的資料都是用0跟1
(24:05~25:05) 在代表的對不對 一個0或者是1的 單位我們把它稱作 一個bit好那一台電腦要 代表一個有小數點的數字 那在這個時候呢最常用的一個 做法就是用64個bit 來代表這個數字 那你用64個bit來代表一個數字 你基本上所有你想到的數字 都可以代表不管它小數點 後面有多少位你都可以代表 的出來因為你 總共這個64個bit 每個bit有兩種可能 所以說你可能代表的組合有 2的64次方這麼多個 但你如果是在訓練一個AI模型 的時候呢你其實不會用64 因為64這個 每個參數都要用64個bit來代表 真的是太佔記憶體 太遲運算量了對不對 所以說通常大家都會用這個 32個bit或者是 16個bit來代表這個 一個數字那像是我這一集一開始說 這個GPT3.5的 大小有350GB這麼大 那這350GB就是
(25:05~26:05) 因為它有這個 175 billion個參數 那175 billion 乘以16bit 因為它每個參數都用16bit來代表 那結果呢就是350GB 不過在這一年半之中我們有發現 欸我們這個模型訓練出來 是16bit的形態 沒有關係但是我們在 使用這個模型的時候其實我們 可以把它壓得更小 我們可以把資料精度再壓得 更低一點我們用8個bit 或者是甚至是用4個bit 來代表每一個數字 每個參數這個模型呢 它的智力並不會下降很多 因為雖然你降低資料精度 這個過程呢它是一個 Lossy Conversion 意思就是說你從16個bit 降到8個bit的時候 你其實是會丟掉一點資訊量的 因為這個8個bit來代表一個數字 它總共能夠代表的 數字的組合量一定比 16個bit少嘛 對不對因為假設你今天 有一個數字是2.345
(26:05~27:05) 然後blablabla 然後小數點後接著10位 那你今天假設是用 16bit的精度 你要代表這個數字首先你一個bit 拿來代表這個正負 這是一定要的然後接下來 你其中幾個bit拿來代表這個 數字究竟有多小 也就是說它小數點之後有幾位 然後剩下的這些數字 再來代表這個數字 它的數字 是哪一些 那你16bit你可以 這樣子分配然後今天你變成8bit了 首先一樣你第一個 bit要用來當 代表正負這個就是要花掉 然後接下來你只剩下7個bit 可以分配所以說你分配 給這個小數點後有幾位 的這個這一部分的 資訊就變少了 你分配給它的bit數量就變少了 所以說你可能就沒有辦法 代表到小數點後10位 你可能只能代表到小數點後 第5位好了那這邊我當然 就是簡單做個舉例啦實際情況不一定是這樣
(27:05~28:05) 大家可以自己去查這個 FP16是 怎麼樣分配它的bit FP8是怎樣分配它的bit反正 無論如何你今天原本在16bit 可以到小數點後10位的這個 數字你把它改成8bit 的話你小數點後 第5位之後所有的數字等於 全部都要直接捨去了 你這一部分的精度就消失了 所以你在降低你的資料精度 的同時雖然說你省下了很多 的記憶體但是你同時會 犧牲掉一些模型的成效 它的智力會 下降一點點因為它的這個 模型的權重它的參數都 變得更低輕的感覺了但是 後來我們發現其實你只要妥善 的運用這8個bit它 其實並不會讓你的模型 成效降低這麼多 言下之意就是你 算是算說會犧牲掉一些 資訊量但你犧牲掉的那些 資訊量都是你用不到的 就是比如說很多這些機器學習的 模型它的參數 或者你說它的權重
(28:05~29:05) 都是介於可能-2到正2 之間的一個數字對不對 因為它就是這個模型在學習 的時候這個模型會做一些 normalization skip connection 把它控制住這樣 你的數字可能就是介於這個 -2正2的這個的間距 之間那你就並不需要 分配這麼多個bit來代表 可能100 1000 10000以上的數字對不對 那些數字本身就在你的模型中 不太會出現你就不用分配 bit給它們代表了那你省下的 這些bit你就可以多多拿來 代表在-2跟正2 之間的這些數字我們發現 這樣妥善利用這些bit的話 我們可以把一個16bit 的模型最多是壓到4個bit 你在4個 壓到4個bit的時候這個模型可能 會變笨一點點 非常少量的變笨 但是你的記憶體需求 會下降4倍 我們會把這個4bit精度的 大型元模型4bit精度的AI 模型稱作Q4的
(29:05~30:05) 模型因為Q是quantization 的意思這整個降低 精度的過程我們都把它稱 作quantization 反正Q4的模型 現在已經變成了一個業界的標準 你如果硬體上有一些限制 的話或者是你可能是使用 你自己家的筆電 你自己家的電腦在跑這些 大型元模型這些genAI 模型的時候你可能都會 使用這個Q4的模型來 跑像是微軟的這個 5.3 mini我說它2.5G 就是指它 Q4的狀態的時候它是2.5G 這樣子的大小然後就是 在手機上也可以跑然後很明顯的 你的模型大小降低的非常 多但是你的模型智商 只降低一丁點那這個 時候你的intelligence per Gigabyte就會上升非常多 對不對那我們講到這邊 基本上就是可以做一個小節 了啦小節就是我們 之所以可以在一年半之內 把intelligence per gigabyte 提升140倍
(30:05~31:05) 一部分呢是來自於我們 對於訓練資料的質跟量 的提升另外一部分呢 則是來自於quantization 就是降低我們的 模型權重的精度這樣 接下來你可能就會有一個問題就是 我們還能靠著這兩個技術 持續的提升intelligence per gigabyte到什麼程度 我們可以持續的提升 多久這樣 首先先從簡單的quantization 開始因為我覺得quantization 這邊呢其實已經差不多 了啦就是我們 大家現在都是使用這個 Q4的模型在跑嘛 那大家都使用Q4呢其實 是因為你再下去這個 模型就會開始大幅的變笨 就是你假設你拿一個這個 mmlu的一個benchmark來看的話 你原本的這個 16 bits的精度呢 你的成績可能是假設是68 好了然後你一路 下降到4 bits你可能 會變成64或是65 之類的有下降
(31:05~32:05) 但沒有下降很多但你一路 下降到Q2的時候 你的成績呢會直接掉到30 或是20G這樣 所以說大部分人都認為這個 Q4就是門檻啦 這個Q4之後就是一個 過不去的檻了這樣所以quantization 這邊的low hanging fruits已經被摘光了 所以我們可以期待接下來 的這幾年呢 我們可能在quantization這邊沒 辦法看到太多的這個大進步 這樣那在訓練 資料這邊呢我則是我覺得 還有非常大的進步空間 首先最明顯的就是這個 LAMA3的發現嘛就是 他們在訓練了14個 trillion token之後呢 模型完全沒有converge沒有收練 到一個成果它還是 持續的在變聰明所以說 我們這邊就是 持續的在丟資料下去就可以了 然後資料品質提升的這邊呢 我不覺得在一年半之內 微軟已經把這邊所有可以研究的東西 研究完了我不覺得是這樣 這邊的它的可能的
(32:05~33:05) recipe實在是太多了 你怎麼樣定義一個好資料 你怎麼樣去filter這些資料 你先train哪些資料再train哪些資料 這個很多東西可以調整的 然後 我不覺得在這一年半之內 我們都已經把最讚的recipe 找出來了一定還有很多可以找的 然後synthetic data 也就是我們使用AI自己 合成的訓練資料這一部分 的也是非常早期的 研究領域我們一定 還有很多這個 新的東西可以發掘出來 所以intelligence per gigabyte這個上升的趨勢 可能會變慢一點點 因為我們已經把這個quantization 這邊的low-hanging fruit都摘光了 但是在這個 訓練資料的這一塊 我們還有很多很多可以做的事情 然後甚至呢 除了這些以外還有一些可能其他的 我今天沒有講到的一些 方法就像是模型 架構的優化等等 雖然說我們剛剛有說這個模型 架構上的優化只是
(33:05~34:05) 能夠只能影響 這個模型多快去 收斂而已 多快的收斂到他的訓練資料 但很明顯的現在我們都還沒有 收斂到我們的訓練資料對不對 所以說搞不好這邊的一些 進步也可以大幅的加速 intelligence per gigabyte 所以你接下來可能不會 再看到可能一年140倍的 提升但你會看到 一樣還是非常可觀的提升 然後我很有信心應該是比 mode定律更快的 mode定律是一年半內可以提升一倍 我是覺得我們一年 都可以提升140倍了 接下來就算慢一點 他還是可以提升非常多 接下來我們來討論一些有趣的 在intelligence per gigabyte 持續提升的情況之下 未來會發生什麼事情 我覺得一個最直接 被帶出來的趨勢就是 邊緣AI的普及 所謂的邊緣AI就是在 邊緣裝置上跑AI 邊緣裝置就是
(34:05~35:05) 書桌上的筆電 口袋裡的手機 甚至是你的未來 可能是你的眼鏡、手錶 或者是maybe你的腦內 晶片對不對 你現在身邊這些所有的邊緣裝置 他們其實都已經有在跑AI了 都有在跑一些machine learning的應用 像是你的手機臉部解鎖 臉部辨識這就是一顆 他就是用AI在做 這些事情但是 我相信你大部分的裝置 應該都沒有在跑最先進的大型圓模型 對不對 但隨著intelligence per gigabyte 持續的下降 總有一天你身邊 所有的邊緣裝置裡面 都會跑一個大型圓模型 甚至是大型多模態模型 也就是這些可以同時理解 視覺資料跟聽覺資料的模型 我們從過去這一年半 我們就有看到邊緣AI的崛起了 在最一開始 在一開始 CHIGBE剛出來的時候 沒有人家裡的電腦可以跑任何的大型圓模型
(35:05~36:05) 任何的都不行 手機更不用想了 但是在 2月臉書的拉馬 出來我們終於開了社群 有一個大型圓模型可以玩了 然後接下來這個quantization 技術的發達 讓我們使用一個弱弱的筆電 就可以自己跑一個大型圓模型了 不用再依賴 我們已經開了一些 零端的API 或是CHIGBE這種網站了 然後後來這個小圓模型也越來越發達 像是這個微軟的Fy系列 然後還有Google的Gemma 也是比較小的模型 這些模型可能 1 billion到3 billion這種大小 就是設計的 讓他在手機上也可以跑 所以說現在基本上 你的手機只要是一個 比較稍微高檔的手機 有足夠的RAM 你的電腦是一個 一樣是稍微高檔的電腦 可能最好是有一張顯卡 或者你是MacBook
(36:05~37:05) 你都有一些相對應的大型圓模型 可以跑 這個趨勢只會持續下去 然後我們會看到的是 所謂的Backward compatibility的現象 Backward compatibility 在講的就是 今天一個軟體 能夠在越來越舊的晶片上面 跑越來越舊的處理器上面跑 他就是有一個 Backward compatibility 現在的AI就是這種情況 每一年我們的 同樣等級的AI是可以在 更弱的晶片上面跑的 這跟我們一直以來熟知的 透過摩爾定律的電腦進步 是完全不一樣的 但是兩者是可以加乘在一起的 那這個 根據這個摩爾定律 每一年半我們IC上面的 晶片的數量會增加一倍 也就是說你的這些電腦的 處理器效能會變強一倍 沒過一年半 確實這個 就結果來看 他也是可以讓現在越來越多的電腦可以跑
(37:05~38:05) 就是同一款遊戲 隔了幾年之後 會越來越多電腦可以跑 但同一款遊戲你以前跑不了的電腦 你現在還是跑不了 不過這個AI因為他有Backward compatibility 所以他可能可以在 舊的機型上面跑 那這兩股力道加乘在一起呢 這個邊緣AI的趨勢 會被推動的非常非常快速 雖然說我知道 有些人在說這個摩爾定律已經死了 但 確實啦我也是覺得這個摩爾定律 有在慢下來的 但我們對於我們的這些半導體 研究人員是非常有信心的 你們各位加油 雖然說你們已經玩過很多 花招了然後也不確定接下來還有哪些 花招可以玩 但是我相信這個摩爾定律 還是可以再走幾年 我們離物理 極限應該還是有一段距離 我們回到這個邊緣AI的話題 我覺得短期 就是在接下來的可能一兩年 兩三年之內你們就會
(38:05~39:05) 立刻看到的就是 你身邊的這些邊緣裝置 很多原本裡面就有這些 處理器的 Micro processor的晶片的這些 裝置呢他們都會開始跑一些 大型原模型了 手機跟電腦不用說了嘛 一定是最先有的現在就已經有了 但是比較侷限於高端的 但接下來就是全部的都會有 那這邊的話 你可以期待的就是一個 Local的語音助手 也就是一個真正有智商 真正能幫你做到事情的一個Siri 那你可能會怎麼樣跟他互動呢 第一個最基本的就是 你會問他問題啊對不對 就任何你想 Why is the sky blue 我也不知道為什麼大家這個 Machine learning community很多人都問這個問題 Anyways你就問他任何問題 你想知道的他都會立刻 上網搜尋然後回答 或者是像是Why is the sky blue 這種問題他甚至不用上網 搜尋他就可以直接根據他 豐富的知識去回答你
(39:05~40:05) 然後你如果有給他你很多 APP的權限的話 他可以幫你做到非常多事情 就比如說你訊息很多很雜的時候 你就跟他說幫我統整一下 我最近收到的這所有訊息 然後跟我講一下有什麼 重要的事情這樣 他就會直接幫你做到這件事 你可能也會叫他去使用這個Uber的APP 幫你叫一台Uber回家 然後他就會直接幫你 做大部分的事情 停留到最後一個畫面讓你確認 你只要按確認就可以了 除此之外 這個助手也可以去進行 手機裡面系統設定的調整 就比如說你今天 要裝一個你去日本 你要用一個E-SIM E-SIM的設定你第一次用你可能 不太會用有點麻煩 你就直接跟他說我要用一個E-SIM 然後他就會他就 一步一步引導你去做 第一步請你秀出這個QR Code 然後第二步 你要幫這個E-SIM取什麼名字 他就用這些自然語言去引導你
(40:05~41:05) 一步一步把這些事情完成 然後這個邊緣AI的助手 他也是可以非常了解你的 因為他是一個完全local的 模型你在使用這個 模型的時候他是在你自己的裝置 的晶片上面跑的你不用 傳任何的這個request 給外面的伺服器 所以說他的個資的保護 是非常強的 一些比較敏感的資料像是你個人 這個健康的資料你都可以 完全放心的去 信任他就像是假設 今天是你的手錶裡面有這個助手 然後大家用 這個智慧型手錶都是 主要是在track自己的 健康就是運動 睡眠什麼東西 這個助手就等於是他隨時可以取得你 所有的健康資訊 所以說可以隨時根據你 所有的健康狀況給你一個 最好的建議 甚至你可以蒐集更多的資訊像是 你每次在吃飯之前 你照一張相不管你是用你的手機 還是用你的眼鏡
(41:05~42:05) 現在這個meta的智慧眼鏡 現在已經可以照相了 你就用這個眼鏡來照一張相 然後你的助手看到了 你每一餐吃的東西之後 他可以幫你算出你每一天 攝取的熱量以及各種的 營養素夠不夠 因為這個助手是大型多模態模型 他可以認得的圖片上面 每一種食物他 有什麼樣的營養成分有什麼樣的熱量 所以當今天你身邊的 如果有這個病人裝置 他裡面都可以跑AI助手 然後同時他們也都可以串聯在一起 互相share這些資料 你的生活便利程度 真的是會大幅提升的 然後我剛剛在講一些可能 我想像的一些使用場景一些功能敘述的時候 你最近如果有在追蹤 一些這些 在評論3C的KOL 你應該就聽得他是蠻熟悉的嘛 因為 就是跟最近大家都在review的 這個 Human AI Pin以及Rabbit R1 的這些裝置
(42:05~43:05) 有87% 你聽到我剛剛在想像未來的這些場景 我完全沒有提到Human AI Pin 或者是Rabbit R1 你大概就知道我對於這兩個裝置 的看法是什麼了 但不過我這邊必須要說啦 很多人現在都在嘴 Human AI Pin跟Rabbit R1 他都說這兩個東西 超慢你問一個問題 你要等十幾秒你才得到一個回答 這完全不能用 沒錯這兩個東西現在就是這麼慢 但是慢並不是他唯一的缺點 而且慢是在 接下來這一兩年內會大幅改善的 一個缺點因為這些裝置 現在之所以會這麼慢就是因為 你在問他一個問題的時候 他要把這個問題發給在雲端 的一個大型圓模型 然後當那個大型圓模型算完了 答案之後再把這個答案 傳回這個裝置 然後這個API Call的動作 那這個動作當然就是 有很多delay在中間 但是過了一兩年 之後呢這些裝置上面
(43:05~44:05) 都會跑現在最先進的這些 大型圓模型了 所以說他在local運算 他就會快非常非常多 所以說大家主要都是批評他慢 但是慢是他最不應該被批評的 一個缺點因為這個 雖然說現在是一個缺點但他立刻 就會被改善了 當然他除了慢以外他 也不是說其他缺點很多 其他有一些缺點 但是最主要的還是因為他沒有 什麼優點就是 就像我剛剛講的假設你有一支 智慧型手機然後有 可能有個智慧型手錶跟智慧型眼鏡 你有這三個裝置的話 一個Human AI Pen或者是 Rabbit R1能做到的所有 事情你身上的這些裝置 都可以做得到而且都可以 做得更好那你還需要 這個新的Product Category 現有的Category就夠用了 那這邊我們在進入QA之前 我們最後再快速的聊一點 就是我們聊到這個邊緣AI 就不得不聊到一間公司 叫做蘋果
(44:05~45:05) 因為這個蘋果 其實一直以來都是被打嘴說 你已經在這一波AI的趨勢 落後了對不對 這個iPhone幾百年都沒變 然後Siri還是一樣智障 然後你們好像也沒有什麼 發表AI的產品 功能之類的 你們到底有沒有在搞AI啊 但之後蘋果可能是見證了 他們的市值被微軟給超過 為什麼超過 因為就是AI嘛 然後這個市值幾乎被NVIDIA趕上 為什麼趕上因為AI嘛 那可能是經過了這一波刺激呢 蘋果就開始 越來越多AI的動作了 那首先是我們看到 他就是把這個原本的 EV的business給砍掉 然後把資源轉到GenAI這邊 對不對 然後我們也有看到說 他開始有發布一些 生成式AI相關的論文 他們有發表一個MM1 雖然說很多人說這個MM1 是臉書的大型多模態模型
(45:05~46:05) 或是大型圓模型 但他其實就是一個 ablation study 他就是一個學術的研究 但anyways 他們有發表這個MM1的paper 然後他們還有上禮拜 發表一個叫做Open ELM 的一個paper 那也是他們的大型圓模型 所以說他們在這邊確實是有 做這個一些研究 然後大部分的人可能不知道 但是在Machine Learning圈子已經很火的 就是蘋果他在去年 年底有釋出一個叫做MLX 的這個深度 學習的架構 就是你可以把它想像成專門為Apple Silicon設計 的PyTorch 這樣子的一個東西 他們也推出自己的這個自家的架構 讓工程師們可以更好地運用 Apple Silicon的一些優勢 來跑這些AI模型 像是這個蘋果最 最著名的就是這些Apple Silicon 他們用的RAM是所謂的 Unified Memory 就是他們的GPU跟CPU
(46:05~47:05) 使用的是同一個RAM 他們是在同一個Memory的 Port裡面就是存資料的 這個就跟Windows筆電是 可能System RAM 跟這個VRAM 是分開的狀況是不太一樣的 MLX 就是可以很好的運用這個 Unified Memory的優勢 來跑這些AI模型 最後我們知道就是這個 蘋果的發表會他們的DubDubDC 快要來了嘛,就是在六月的時候 然後這個在這之前 Tim Cook也有 多次的提到AI 提到AI了嘛 他在Earnings Call也有講到 甚至在一個產品的release 他們也有用AI這個詞 你要知道這是很難得的喔 蘋果是一個 他們用詞是非常小心的一間公司 然後他們每次用詞都要 硬是要用的跟別人不一樣 像是他這個Apple Vision Pro 他們就從來都不講Metaverse 這個臉書都講爛了 他們從來不講,他們就說
(47:05~48:05) Special Compute 但是這個,然後他以前講到AI 確實他們會講到AI的東西 但他們都講Machine Learning 雖然說 確實啦,AI是Machine Learning 但是他們現在終於開始 使用AI這個詞了 我覺得大部分人的解讀就是 哇,你們現在終於 就是終於放棄了 放棄自己在那邊高冷了 你們也要來蹭一波AI了 甚至最近也有留出一個消息 是蘋果的M4 M4晶片快要出來了嘛 然後這個M4晶片就是一個 以AI為主的晶片 可能就是他增加了比較多 Apple Neural Engine之類的 反正做個總結啦 其實蘋果他的 MacBook在跑 生成式AI這邊的能力 其實一直以來都是蠻強的 然後這個開源社群也超愛蘋果的 有一大堆這種開源 支援蘋果筆電 跑GEN.AI的這些Github專案
(48:05~49:05) 甚至你可以說 很多這些比較主流的Github專案 甚至是AI的Github專案 他都是專門為Apple Silicon設計的 然後現在也有 MLX的架構出來 然後大家可以用的 選項又更多了 可以用PyTorch,可以用MLX 然後大家也有發現說,MLX跑 Inference好像確實是比較快一點喔 在iPhone這邊呢 我們其實就沒有看到什麼 但我們在這個 他們最近的一些研究 像是我說上禮拜的這個 Open ELM 這個模型他們就有在 iPhone上面部署,然後就是有跑 所以他們,就論文裡面有寫 所以說接下來的 這個WWDC 很多人都說要發表這個iOS18 那這18 會有哪一些AI Feature 就是大家可以去 關注一下這樣 那現在就來做QA的時間 那這個,我覺得這個QA的Section 我之後想要多加一點
(49:05~50:05) 因為我覺得 我大部分時間都沒有跟大家互動到 其實是蠻可惜的 很多人其實有留蠻不錯的留言 所以我應該要來多念大家的留言 那現在 我就是有很多債要還 很多之前的留言沒有回到 所以我現在的念法就是會 可以參幾則最近的留言 以及參幾則以前的留言 那我覺得 做到後來呢,總有一天這個以前的留言 就會被用光,然後就變成是 每週就是回覆可能 上週或是上上週 有一些比較 有趣的留言這樣子 好,那首先我們來回答這個 Spotify的問題好了 首先這一則呢是 EVA在兩個月前留的 不好意思EVA 我兩個月都沒有回到你 好,那我現在回你 我一直很想請教要讀論文的話 可以去哪裡找,你會怎麼讀論文 還有大概多少時間多少 篇之類的,我想學習 那你兩個月前問這個
(50:05~51:05) 你現在搞不好已經是論文 高手了,我不知道 但我可以分享一下我的方法這樣 那首先我讀論文就是為了 隨時跟在就是 AI技術的最尖端 隨時了解最新的AI趨勢 而已,我並沒有自己在做什麼 研究啊之類的 我只是了解趨勢這樣 那我在X上面有追蹤 一些帳號是他們 他們的帳號的Value Proposition 就是會定期的發 一些論文出來這樣 有些人是發當週論文的 排名,有些人是發 最新的論文的一些 簡介這樣子,那我有Follow 這些帳號然後他們就會 Poll然後我就會看到,我就從這邊 知道論文的這樣 那這些帳號就包括像是AK 這應該很有名的 就是Machine Learning的人可能 蠻多人都看過這個帳號,A跟K 就AK這樣 除了他以外還有一些其他的我現在 想不太到,那會怎麼讀論文 就是當然也要看我讀這篇論文的
(51:05~52:05) 目的是什麼,我如果是 只想要快速知道他在講什麼 我就就是用快速的讀法 那我有時候也會想要非常 細細的去 了解他每一句在講什麼 那就是我想學東西 學很多東西的時候,那那個讀法 又不太一樣,那其實大部分情況 我只是想要快速知道他在講什麼 那這個時候就可能是 第一個我會先看Abstract 這是我一定會看的,一定會一字不都 全部看完的,就是Abstract 因為他也很少,這樣 那看完Abstract,我可能就會滑下去 看一些圖表這樣 然後看完圖表之後,我就把 首先我會先 看這個Introduction section有多長 如果也沒有說很長的話 我可能Introduction section也會把它看完 但如果就是 我不想看,或者是他很長之類的 我就可能從Introduction 直接框到 任何我有興趣的地方 比如說Methodology結束,在Eval之前 之類的,直接框到 這邊之後,然後直接貼到Chad GPT
(52:05~53:05) 裡面,然後做一個認知確認 就是我會一句句答出我對於 這個論文目前的認知 我猜想他應該是,我認為他應該 是怎麼樣運作的,然後這個Chad GPT 就會跟我說,這個認知是對還是不對 哪裡對哪裡不對 然後不對的話,我就會再問Fallout的問題 然後叫他跟我說 是哪一段講這個,或者我也可能會 回論文去看那一段 他本文是怎麼寫的之類的 好,接下來是這個Sky Lee 20天前在Spotify發表的留言 他說,關於Devon事件 我覺得Harry的切入點是對的 但網路上的言論是針對 宣傳片的造假,over promise 正如Gemini當初宣傳 片那樣造假 好奇為什麼Harry這次的觀點會180度大轉變呢 我覺得 這兩個事件 對我來說 他的程度有點不一樣 然後給我的Kimochi也有點不一樣 首先這個Devon 的事件,我覺得他的 宣傳片,你如果要說他over promise yes,他確實是
(53:05~54:05) 可能有一點點美化了 這個產品 覺得他實際跑的時候 他跑得這麼快,然後他 有些很大的缺點都沒有秀出來 比如說,你其實跑了一天 他都沒有講,然後過程中 他可能自己寫出了一大堆bug 要fix這些bug 這些比較醜陋的部分都沒有秀出來 但是他沒有講錯任何的 feature,就是Devon能做到 哪些事,他就講那些事情 儘管他把Devon做這些事情 的能力美化了很多 這樣,這對我來說 就是一個,我是可以接受的 一個demo影片 因為我知道,首先我關注這個 Agent領域很久了,我知道這個Devon 當然不可能像是demo影片 這麼完美的去解決這些問題 然後,但是我也同時也知道 他這個這些 可能實際上遇到的這些 小缺陷,比如說 一些GPD API很貴啊 然後這個他會講錯話 這些問題未來都會大幅的 改善,然後就算是今天的Devon
(54:05~55:05) 他可能跑一萬次裡面 也有一次可以跑到 像是他demo影片那樣子的程度 他是可以做到這件事情的 只是,他不能 常常做到這件事情,然後 他給大家的感覺是 他好像隨時開起來都可以 有這樣子的表現,所以說 大家覺得被欺騙了,這邊我也可以理解 但,如果你單純是 在批評說Devon 你就是over promise 然後廣告不實的話 我是覺得這個批評 是合理的,但如果你是批評說 這個產品沒有未來 那我就覺得很糟糕 那Gemini是怎麼樣的狀況 Gemini的影片,我就感覺到 我自己被騙,因為我是覺得他們 把feature給講錯了 就是他明明沒辦法理解 影片,你為什麼要放一個影片 然後感覺好像Gemini看著這個 影片做回答 這個feature是不存在的 但他們讓我以為有這個feature 然後後來我跟Google的季懷新博士 聊到Gemini這一點
(55:05~56:05) 然後他是跟我說,這個影片 是在展望未來 現在Gemini還做不到,但是未來可以做到 那這點我也可以理解啦 確實未來Gemini一定會有這個影片 應該說現在已經有啦 對不對,現在他已經可以了解影片啦 但我是覺得現在很多 這些產品的影片 他的demo跟展望未來 之間的這個線 已經變得很模糊了 很多時候你真的是 你不知道哪一個是哪一個 反正在這種情況之下 我自己的底線就是 你不要讓我以為你有 你沒有的feature 你所有的feature都要是真的 那這些feature實際上 是不是能很好運作 這個我們可以再看 最後有一則,順便回一下 一樣是Spotify的李 11天前他說 哈利洗澡先洗頭還是先洗臉 給我參考一下 我先洗頭啊,我洗澡的時候不會洗臉 應該說那個水 留下來會順便搓一下
(56:05~56:49) 但我不會特別去洗臉 我洗臉就只有早上洗,起來的時候洗 其實我也不確定這樣是不是 好的,我覺得我skincare 也沒有做得很好 很奇怪明明是 這個拍影片的 我覺得我應該是要做好一點 我覺得比起我給你參考一下 你應該給我參考一下 我應該怎麼洗臉比較好 那今天就講到這邊 如果你喜歡科技浪的話 一定要幫我五星評分留言 把科技浪給分享出去 讓你的朋友們知道 同時也謝謝今天的贊助商NordVPN 大家可以到本集資訊欄裡面 使用我的科技浪專屬連結 去購買這個服務 你可以得到免費四個月的優惠 最後也祝大家有個愉快的一周
