(00:00~01:01) 【音樂】 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式 帶你了解時下最火的科技話題 本期節目由Speak贊助播出 Speak是一個語言學習的APP 目前可以學英文跟西文 那這個Speak這間公司呢,其實挺特別的 它背後的金主是OpenAI OpenAI有個投資新創的基金叫做OpenAI Startup Fund 那這個基金呢,Sam Omen本人也有說 這個基金他只會投資那些 真的在解決非常重要的問題的新創公司 然後同時呢,他們不會廣撒 他們只會挑幾間最有前途的公司來投資 那我們今天的贊助商Speak就是其中一間 所以說他真的就是一個OpenAI認證的公司喔 那這個Speak顧名思義啊 它就是專門幫你練習口語的一個APP
(01:01~02:03) 它下載是免費的 然後下載下來之後呢,它會先問你一些問題 然後根據你的回答 幫你客製化一些口語的課程這樣 就是他們會一句一句的教你怎麼念 然後讓你不斷的練習 然後除了這些口語課程以外 他們還有一個很大的賣點就是他們的AI家教 這些AI家教呢,就是可以跟你聊任何你想聊的話題 你可以透過跟這些AI家教聊天的過程中呢 來主動的練習你的口語能力 不過這邊呢就是需要付費解鎖的部分了 大家也知道這些LM的運算資源不便宜啊 然後除此之外呢Speak也是高度遊戲化的 它會有一些什麼挑戰啊之類的 有些成就要解鎖 所以說可以持續的激勵你一直來學習 那我覺得我們亞洲學生呢 在英文的這方面 口語能力一直以來都是聽說讀寫裡面最弱的那個 那這也是非常明顯的 其他的比較好scale 就是比較好規模化的教學的意思 你一本閱讀測驗你可以隨便印一萬份 但是口語能力的練習就不是很好scale
(02:03~03:05) 那今天呢我們有了這些生成式AI的科技 我們終於來到了一個可以scale口語練習的時代了 那我覺得這個Speak呢在做的就是這件事情 你如果想要練習你的英文或是西文口語的話 可以在本集的資訊欄找到Speak這個程式的連結 你可以先免費下載來玩玩看 再決定要不要付費購買他們的AI家教 本集業配就到這邊結束謝謝Speak的贊助 好那我們今天的科技浪邀請到了一個非常重量級的來賓 這個人呢就是季懷新博士Ed Chi Ed他是Google的傑出科學家 傑出科學家這個職位在Google是L9的職位 你如果不知道的話Google的scientist跟engineer 都有分這個職位等級 然後你最一開始進去的菜鳥就是L3 然後最高級最高級像是Jeff Deano等級的就是L10 然後我們今天的來賓Ed是L9的科學家 所以真的是非常非常高階的一個職位 就是一個senior director level的這樣子的一個職位
(03:05~04:06) 他底下也是帶了上百人的這個research team 那他同時呢也是ACM的fellow 這個ACM也就是美國計算機學會的fellow的這樣子的頭銜 他是一個在計算機領域非常非常高的一個榮譽 全台灣也才九個人有這樣子的一個榮譽 然後這個季懷新博士呢他就是其中一個 那他在Google專攻的領域呢有兩個 第一個是推薦系統 Google有超級多的產品 包括YouTube YouTube Shorts Google Play很多的這些推薦系統 他都是背後的大功臣 然後在LM這邊呢像是Bard這個產品 然後跟他背後的一個語言模型Lambda 就是之前用的這個語言模型Lambda 都是他的團隊做的 那Ed這次來台灣呢其實也只會待短短的幾天而已 然後在這幾天之內他的行程真的是完全滿檔 大家都想要他的注意力 其中也包括這個天下經濟論壇 那我們科技讓呢竟然有幸可以邀請到他 真的是非常非常的開心 那我們這次的訪談呢會分成上下兩集來播出
(04:06~05:08) 上集會在這禮拜播出 下集是下禮拜 上集的部分呢我們會聊到Ed他的個人經歷 以及他在Google D-Mine做的一些研究 那這部分呢聽也知道會比較技術一點 那你如果中途有聽不懂的地方呢 都歡迎去看本集的竹子稿 在本集的這個資訊欄連結就可以找到 那竹子稿呢我並沒有一個字一個字的做訂正 但是我在專有名詞的部分我全部都有檢查過 所以說專有名詞大家可以放心的去查 下集的部分呢我們則是會聊到一些AI的大趨勢 以及Ed想要給年輕人的一些建議這樣 那這一部分呢就比較沒有那麼技術一點 好的那以下就是我跟Ed的訪談 OK Ed歡迎來到科技浪 謝謝 好那Ed你在AI這個領域已經深耕了超過20年了 可不可以跟大家分享一下你的新的歷程怎麼樣 就是你怎麼樣從美國的明尼蘇達大學 花了六年半的時間就拿到了學士碩士跟博士的學位
(05:08~06:15) 然後之後你就進入Pella Alto Research Center 在裡面當到了首席的科學家之後 在2011年進入了Google 然後你就一直從Google做到了現在 變成Google的Distinguished Scientist 跟大家分享一下這一切怎麼發生的 我當年一直對電腦很有興趣 那時候是實際上是因為我爸爸在丹安大學任教的時候 有一天從這個電腦展那個地方就找了一個電腦回來 我那時候還很小 然後就看這個東西 當然很多那時代的年輕人都是以玩電玩之類的這些遊戲開始 那當然那是很早以前的時代 那我後來去了美國以後就一直決心要念電腦系 那我念那個部分的時候呢 那時候事實上是做Computer Graphics最強的時候 Computer Graphics大家也知道就是說
(06:15~07:17) 它是一個以當年來講是運算需要更多的技術支持的一個部分 然後所以它的Data量 它的Computer的這個量數 也都是最頂尖的技術那時候 所以我事實上是原本是念Visualization of Data 跟Graphics那個地方出生的 然後後來念完碩士博士以後 去Zerox PARC的原因也是因為 那個地方當時是人機介面的Research 大概是最好的Research Center 那我在因為我父母原本都是教授 那我就一直想說 我也應該做Academic那方面的這種Research 學術上面的Research 所以就一待就在Zerox PARC待了13年 然後後來才下定決心說 要去一個像Google這樣子的公司去做其他的事情 所以這個徐徐則則的吧可以這樣講
(07:17~08:17) 就是慢慢的步入做Machine Learning這方面的這種Research的一個路程 了解然後你進入Google之後 你早期是比較Focus在Recommendation System 然後後來就是可能最近這幾年開始有分支到這個LM的Research 那可不可以跟大家講一下 這樣子的Transition是怎麼發生的 因為之前可以這樣講就是說 Machine Learning它原本就是一個Pattern Recognition的一種技術 那以Pattern Recognition的角度來看推薦系統的話 它就是說如果我在Data裡面看到這樣子的Pattern 那我就要做這樣子的一個推薦 所以它事實上在起步的階段 譬如說2000年那個階段到後來10年來的這些推薦系統的發展 都是以這種Pattern Recognition 而且跟Visual Perception或者甚至於一些Audio Recognition的這些Technique
(08:17~09:17) 都有相似的地方 那當然推薦系統它因為在商業的應用上面 有很大的商業的契機 所以呢我在那方面也就是花了很多年的時間 就專門是在研究推薦系統 但有一個比較很多人不知道的事情就是說 我當年在念博士的時候 我的Advisor是一個名叫做John Riddle的一個人 John Riddle剛好很多人認為他是Collaborative Filtering的father 因為他跟一些其他我的教授朋友們 發表了當年最重要的Recommender System的一篇Paper 所以我是經過輾轉做了Graphic、做了Visualization 跟我的Advisor做那些Research之後 一直到大概2009年左右
(09:17~10:18) 2008年的時候才真正開始做推薦系統的Research 然後就發現這個Pattern Recognition的Connection 不過我蠻有興趣的就是你加入Google的這一年 就是差不多是深度學習革命剛要開始的一年嗎 那你說你的執照教授其實是在做Collaborative Filtering 是不是你進入了Google之後 這個推薦系統這邊也開始要慢慢進行深度學習的改革 然後從Collaborative Filtering慢慢走向Neural Network 對沒錯而且你問的這個問題非常好的原因就是因為 很多可能在聽的朋友們都知道說 當年很多Pattern Recognition的Technique 最初都是從線性數學的方法在做Linear Algebra的方法在做 然後那一方面的Development一直大概做到 可以說是到Mid 2000那個時候
(10:18~11:18) 然後到後面就慢慢有更多的其他的Machine Learning的Technique 特別是Kernel Methods、SVM 或者是一些其他我們所謂叫做Factorization Method的一些做法 然後那個跟線性Regression Linear Regression的這些Technique 一直大概做到2013、2014那個年段 然後因為你說2011嘛那個深度學習的崛起 所以從差不多2013、2014的時候 開始就有很多人用深度學習的方法來做推薦系統 所以那個我在那上面也花了好幾年的時間 現在這個深度學習系統也是這個推薦系統的主流 就是大家主要就是它主要的這個推薦系統的大腦就是一個Neural Network 但是它其實是不是還是有一些原本的Traditional Classical Machine Learning的方法在跑
(11:18~12:19) 可能還是會用一些Matrix Factorization 或是Collaborative Filtering在做前面資料的一些處理之類的 現在最先進的一些推薦系統的公司基本上都在用Neural Network的方法 就是一個單純的Neural Network這樣 基本上都可以算是這樣子的 當然之前的一些Idea像譬如說你看我們現在所用的一些所謂叫做2 Tower Model 它中間的這個大Product還是跟以前的一些Idea是有connection的 但是基本上現在幾乎所有的推薦系統都是用Neural Network的方法 而且很多人有問過我這個問題就是說 後來也有一些新的公司像譬如說TikTok他們在做的一些推薦系統 跟我們在其他地方做的推薦系統有什麼不一樣 但基本上現在的主流都是用非常相似的方法在做推薦
(12:19~13:22) 而且都是跟這個Pattern Recognition非常有關係 所以說神經網路就是在做Pattern Recognition的一個machine 最起碼之前式的 不好意思 最起碼之前式的 神經網路的話就是說以之前的最主要的Focus就是Pattern Recognition 所以說其實這個推薦系統它背後就是一個神經網路 LLM背後基本上也是一個神經網路 只是它是非常非常大很多層的神經網路 所以說對你來說這個Transition是一個蠻自然的Transition是嗎 可以這樣講吧 其中有一個比較如果說是只是學過神經網路的人可能比較沒有仔細去了解 過去大概這六年七年的發展的話 這個Transformer Technology事實上之前2015年的時候
(13:22~14:23) 有一個革命性的新的想法就是所謂Sequence to Sequence Learning的方法 這個方法這個想法事實上是突破了之前的這種Pattern Recognition的一個思考方式 因為什麼呢 因為之前大部分就是看到一個Pattern然後我做一個Prediction 像比如說我有一個圖像然後我要說這個圖像裡面是個Lion還是一個Cat還是一個Dog 這種情況下它所做出來的方法是一堆資料進去然後一個Prediction出來 但是以Sequence to Sequence的這篇Paper2014年12月發表的一篇Paper 它想法不一樣 它想法是說我要輸入的是一個Sequence of Information 然後我要輸出的也是一個Sequence of Information 所以從2015年所開始的一個革命性的這種思考的方法就演變成
(14:23~15:25) 用其他的方法來做Sequence to Sequence的Learning 那為什麼當年Google Brain裡面的科學家對這個東西特別有興趣 事實上也就跟自然語言的processing有關係處理自然語言的processing有關係 譬如說Translation或者是Question and Answering或者是聊天機器人這樣子的方法 我們就開始在想這種Sequence to Sequence learning的問題 所以就是比較像是從一個單純的Pattern Recognition變成一個去學習你的training data的distribution 然後把這個distribution recreate出來類似這樣 我會覺得說更容易了解的部分是之前可能是一個Data的Pattern 然後你要做一個Single Prediction 那現在是我要不單是生成一個Prediction 我要生成一個Sequence of Prediction
(15:25~16:27) 那這個Sequence of Prediction事實上是從科學的角度來看這個東西 我生成第一個字 那我第二個字會被我第一個字產生影響 第一個字我說什麼之後第二個字我會說什麼 這個是一個conditional probability的chain 所以從那個角度來看的話 我們並不是只是生成一個Prediction 而是生成一個Sequence of Prediction 所以這個跟forecasting很有關係 接下來我想聊聊在Google DeMine你做的一些研究 首先當然我們要先從就是audience favorite Gemini開始講 那首先我想先請問就是大家去看這個Gemini的Technical Report這個Paper 它裡面有列出900多個作者900多個co-author 為什麼會有這麼多的co-author 然後你也是其中一個嗎 那你在這個Gemini的project裡面扮演什麼樣的角色 這個問題非常的interesting
(16:27~17:32) 因為這跟Google的culture也有關係 Google的這種研發的模式是屬於一種比較開放性的一種研發模式 就是說有多少人對這個topic有興趣 他們很多人都會想要來參與這樣子 那以Gemini的整個project的development來講 當年大概一年前左右的時候我們開始的時候就有一個call to action 就是說誰想要做下一輪這方面的research 那當然有很多人都有興趣 那我當時領導的團隊叫做Lambda 那也就是後來衍生成BAR的這個研究團隊 那我們事實上是在做另外一個base model的research 我們當時叫做primer 那所以Gemini剛開始的時候我的團隊事實上是並沒有參與的 那後來我們這個Lambda的團隊跟Gemini之間的關係是
(17:32~18:34) 因為我們負責的後來是越來越傾向於post training這一塊 就是base model的training做到某一個地方的時候 我們那個地方覺得第一個phase等於是結束了以後 之後有我們所謂的這種instruction fine tuning的這個步驟 這個部分事實上我們一直認為 因為Lambda在做BAR的時候的一些experience 發現這個post training事實上比pre training甚至於有時候會更重要 是RLHF的部分嗎 RLHF事實上只是post training的一部分 而且不見得完全是就是說它是比較難做的一個部分 所以我們有另外一個phase叫做supervised fine tuning 也就是這個flum也就是這個instruction fine tuning這一塊 事實上我知道我偶爾知道我們一些其他start up那邊的團隊 也都在看我們的paper 也許Harry你也知道就是說Google在這一點上面
(18:34~19:39) 不管是sequence to sequence learning或者是transformer 或者是instruction fine tuning或者是chain of thought 這方面這八年來的一些最重要的研究突破都是從Google的研究團隊出來的 那我想問一下你們那時候是怎麼從POM2scale到Gemini的 就是你們在設計在train這個Gemini模型之前 你們要設計它有多少個參數 然後你們要用什麼資料去train它嗎 那這個你們是怎麼想這個問題的 你們有沒有follow什麼樣子的scaling law 對你問的這個問題非常好 就是因為2023年初期就是大概1月到2月3月那時候 大家都在看這個neural scaling law的paper 然後就在想說如果這個問題 最主要的問題是在於它的這個運算的提升 它的這個所謂這個computer scaling 或者是data scaling的話 那我們的investment從研發的角度
(19:39~20:39) 也應該從scaling的這個角度來去做最重要的這種investment 所以這個Gemini剛開始的時候 完全是follow這樣子的一個hypothesis 當然一年了以後我們也發現越來越多 這裡面不只是base model的pre-training非常重要 其他的部分也相當的重要 特別是instruction fine-tuning 那你們這邊Google的DEMY有出一篇Chanchella的論文嗎 非常有名的一個scaling law 那我是在你們的technical report裡面有看到說 Gemini也是follow這個Chanchella的scaling law去train的嘛 那我覺得因為現在很多這些大型 非常大的大型的模型都沒有公佈他們的參數 所以我們也沒有辦法去根據這個Chanchella 抓出說你們可能用了多少資料去train這些模型 但是很多人說在猜測就是可能Gemini Ultra
(20:39~21:39) maybe有超過1 trillion的parameters maybe 當然這個你應該也沒有辦法公開講嘛 而且事實上我們現在在學術上面探討這個問題的時候 我剛才也有透露一點就是說 這個參數的數字可能反而沒有其他的一些因素還要更重要 當然好幾年前在Near Eps的conference的時候 有一個也是Google來的學者 他要說你們怎麼做這些深度學習的一些科學家 怎麼好像覺得好像Alchemist 就是那調一些奇奇怪怪的這種recipe 然後就希望他能夠work這樣子的一個情況 事實上現在的有一些這樣子的情況就是說 我們事實上對某一些參數 或者說為什麼要這樣子做並不是非常的了解 為什麼這樣子的combination work
(21:39~22:40) 那樣子的combination就會出問題 所以有很多現在這方面的research 並不完全是science 更屬於一種engineering的表現 了解 不過不管這個Gemini Ultra的參數多少 我們知道的是根據Chernchella的scaling law 你的訓練資料要跟著你的parameter一起scale 你要等量的增加你的訓練資料 才可以最好運用你的運算資源 那這是不是代表說 Gemini用了非常非常大量的訓練資料下去train這個模型 然後這邊有一些人會開始有問題的就是 網路上真的有這麼多的訓練資料嗎 有幾十個trillion的訓練資料那麼多嗎 事實上資料的來源並不見得是最困難的部分 而最困難的部分是知道說 哪一部分的資料是有用的 哪一部分資料是沒有用的
(22:40~23:41) 而且我們這一年來所得到的很多的experience就是說 之前我們所知道的machine learning的golden law golden rule你可以這樣想就是說 garbage in garbage out 所以你要好的資料進去你才有好的結果 所以這一年來我覺得最坎坷的心理路程 可能是在data的quality的control上面 特別是我的團隊在這方面花了很大的精力 那這邊可不可以分享一下你們怎麼樣定義一個好資料 這問題也難為什麼呢 因為在某種程度上你可以這樣可以用一個比方來講這個東西吧 就是說我們也知道物理學對不對 它是有它的theoretical的部分 也有它experimental的部分 那物理學常常是theoretical跟experimental的physicist 他們之間物理學家之間的一個對話
(23:41~24:44) 比如說我們experiment出現這樣子的phenomena 你這邊theory有沒有辦法去解釋這個東西 然後theory這個地方是make a certain prediction 然後experimental這邊你是不是看到這樣子同樣跟它吻合的一些資料 所以我們現在事實上是處於 最起碼從大型語言模型的角度發展的角度來看的話 現在是處於一個非常experimental的stage 就是theory並不能完全能夠解釋我們現在看到的一些pattern 所以您剛才問的這個問題有關於什麼是好的data這個問題 事實上它是有可能是有一些相對性的 比如說在你之前trained的model 它可能已經有很多比如說數學方面的訊息 那你在加其他的數學訊息進去 事實上是不見得對model是好的事情
(24:44~25:49) 所以它是有一些對比或者是一些selection的問題 以前在machine learning的field裡面的話 就常常會做一個叫做curriculum learning的research 我在做training的時候 這個data example是怎麼樣去選擇feed into the model in what order 什麼樣的sequence的這種問題 現在都有很多我的團隊也好或其他的團隊有在探討這個問題 所以什麼是good data這個問題 基本上可以說是我們最頭痛的問題 要經過非常多的實驗去慢慢摸索 怎麼樣子的data feed進去 然後用什麼樣order才會比較好 而且現在最有一個我甚至可以說是相當火熱的research topic 有一個hypothesis是說你可以把這個數量減到非常非常的小 as long as you can figure out what is the perfect data set in what sequence
(25:49~26:51) 因為我們有看到像是Microsoft他們做很多小模型 像是Fy2那種 他們就是靠著非常好的textbook level的data 然後發現說這麼小的一個模型可以outperform比它大非常多的模型 而且現在open source開源那邊的模型也有相似的research paper出來 就表現說你只要那個base model到達一個reasonable performance level的時候 你post training那邊的data如果好的話 事實上是可以補救一些之前的不足的地方 OKOK 然後其實我覺得如果退一萬步想我們從人的角度出發 就是我們人腦怎麼學習 我們其實真的花非常少量的資料 就可以學會做很多事情了 一個高中生花了大概20分鐘就學會開車了
(26:51~27:53) 但是一個neural network可能要花幾千幾萬小時 不止不止幾十萬小時才可以學會怎麼樣開車 所以說maybe data量真的不是最主要的問題 而是我們怎麼去figure out 怎麼好好運用資料跟什麼樣資料才好 是的 而且我覺得你想出來的方法去解釋這個問題 也可以用我之前回來台灣的時候有做過一個比喻 好像base model的training有一點點像是一個剛剛刮刮落地的嬰兒 它可能有這個當然是在生物學裡面有一些controversy 也就是說它可能生下來它具有一些天賦異稟的capability 它如果智商譬如說已經非常的高 你輸入的data可能就不需要很多 它也能夠有很好的performance
(27:53~28:55) 但是它如果生出來之前的智商就不是很高的話 那你輸入的data就要更多 所以現在的大部分的科學家是有這樣子的一個hypothesis 就是說我們的大型原模型也是follow類似這樣子的一個pattern 了解 接下來我們來聊聊Gemini的multi-modality 這個算是Gemini最大的賣點之一 是 那Gemini它的multi-modality並不是組合起來的multi-modality 它是原生的multi-modality 意思就是說它是可以同時處理每一種modal的資料 像是text,image,video,audio 它是可以同時處理這些資料 不像是一些組合模型是可能一個負責處理image的模型處理image 處理audio的模型處理audio 然後最後再把它們組合在一起這樣 所以Gemini是一個原生的大型多模態模型
(28:55~29:55) 為什麼會想要把它做成一個原生的大型多模態模型 然後你們是怎麼做到的 這個地方有一個小插曲的地方事實上就是BAR 像比如說一些它圖像處理的capability 也是我的團隊後來做的 那為什麼一直知道說 第一我們要探討的問題是說 為什麼要做這個multi-modality in the same model的問題 這個部分我們之前已經了解到就是說 我們從artificial general intelligence的角度來看 一個現在的發展趨勢的話就是說 一個人並不只是能夠說話能夠communicate 能夠用language來做思考的動作 他也能夠聽能夠看到東西 所以我們一直覺得從發展AI的角度來講 一定要有multi-modality的capability 只是問題是說為什麼要native為什麼要原生
(29:55~30:55) 這個部分也就是有一部分是因為 跟在想說人類是怎麼樣達到這個capability的 我們在講話的時候 眼睛還是繼續在看還是在吸取information 然後我們會按照那時候的情景 做不同的語音或者是語言的處理 所以原生的概念的原因就是說 我們不想要說這個是分開處理的 因為我們覺得人類的頭腦不是分開處理的 那為什麼機器的方法也要分開處理 這是一個原因 另外一個原因事實上是我們已經看到 Transformer這樣子的architecture 它在自然語言處理的這個部分 已經是一個multitask的model 比如說我們沒有一個分開translation的model 跟一個question and answering的model
(30:55~31:58) 也沒有另外一個比如說image to text的model 這都沒有分開 它全部都是在同一個model裡面 這種integration有另外一個可能性的是什麼呢 就是說它能夠做一個generalization的表現 我給你一個example 我們在五月的時候在發表一個新的BAR model的時候 就提到這個capability 我們現在可以問BAR 比如說 Can you debug this program and write all the comments in Korean 那它是一個模型就可以做到所有的這個部分 Can you provide an explanation for why the bug is there in English 所以它是整個是用統一的一個模型 在做這個unified的一個model在做這個東西 所以這樣子的一些比較complex的一些task
(31:58~32:59) 我們希望這個model能夠以後都同時都可以一起同步的在做 那能不能分享你們是怎麼做到這件事情的 原神的multi model 這個問題好的原因是因為 第一我們在開始做的時候就已經知道說 因為transformer model是剛才講的sequence to sequence model 的一種表現的方法 所以它是一個所謂我們叫做token in token out的一種model 那跟image那邊或者是video那邊 事實上還有另外一種方法 可能大家比較沒有在做語音處理或者是圖像處理的人 可能比較不會碰到的東西就是我們所謂的diffusion model 那diffusion model的看法 跟它的運算的方法事實上跟token in token out的這些model的capability是很不一樣的
(32:59~34:05) 那在Gemini這邊我們做native multimodal的時候 就是把所有的圖像也好 語音也好或者是任何這種audio的signal 全部都把它變成token based representation 然後做token in token out的處理 了解 所以你們是有每一個model都會有一個類似embedding model的東西 把它map到一個共同的token space 沒錯 然後把這些混雜了很多modality的token sequence當作input 然後output就是text跟image 對 所以你也可以看得出來就是從你這個問題 可以看出我們剛才在聊有關於這個pattern recognition 跟現在的這個sequence to sequence model之間的一個bridge吧 你可以這樣想 因為我們token in token out如果是一個single token out的話 它事實上就是一個pattern recognition的問題
(34:05~35:10) 所以這整個學術的發展事實上是有路可循的 了解 那再來我們來講講Gemini的demo Elephant in a Room 就我自己在看那個demo的時候 我一開始看 我們應該在講同一個demo就是那個五分鐘的demo 我一開始看我是覺得 OK它應該是因為我先看了你們的technical paper 所以我是覺得你們是拿video跟audio做為input 然後Gemini吐出文字然後你們再用text speech這樣 但是後來發現是你們是用文字跟圖片做為input 所以說這是不是代表說Gemini的video跟audio的modality 還沒有到那樣子的程度 然後你覺得什麼時候Gemini可以做到這個程度 這個東西事實上也許大家知道這裡面細節的人也都非常的了解 就是說要process像比如說video這樣子的signal
(35:10~36:10) 事實上是需要非常目前為止是需要非常非常強大的運算能力才能夠做到的 所以我們可以展望未來的話就是說你從現在的這些TPU也好GPU的這種development 特別是台灣的半導體特別的強大的地方 我們都可以看得出來說往前走這些technology會到什麼樣的地步 所以已經可以看得到說 within the next couple of years再過來掌握這幾年來 我們這些computation capability應該是可以達到那樣子的需求的 所以就那樣子的一個demonstration事實上是在展望未來說 我們到達那個運算能力的時候能夠做的事情是什麼 所以我覺得有一個很有意思的地方就是說 科學家有時候是在想說現在的運用是能夠運用到什麼樣的應用程式
(36:10~37:10) 一種application的角度來看這個東西 但有時候科學家的另外一個想法是 如果我們把這個technology把它push到extreme我們能夠做什麼東西 那我們想要做這個prediction 因為我們一直在做machine learning就為了就是做prediction 所以就很多科學家就會想說 ok如果我們這個technology是三年以後會是什麼樣子 五年以後會是什麼樣子 所以你覺得距離GEMNAC可以做到demo這樣子的程度 最大的bottleneck就是算力而已嗎 其他的像是資料或者是模型的架構上面都是可以支援的 沒錯這個就是我覺得以現在的革命的progress來看這個問題的話就是說 我們剛剛講的就是theory跟practice 以practice那個地方engineering的角度來看這方面的發展
(37:10~38:13) 我們現在是可以做很accurate的prediction 就是說我們運算能力如果到這個地方的話我們能做的東西是什麼 這個是有很多有跡可循的 但是科學這個地方的話比較難的地方就是說為什麼我們能夠做到這些東西 我們現在比較不清楚為什麼能夠做到 這是mystery的部分 那Ed我有去偷偷看一下你最近的一些研究的論文這樣 那我發現你在LLM這邊的研究你蠻focus在LLM的reasoning這個領域 那尤其是我看到你有call author一篇 我覺得是這一兩年在LLM reasoning領域應該是最重要的論文之一 叫做Chain of Thought Prompting 我們簡稱COT好了 你們會這樣簡稱嗎 對我們就說COT 那能不能先簡單跟大家介紹一下什麼是COT 然後是什麼啟發你們開始研究COT
(38:13~39:16) 你問這個問題我還覺得有一種幾乎是這種emotional的reaction 原因是什麼呢 因為我在加入Google之前事實上一直是在做人機互動的一個research界面的research 那我參加的Xerox Palo Alto Research Center的團隊 裡面事實上不只是有computer scientist也有psychologist 而且那邊的psychologist當年都跟諾貝爾德主Herb Simon有淵源 然後另外一個Touring Award的winner Alain Newell也是我那邊的領導團隊Sue Carr的先祖先師可以這樣講 就是老前輩 那麼我在他們那邊學到很多computer science的東西 那從那個角度來看這個Chain of Thought的想法的話就是說
(39:16~40:16) 我們人類在思考的時候很難把所有的東西都記在頭腦裡面 像譬如說我們現在在做這個interview訪談的時候 你也是有一些notes在手上 原因是因為你不是沒有想過 你全部都想過了你有準備 那準備你如果沒有寫下來的話 你沒有這個augmentation的話 你是很難記得所有的細節的 那我們後來的想法就是說LOM大型語言模型也一定會有同樣的問題 而且我們事實上是知道說這些大型語言模型 它一直有一個很大的問題就是說 它的因為它是用attention mechanism 它的contact length是有限的 一旦超過譬如說4K或者是8K 當然現在最先進的model可以做到32K 或是有些人claim可以做到更高的一個contact window 但是一旦fall outside token length
(40:16~41:22) 超過限制的時候東西就可以忘了 所以我們當時在想Chain of Thought的一個原因就是 這個cognitive limitation就有點像人腦的問題 那你唯一其中一個方法是什麼呢 就是不停的summarize然後reduce 所以Chain of Thought其中一個當年 所以才一年前的事情 一年多前的事情就已經覺得很久以前了 不過那時候的想法就是說 you have to write things down to remember it 那你有explanation 有一些更好的reference material的話 你的思考能力也會增加 所以Chain of Thought事實上是跟cognitive science那邊的想法很有關係的 很有淵源 所以你們就是發現說讓LOM一步一步去思考 應該說你們用一些example引導他一步一步去思考來解決一個問題
(41:22~42:22) 會發現說他這樣子解決會比他直接用直覺下去解決成果好非常多 你可以這樣想就是說 我們在解決很多問題的時候都會按部就班 把它分解 然後呢先解決part A然後再解決part B 然後再把它組合在一起 我們的想法就是說 這個LOM也需要做同樣的步驟 好那現在我覺得從前一陣子那個OpenAI的Q-Star leak之後開始 我覺得有很多的machine learning的人 開始去對於LOM reasoning這個領域有很大的興趣 因為那時候就是說 大家覺得這個OpenAI的Q-Star應該就是一個讓LOM可以reason的一個技術 然後可以讓他解決一些可能國中國小的數學問題這樣 那目前我覺得絕大多數人的共識可能是 有用幾個component組合起來
(42:22~43:22) 就是把LOM跟Chain of Thought結合 然後再結合一個search的algorithm 然後再結合一個可能self-improve reinforced learning的方式這樣子 去做一個讓LOM可以去一步一步自己去檢視 然後思考的一個模型這樣 那我覺得最有趣的就是 今天早上剛剛看到了Google DeepMind出了一篇論文 是這個Alpha Geometry 那應該說嚴格來說是今天凌晨啊 就是美國時間嘛 那我今天早上 而且就是我的團隊發表 Oh really? OK 正好 因為我今天早上看了就是說 欸等一下要訪問ad我來看一下 那我就發現說這個Alpha Geometry 基本上就是我覺得像是Google DeepMind的Q-Star 就是跟我們大家講的這個LOM加search
(43:22~44:25) 加一點點self-improve是有差不多的概念這樣 可不可以跟大家講一下這個Alpha Geometry 對 Alpha Geometry 這個特別是裡面的研究團隊 他們當時的想法就是說 很多人覺得solve mathematical problem 是一個很好的AI跟AGI的表現 所以我們可不可以用這個example來看能不能夠 組成一個模型能夠做到 超過99%的人類的這種capability 就幾乎是可以說是super expert 那樣子的一個capability 那這個幾個月前他們有這個研究成果了以後 我們準備要submit這個paper到nature的時候 他們就做過一些就我們組裡面的簡報 我覺得裡面特別impressive的一個部分就是說
(44:25~45:27) 我們剛剛也在聊原生性的multi-modality的問題 因為像geometry的problems 事實上常常是有圖片的 有一些很困難怎麼樣解釋給machine 說我這個problem的structure是怎麼樣子的 所以這個研究團隊裡面其中一個很重要的部分 事實上是problem representation 怎麼樣子能夠用token in token out的方法 來傳送到transformer model裡面去 然後當然也有你剛剛講的其他的問題 比如說synthetic data的generation 要generate很多很多的數量的example 來train這個model然後來看看它的capability 所以現在達到的技術標準就是已經可以看到說 我們可以達到非常非常厲害的數學家的奧林匹亞金牌運算能力 不能說是運算能力 這幾乎可以說是思考能力
(45:27~46:29) 就solve problem的capability 所以這也是我覺得一種里程碑的表現 然後你們在做的基本上就是給LLM一個 讓他幫助他reason的一個搭檔 你們在這篇論文裡面你們是把它稱作symbolic deduction engine 這個就是我覺得有一點類似2015年AlphaGo 它其實是兩個neural network 但是它配合一個multicolor tree search的方式 有點像是這種方式 就是因為LLM本身我看你們論文裡面寫說 它是一個可以把它想成一個system one 它就是一個直覺腦 根據它pre-trained玩這麼多的知識之後 它直覺覺得這個問題怎麼解 但是你如果再給它一個symbolic deduction engine 逼迫它說你把這個直覺你一步一步來 你產生這個方法然後丟給我的engine
(46:29~47:30) 然後看一下我們現在可以做到什麼程度 然後還沒有達到目標的話你再給下一步這樣 是不是這樣子做 你剛剛講的這個部分有一個很重要的concept就是說deduction 我一直認為reasoning這一塊 事實上是有兩個reasoning的這種表現 一個是induction一個是deduction induction的話當然就是說你有一個fact A跟fact B 你可以induct一個新的就是產生一個新的fact 比如說C 那C是正確還是不正確 如果C是正確的話我們就說這是correct induction 甚至於可以說這個system是非常的creative in solving a problem 所以現在的情況當然我們如果碰上一個國中生或者是高中生 在solve這些非常難的geometry problem的時候 它如果能夠解答它的話我們會說 哇你非常非常creative對不對
(47:30~48:31) 那如果machine也能夠做到這個部分的話 它也是非常的creative 所以有很多這個表現事實上是一個induction的步驟 另外一個是deduction deduction的話當然就是說A跟B加在一起 代表它是另外一個fact C是可以deduce就是說 這個C must be true in order for A and B to be true 這樣子的deduction 所以在這個整個geometry的reasoning problem裡面 有這兩個不同的表現是這個研究團隊特別想要了解的部分 了解 那其實這個alpha geometry它的結果真的是非常好 可以做到奧林匹亞金牌 但是這個alpha geometry它還是只能解決geometry的問題 甚至連其他數學領域的問題沒有辦法解決 它就是geometry這樣
(48:31~49:32) 那我覺得這個方向是對的 就是給LM一個reason的能力 但是我們要怎麼樣讓它可以跳脫一個domain specific的框架 讓它可以變成一個general的reasoning machine 這個問題呢從一個AGI的角度看這個問題的話 就是我們現在常常在想AGI怎麼樣去develop 就是由您剛才這個框架去思考這個問題 因為我們事實上在alpha geometry之前 有很多的domain我們已經可以看得出深度學習 或者是LOM也好 或者是之前的這種pattern recognition based的technique也好 或者是說alpha go的capability也好 它們事實上都已經在某些領域裡面已經達到superhuman的capability alpha go就是一個很好的example對不對 下期nothing beats a machine at this point 所以我們可以看得出
(49:32~50:37) 只要我們對某一些narrow的domain有興趣 我們都可以想出一個方法讓這個machine能夠有superhuman的capability 但你問的這個問題就好了 問題是說我們不希望要每一個領域都要花那麼多的精力 去create一個superhuman的capability 那有沒有可能性從一個科學的角度來講 當他學會了geometry 當他學會了下期 當他學會其他的skill的時候 他能夠把這些不同的能力組合起來 to solve一個新的領域裡面的東西 without additional teaching 這個是我們reasoning團隊特別有興趣的一個research area 在神經網路的這些學會裡面 這個領域特別是有一個學術名詞叫做compositional generalization
(50:37~51:37) 意思就是說可不可以把不同的skill把它compose起來 然後能夠solve新的problem 但是這個目前還是非常早期的研究領域 就是有一些明確的方向出現了嗎 有一些我覺得是有一些 像比如說我們剛剛在講的這個language learning這個部分 我們現在是可以看得出來說 甚至於有一個task在我們所謂一個benchmark裡面叫做bigbench 也是我們Google brain前幾年做出來的一個學術研究 其中有一個部分就是說 如果有一個人invent了一個新的language 那這一些large language model 他們多快就能夠學會這個新的language 我們發現這些model是有非常顯著 就是可以說是superhuman capability
(51:37~52:39) in learning new language 所以看得出來是有些東西是有這種pattern 這種transformer model是能夠handle的 所以我們是非常有希望說 在轉彎未來的時候這種compositional generalization 是within reach of our lifetime 然後你們覺得主要還是從transformer下手 就是我們不需要一個新的架構 我們只缺一些附加的component 這個是一個非常controversial的hypothesis 我覺得很有意思的地方 在討論這個問題的時候 大家對transformer有一些粗淺的了解的話 也知道說transformer它是一個 可以說是一種我們數學上面會叫做autoregressive的一種model 但是我覺得這些名詞 比如說autoregressive或者是mass language model
(52:39~53:42) 對很多人來講都是一個學術上面的一些 很難了解的concept 但我覺得事實上是有一個 很簡單能夠讓人了解的解釋方法 像我們現在在溝通的時候 我所用的一些詞彙或者是一些sentence 我不管在什麼時候停下來 你的頭腦都不停的在feel your initiative blank 而且是不由自己的 你就會一直這樣子 所以你有沒有發現說 雖然我們跟一些可能有一些speech impediment的一些人溝通的時候 雖然是有一些困難 但是他們停下來的時候 你還是能夠了解他們大致上的那種意思 所以這種fill in the blank的這種 我們叫所謂mask label的這種trainment的方法
(53:42~54:44) 事實上它是一種pattern recognition的表現 但是fill in the blank的capability 它有時候fill in的東西並不只是文字 而是一些concept 所以這個也是我個人認為 這些reasoning capability的原由 為什麼會出現這種類似AGI這樣子的表現的原因是在這個地方 了解 我們人腦其實也是autoregressive的概念 autoregressive這個部分 很容易的解釋就是說 我現在目前為止所講的一些東西 讓你有一個context 讓你能夠開始predict我下一個字會要說什麼 如果我突然完全switch topic到另外一個東西 比如說日本東京有什麼好吃的 你可能現在突然 因為你沒有跟我聊過這個話題
(54:44~55:23) 你就完全不知道說我喜歡吃什麼樣的東西 我想要聊什麼你就沒有那個prediction 但如果我們是好朋友 希望經過今天的podcast之後 我們會見到好朋友 那你知道我的口味的話 你可能會想要聊sushi或是ramen 這就是一種context representation的表現 那這autoregression事實上就是在做這方面的東西 了解 好那我們上集的訪談就到這邊結束 別忘了下禮拜再來聽下集喔 那你如果喜歡今天的podcast呢 也別忘了分享給你所有的朋友們 因為好東西要跟好朋友分享 那最後呢就祝大家有個愉快的一周 我們下週見
