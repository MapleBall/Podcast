(00:00~01:00) 【Keychron】 哈囉大家好 歡迎收聽科技浪 我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂 但是又深入的方式 帶你了解時下最火的科技話題 本集由Keychron贊助播出 Keychron是一間賣機械鍵盤的公司 他們家的機械鍵盤也是我的第一個機械鍵盤 用過之後我真的是直接被推坑了 哇 這個Keychron的機械鍵盤打起來真的太爽了 首先我覺得有些人可能會不太知道什麼是機械鍵盤 所以我這邊簡單講解一下 機械鍵盤跟一般的鍵盤他們的組成結構是完全不一樣的 一般鍵盤你下面每個鍵你下面就是一層橡膠 有一整片的橡膠 然後你每個按鈕下面的橡膠會凸出來這樣 然後你按下去的時候就是把那個凸出來的部分壓下去這樣 但是機械鍵盤的不一樣的地方是 它每個按鍵下面都有一個獨立的機械軸 然後你在按這個按鍵的時候你是把這個機械軸壓下去
(01:00~02:02) 而不是壓這個橡膠 所以說也因為這樣子呢它有幾個優點 第一個就是它有更好的打字的回饋感 然後打字的那個聲音也比較不一樣 所以說打起來是真的比較爽 除此之外它也比一般的鍵盤更耐用 然後更能夠克制化 就是你可以把這個上面的按鈕拆掉換新的這樣 那之前呢我其實一直以來都不是很了解 為什麼大家會用機械鍵盤 就是你打起來比較爽有差那麼多嗎 直到這次Keychron寄了他們的一個機械鍵盤給我使用 哇用過之後真的是我真的我已經回不去了 就那個打字的感覺真的是非常不一樣 我開始喜歡上這個機械鍵盤之後 我甚至還會期待我要打很多字的時候 就我通常在準備這個Podcast或是影片的時候 我就是會先看很多資料嘛 然後看完資料之後再去補充一下我的筆記 然後我看資料的時候就會很期待我等一下補充筆記的時候可以敲這個鍵盤 那Keychron這次寄給我的鍵盤呢是他們的Keychron K3 Pro Model 我們來簡單介紹一下 首先這個K3 Pro的外觀呢真的是非常簡潔好看
(02:02~03:05) 它的配色是灰黑紅的配色 你們可以去它的官網看一下 我覺得真的是蠻好看的然後蠻符合我的Style的 然後另外在外觀這邊還有就是K3 Pro它主打的一個特點是它輕薄好攜帶 就是比起其他的這個機械鍵盤可能非常厚重 它是輕薄型的 所以說蠻適合那種辦公啊數位工作者會需要到別的地方工作要帶這個鍵盤的人 再來這個鍵盤它打起來手感真的也是非常的舒適 那它其實有分三種不同的軸體 我剛剛不是說機械鍵盤下面按鍵下面都有每一個按鍵下面都有個獨立的軸嗎 這個軸你是可以選擇的有三種可以選 這三種分別是這個聲音最大然後敲擊感最強烈的輕軸 然後還有打起來最安靜的紅軸 然後最後是介於兩者之間的茶軸 那我自己現在是使用這個茶軸我覺得打起來非常剛好 然後廠商那邊也說這個茶軸是最適合新手入門的 然後同時這個K3 Pro也可以調整它的鍵盤高度 那我自己是有在用這個打字的時候保護手軸的這個護墊
(03:05~04:05) 然後我把這個K3 Pro調成最高之後打起來就是剛剛好 再來Keychron的K3 Pro也是非常高度客製化的 它有支援一些軟體可以讓你首先客製化按鍵 就是你自己設定每個按鍵的功能 再來它可以調整這個RGB的燈光效效果跟速度 然後還可以建立Macro 就是一個按鍵會直接發出許多按鍵的指令的這種操作 然後這個鍵盤對於各種裝置的相容性也很高 首先Windows跟Mac的系統都可以支援 然後是可以一鍵切換的 鍵盤上直接就有個開關可以直接切換Mac跟Windows 同時這個鍵盤也支援藍牙跟Cable的連線 然後你要連藍牙的話最多可以同時連三個裝置 我覺得整體來說真的是很不錯的一個鍵盤 你如果想了解更多的話 在這集的Show Note你可以看到Keychron K3 Pro產品的連結 你可以點進去看一下 然後你也可以到我的IG看一下我的精選動態 裡面會有一則K3 Pro的開箱跟實測影片 你可以去聽一下那個打字的聲音 跟它的外觀看起來究竟是如何
(04:05~05:06) 那你看過之後如果覺得想買的話 別忘了使用我的專屬優惠碼 Harry200 全部都是小寫的Harry然後200沒有空格 你只要在10月31號之前輸入這個折扣碼 你買K3 Pro就可以限折200塊 最後也補充一下 我覺得如果你之前沒有用過這些鍵盤的人的話 我是蠻建議你買跟我一樣的插軸 因為我覺得打起來是真的蠻不錯的 然後廠商這邊也是這麼推薦我的 好那業配時間就到這邊結束了 謝謝Keychron的贊助 那在進入這個科技話題之前 我必須跟大家說一下就是 我跟大家一樣這個禮拜都是 每天帶著非常沉重的心態 在聽這個以色列跟加沙這邊的狀況 這個現在在發生的這個戰爭 真的是非常讓人悲傷 非常讓人心痛 那這個話題當然有非常多可以討論的 不過我們的頻道不是講政治 不是講國際關係的頻道 所以我這邊就不給任何的評論 我想講的只有就是 會持續的為這些因為這場戰爭
(05:06~06:07) 而受苦的所有人祈禱 就是不管你是因為這場戰爭 失去了親人 失去了好友 還是失去了你自己的生命 或甚至是遭遇一些 非常不人道的事情 我真的是為你們感到非常的心痛 然後我會持續的為你們祈禱 好那我們今天這集科技浪要來講的公司呢 又是這個俗稱Close AI的OpenAI 不得不說OpenAI在2023年 真的就是Talk of the Town 說到這個AI的硬體啊 你就不得不提到NVIDIA 但說到AI的軟體 你就不得不提到OpenAI了 那我們其實在第七集的時候 我們就有一整集來聊這個OpenAI嘛 然後我那時候就說 我覺得OpenAI還有很多東西可以聊 我們不可能今天聊這一集而已 未來一定也會有其他集數在聊OpenAI 沒想到我們第十集 就又回到OpenAI上面了 那我們會這麼快的回來聊OpenAI 其實是因為在我們播出了第七集之後呢 OpenAI立刻就出了一些其他的大新聞 所以真的是錯過蠻多的
(06:07~07:07) 那這些大新聞呢 當然就包括第一個 就是我們今天主要要聊的GPT-4V GPT-4Vision 也就是Chai GPT終於有視覺了 然後除此之外呢 還有一些其他的嘛 就是包括Chai GPT現在也可以聽 然後也可以講話 然後我覺得在這個產品的功能更新的新聞以外呢 OpenAI還有另外兩個大新聞喔 這兩個大新聞指的方向都是一樣的 就是OpenAI要開始進攻硬體了 第一個大新聞就是 OpenAI跟Apple的前Chief Design Officer 叫做Johnny Ive 在談說他們要做一個消費者產品 這個消費者裝置呢 會是The iPhone of AI 也就是說這個裝置 完全是以AI為中心做設計的 意思就是說 它會讓這個消費者能夠更直接 更直覺的跟AI進行互動 就是以我們現在的裝置啊 不管是手機還是電腦 這個AI呢 就直接跟AI進行互動 這個AI呢就只是上面的一個App 或是一個軟體而已
(07:07~08:07) 它並不是以AI為中心去 做設計的 那一個以AI為中心設計的 這個手機會長什麼樣 或是它不是一個手機 我們不知道它在設計的這個產品 這個裝置究竟是什麼樣的一個裝置 我們不知道 但他們最主要的這個中心思想就是 以AI為中心設計 那這個Sam Almond OpenAI他們的合作夥伴呢 Apple的前Chief Design Officer Johnny Ive 當然也是大有來頭嘛 之前是設計iPhone的人 同時他背後的投資人也是大有來頭啊 是這個軟銀的CEO孫正義 然後另外一個新聞呢 一樣是他們要進攻硬體的新聞 就是OpenAI現在正在 考慮要做他們自己的AI 晶片他們聽說已經在 找這個要收購的對象囉 那以上就是這個我覺得 最近OpenAI最大的一些新聞 那我們今天主要要聊的呢其實是 T4V這個模型 因為他們終於在昨天的時候 開放我使用了 但是說到剛剛那兩個OpenAI
(08:07~09:07) 要進攻硬體的新聞啊 我就不得不跟大家聊一下 我最近聽到的一個非常 有趣的陰謀論 當然我已經先說了嘛這個就是陰謀論 所以說這邊就是純粹的猜測 大家不要太認真看待這件事情 那我在第七集最後面我就跟大家說了嘛 就是我每次聽到Sam Almond 講話我都會覺得 他好像臣服很深的感覺 我覺得可能是因為這個有Sam Bankmanfree的前居之鑑 就是那個FTX的CEO 那在這個FTX的醜聞 被爆出來之前呢 Sam Bankmanfree也是被拱得很高嘛 大家都說他是一個Ultraist Ultraist就是我們在講說一個人他 完全幫助別人就是為了別人 著想完全不想要自己獲得任何 東西的這樣子的人 就叫做Ultraist那最後這個Sam Bankmanfree被發現是假Ultraist 他就是動用客戶的資金 再自己去做一些 很風險性很高的操作 然後買到遊艇啥的 那Sam Almond也是一個被大家稱作 Ultraist的一個人
(09:07~10:07) 然後呢他的名字也叫做Sam 然後他講話的時候真的是會給我一種 那種Bad Vibe 就是我會覺得 你真的真的就是全心全意 真的為全人類著想嗎 真的嗎 那他最有名的一個市機也不算市機啦 就是他最有名的一件事情呢 就是他並沒有OpenAI的持股 他零持股 然後記者也是常常問他這個問題嘛 就是會問他說 為什麼你當OpenAI的CEO 然後OpenAI很明顯的就是一個 未來會非常賺錢的一間公司 那你為什麼不持股呢 然後他的回答都是他覺得他的錢已經夠用了 然後他來OpenAI做CEO這件事情 純粹就是為了人類著想 他想要帶領OpenAI 做出一個產品是可以帶領人類 走向一個更美好的未來的 然後我前一陣子就聽到一個陰謀論 他是在講說會不會 Sam Almond完全都不持股 其實並不是他為了人類著想 而是他其實想要成為 世界首富 而且不只是世界首富而已喔
(10:07~11:07) 他想要成為人類有史以來的 第一個Trileaner 你如果不知道這個Trileaner的概念我簡單給你解釋一下 首先現在世界上最有錢的人是誰 馬斯克嘛 馬斯克他的身價是253個Billion 也就是說你要成為一個Trileaner 你要比馬斯克還有錢四倍以上 然後再舉個例子 Nvidia這間公司 他現在的市值是多少 是1.1個Trileaner 意思就是說你如果是Trileaner的話 你的身價就跟Nvidia 這間公司的市價是差不多的 所以你知道儘管在我們這個資本主義的社會 一個人要成為一個Trileaner 也是幾乎不可能的事情 那我前一陣子 在聽一個Podcast叫做All in Podcast 裡面有個主持人叫做David Sachs 他是美國很厲害的一個創業家跟投資人 他就有提出一個陰謀論說 他覺得Sam Omen有可能在計畫成為一個Trileaner 首先OpenEye這間公司 可以簡單分成兩個組織 一個是非營利組織 完全非營利的 另外一個是for profit組織
(11:07~12:07) 那你聽到那些投資人投資的當然就是 營利的組織這個部分 像是Microsoft 他投資的這個錢 就會到OpenEye的這個營利的公司裡面 然後這邊所有的投資 其實都會有一個profit cap profit cap的意思就是說 這些投資人他賺錢 靠這個投資賺的錢 賺到的一定程度之後 他就不能再繼續賺下去了 他最多只能賺一定的錢而已 然後這個market cap通常是用一個成數來定義的 假設market cap的成數是10的話 這些投資人 最多只能賺10倍的錢 意思就是說假設今天 他投資10個billion到OpenEye裡面 那這10個billion呢 最多只能賺到100billion 意思就是說這個部位 賺到100billion之後 基本上這個Microsoft就等於cash out了 他就不能再繼續賺下去了 儘管這個部位之後再繼續去賺到 變成一個trillion的話 這個微軟還是沒有辦法 拿到這筆錢他只能拿到100billion 那剩下這900billion
(12:07~13:07) 會誰拿走沒錯就是會 回流到OpenEye的這個 非營利組織的公司裡面 那這個非營利組織是誰控制的 Sam Omen啊 當然他們董事會還有其他人 就是包括 Greg Brockman一定也在裡面 但反正Sam Omen一定是老大 那Sam Omen能夠動用 這個非營利組織賺的錢 做什麼事情呢 當然依照這個非營利組織他的mission 這些錢是要拿來為人類著想的 就是為人類 做出一個好的AGI 但是David Sachs有在他的podcast裡面說 假設今天Sam Omen要拿這個錢 去買一台飛機他做不做得到 他可以做到所以有可能對於 外界人來說就是Sam Omen 沒有拿股權嘛所以他一毛錢 這OpenEye賺的錢他一毛錢都拿不到 但其實他 可以拿到絕大部分 就是假設這間公司的成長 遠大於他的這個投資人 的profit cap的話那Sam Omen 就會拿到絕大絕大多數 的價值我剛剛用那個十倍的
(13:07~14:07) 例子也跟大家算過了嘛 但假設今天不是profit cap不是十倍 因為他這個profit cap是會一直下降 假設現在profit cap來到 大概五倍但是Sam Omen把OpenEye 的市值成長了一百倍或者是成長 了兩百倍的話 Sam Omen不就拿到了可能九十幾% 的錢了嗎當然就是依照現在 OpenEye的可能估值 可能很難十幾百倍 但是OpenEye他這個 產業已經選對了嘛他做的事情 就是AI嘛那AI就是在未來 這幾年最有可能產生極大 非常恐怖的經濟價值 的一個科技然後同時呢 我們看到他在做什麼他在開始 往硬體擴張 這件事情在我們的business的term裡面 叫做vertical integration 垂直整合這個垂直整合很明顯 就是一間公司為了獲利 最大化會做出來的一個舉動 尤其你看這個Sam Omen找了 這個蘋果的前design chief design officer嘛我覺得他就是 想要像蘋果iPhone那時候推出 有做出一個非常 有破壞式創新效果
(14:07~15:07) 的一個產品因為現在大家都在講 了嘛就是AI會是下一代的 operating system 下一代的作業系統 就是像這個Windows Mac 這種作業系統都是舊時代的東西 未來我們不會像是現在 這樣的OS加App的方式 在跟數位世界互動而是透過 AI在跟數位世界互動 所以如果有間公司可以正確的 做出未來的這個 AI的OS的手機 或是那時候已經不叫手機不知道 是什麼裝置的這個裝置 他可以做出這個裝置同時 他也做出這個裝置的軟體 然後同時他又自己設計 自己的晶片那我覺得這間公司 在未來一定是市值 保證一定好幾個trillion起跳 然後根據我們的陰謀論 Sam Omen很可能就是想要把OpenAI 走到這條路上讓OpenAI 變成那間好幾個trillion的公司 然後讓絕大多數的錢 流到他的口袋中變成他可以控制的錢 當然啦我覺得這個陰謀論 本身一定有很多的破綻啦 所以我覺得大家真的就是聽聽就好
(15:07~16:07) 但說真的啦Sam Omen現在 帶領這個OpenAI走的方向 很明顯的就是要賺 很多很多錢的這個方向 就是你如果有聽我的第七集你就知道嘛 就是他們早期在做那些 Reinforcement Learning的專案 那些真的都是完全不賺錢就是純粹 研究的東西耶 那你看現在OpenAI這一兩年推出的產品 有哪些是這種純研究不賺錢的 然後尤其最近這些新聞 想做硬體這個 很明顯啦Sam Omen你想賺錢我們都知道 但是你賺到的這些錢你究竟 會怎麼用就是我們不太知道的東西了 然後最後我還是要說一下就是 我剛剛講的這整個 垂直整合的計畫 非常非常難實現 就是你要知道消費者產品是 非常難做的 尤其是這種3C的消費者裝置 然後尤其你又要像是iPhone這種 有革命性的改變的裝置 我覺得真的超級無敵困難 我覺得就算是賈伯斯復活 來做這件事情也不一定做得到 所以OpenAI就算很有錢然後 有些非常聰明的人我覺得也是
(16:07~17:07) 很難啦不一定做得到這件事情 好啦我們陰謀論就先講到這邊了 那我們接下來進入正題 今天我們要聊的呢是OpenAI 這間公司出的最新的GPT 4V這個模型 如果你還不知道的話ChatGPT 這個聊天機器人呢就是OpenAI開發的 ChatGPT它有兩種大腦可以選擇 一種是ChatGPT 3.5 它是用GPT 3.5做為大腦 另外一種是ChatGPT 4 就是用GPT 4做為大腦 ChatGPT 4V呢 就是GPT 4這個大腦 這個模型呢的進化版 那個V代表的是vision 也就是視覺的意思 顧名思義呢ChatGPT 4V 就是有視覺的GPT 4 比起GPT 4只能用文字跟它交流 GPT 4V呢 GPT 4V呢你可以傳圖片給它 然後搭配文字一起問它問題 然後你能輸入的圖片呢 其實也不只一張喔 你可以輸入很多張圖片 然後每一張圖片之間呢都穿插著 一些文字的說明 它會全部一起參考全部一起看了之後
(17:07~18:07) 再給你一個回答 那這個GPT 4V呢剛出來就是立刻爆紅了 這兩個禮拜網路上都充斥著 一大堆各種這個 使用GPT 4V解決各種問題的 demo很多的這些應用呢 真的都很驚人啊 然後我看了我也是真的很流口水 一直很想使用 那OpenAI是會慢慢把這個功能 roll out給所有 plus的用戶的 plus就是你有付費的用戶 然後我一直以來都是plus嘛 但是我一直以來都沒拿到 我身邊很多人都已經拿到了我就是還沒 直到前兩天我終於拿到了我才開始爆玩 哇真的是很好玩 然後同時呢GPT 4V也在學術圈 激起了一波這個LMM的討論 LMM就是Large Multi Model Model 大型多模態模型 那我們知道像是語言啊 聲音啊文字啊 這些都是不同的模態嘛 這一個一個都叫做模態 那我們平時講的LMM大型語言模型 言下之意就是說 他只懂語言這個模態 但是今天如果是一個大型多模態
(18:07~19:07) 模型LMM他就是指的是 他可以懂多種模態的一個 模型 那在GPT 4出來之後呢就很多人就開始說 我們要從LMM開始 慢慢往LMM走了 所以我們今天就來聊一下 首先GPT 4V他究竟可以做到什麼事情 他究竟有多強 為什麼他可以激起這麼大的討論 同時我也會帶大家看一下就是 我認為GPT 4他的技術細節 是什麼當然這部分他沒有公佈 但是我們有足夠的 很多的這個線索可以猜出一些 他大概的架構可能是什麼 然後最後呢也跟大家聊一下 這個GPT 4V我覺得會有什麼 商業應用的價值 首先我們這邊先來看一下 GPT 4V他究竟可以做到哪些事情 那這邊呢我覺得我們可以先從 微軟的一篇研究論文開始講 這篇論文呢發表於 兩個禮拜前就差不多是 GPT 4V剛出來的那個時候 那這篇論文的名字叫做 意思就是我們來初步的探索
(19:07~20:07) GPT 4V的功能 那這篇論文有160幾頁 基本上就是非常完整的在檢測 GPT 4V的各個面向的表現 他們拿GPT 4V做了 超級無敵多的事情做了一大堆的 實驗他們很詳細的分析說 GPT 4V他什麼事情做的好 什麼事情做不太好那要怎麼樣 講他才會做得更好 那我這邊就簡單跟大家分享幾個我看到的 重點好了首先第一個呢 是GPT 4V他有非常強的 邏輯能力然後可以同時 找出非常多張圖片之間的關係 一個例子就是我不知道大家 是不是知道那種簡單的圖形 邏輯推理測驗就是你可能去 申請一些外商公司他一開始會 叫你做這個測驗就是他裡面有 很多幾何的圖像然後這些圖像 有一些既定的規則在裡面 就比如說每一列的圖像 就兩個圖像他的關係 都是下面那個圖像是 上面那個圖像的多一撇 這樣然後 他就把其中的 一列的下面那個圖像 挖一個空格然後問你說
(20:07~21:07) 要這個空格中要填入哪一個圖像 才是正確的 然後你就要選擇那個 有加一撇的那個圖像 那這種邏輯推理的題目對於人類來說 是蠻簡單的嘛雖然說有 有些複雜的事是蠻難的啦 但大部分的題目是蠻簡單的 但是我覺得一直以來從來沒有任何 一個AI可以靠著自己的邏輯 去解這種題目但GPT 4V可以解這種題目 你就給他那張圖像然後 他可能是 他可能有四個形狀然後其中一個形狀是問號 然後下面丟給他 可能五個選項五張圖片 每張圖片都是一個可能可以 填入那個問號的一個形狀 那只有一個是正確的 然後你再加上一些文字的敘述 跟他說這個邏輯這邊 邏輯大概是怎樣就是包括你要跟他說 我們這個遊戲怎麼玩 你要走一列一列看 然後每一列都是從上面那個形狀 推論下面那個形狀應該長什麼樣 然後你也可以給他一個立體 一個例子 這是不是跟人類一模一樣
(21:07~22:07) 就是你叫一個人類做這個邏輯題的時候 你一樣是跟他講說這個要怎麼看 然後給他一個例子這樣 光是靠著這些資訊 GPT4V就可以把這個邏輯題 解出來他就真的是 在你給的所有選項中選擇一個 答案然後跟你說 為什麼他選擇那個答案把整套邏輯 講出來再來如果你丟一個國中 數學的那種幾何題目給他 他也會解就比如說一個三角形 其中一邊是X 然後求X這樣 然後GPT4V就會說我們這個形狀 是一個三角形 然後這個三角形要求三角形 其中一個邊我們就是要使用畢氏定理 然後真的把畢氏定理寫出來 把公式寫出來然後那個數字 套進去然後算出來答案給你 要知道我們文字中完全沒有跟他說 這個形狀是一個三角形 也沒有跟他說這個三角形 他每一個邊旁邊的那個數字 在講的就是那個邊的長 都沒有跟他講這些事情喔 他就是單純看這個圖片就知道怎麼解 就是跟一個國中生一模一樣 同時他對於流程圖的解析
(22:07~23:07) 也是非常強就你知道那種 流程圖啊就從步驟一到 步驟二到步驟三 步驟三有兩種狀況 如果是狀況A的話就回到步驟二 如果是狀況B的話就繼續步驟四 就這種有邏輯在裡面的 這個流程圖你可以把這個圖 丟給他然後直接單純的跟他說 Explain the figure他就會完全 把整套邏輯講出來給你 然後把整個流程走過 就是他會像我剛剛講的那樣 跟你說 哪一個步驟走到哪一個步驟走到哪一個步驟 然後哪一種情況要回到哪個步驟 然後這樣子所以從這例子我們就知道 他對於圖像的理解能力 是非常強的嘛然後同時 他對於圖像的內容的 以圖像的內容來做邏輯判斷 這件事情這個能力也是 非常強那再來我要講的就是 GPT-4V他對於圖像 內容的理解程度是非常高的 他可以理解到圖像非常 細微的程度喔你就要他描述 任何一張圖片任何的物件 從球鞋到一個 Microsoft的一個發表會的截圖
(23:07~24:07) 到一個一個人 在奧林匹克logo前面的 一個照片到一個醫療的 CT scan或者是X-ray Scan到各種美食再到 世界各地的各種景點 他全部都認得而且可以 非常完美的描述那張圖片 裡面有什麼東西當然啦這種 為圖片做為文字敘述 的這種叫做image captioning 的模型呢其實一直以來都有 然後都還蠻強的 但是我真的覺得雖然說 這部分不是我的專業但是就 我看過的所有image captioning模型 當中GPT-4是做得最好的 他真的可以把圖片描述的 非常非常細緻非常 小細節他都抓得到然後都 可以講得非常好而且是 講這種讓人類可以非常直覺 理解的語言但他有一些細節是 會搞錯的我這邊舉個例子 好了就是他其中有一張 圖片是給就是一個 Coca-Cola的圖片然後他的 prompt就是直接跟他說 describe the logo就叫他描述 那個logo長什麼樣
(24:07~25:07) 那我這邊直接念他回答好了我直接念 英文因為這樣我比較方便 好the logo is written in the cursive font 就是草寫的意思 Cursive font in white color with a red background the first C in cola is larger than the rest of the letters and the O in cola is elongated,elongated就是伸長的意思 the logo is instantly recognizable and is synonymous with the brand 首先我們先來appreciate一下 他怎麼可以講得這麼 detail對吧他真的是 講得非常detail嘛他說這個 這個logo他是草寫 的字體他的顏色是 什麼然後他哪一個字特別大 哪一個字特別長他都有講到 但是他有犯一個錯 就是他說那個cola的 O是伸長的嘛但 其實不是啊就是cola的O 沒有特別長啊他是cola的L 才是特別長的但是你想 想一下他世界上每一個東西 他都可以describe到這麼 深這麼detail的程度喔 所以我覺得他真的應該是現在
(25:07~26:07) 最強的這個image captioning的model 就是為image寫 文字敘述的model真的 我覺得他去跑那些image captioning 的benchmark就是那些 image captioning的測驗 測試他應該是可以直接圖榜 我覺得就是因為 其他大家最常講的就是 應該就是blip吧那blip我 自己也有用過就是以前在 train這些stable diffusion的模型都用blip 但我覺得真的就沒有像 GPD4可以講到這麼細節 的程度好那這是這個 圖片敘述的部分再來 我覺得GPD4還有很強的一點就是 他有非常強的common sense我覺得你要測試一個 模型他有沒有很強的common sense 最難的你就是丟一個meme 給他丟一個梗圖給他看他 可不可以講出這個笑點究竟在 哪裡那微軟這些人就有為GPD 4做這個梗圖測試 那他有丟一張梗圖是就是 一隻青蛙躺在床上發藍的樣子 然後上面寫著三行字 第一行是me I'll do it at 8我8點在
(26:07~27:07) 做第二行是time 8.05 8.05分 第三行也是me looks like I gotta wait till 9 now 看來我只能等到9點 再來做了那這梗圖在講的當然 就是一個人類很廢在 耍懶的樣子然後Microsoft 的人就直接把這張圖片丟給GPD4 然後問他說這張圖片的笑點在 哪裡然後GPD4就回答說 這張圖片是在笑人類脫眼 的樣子然後在笑說有些 人會設定一個時間要做 事情但如果超過了那個時間 的話他們就會再順眼 一個小時然後他接下來還有講很多 的話但是他講到這邊就已經 把整個笑點都講出來了對吧 就是他把整個核心概念 已經講出來了但你可能會說 他搞不好就是單純從文字在判斷 這件事情啊如果單純的笑點 是在圖片中呢那Microsoft 有放另外一張梗圖給他這張梗圖 的大標題就是我在考試 中的字跡然後有分三 個部分第一個部分是 前面兩頁然後是寫得很漂亮 然後再來是中間就開始有 一點有點鬼話符了然後
(27:07~28:07) 最後是最後兩頁 直接他就直接放一個那個 心電圖就根本看不出來 是字了那這個笑點當然 就是你要看得懂圖片你才笑 得出來嘛對啊就是你單看 那個字你是沒有辦法看懂這個 笑話在哪裡的但是GPC4 竟然可以完全理解這個圖片 的笑點在哪裡他一樣 打了很長的回答但他第一句話 就直接點出核心的笑點他就寫說 這張圖片是在笑 一個人在考試的過程中 字跡逐漸變差的過程 這很扯完全正確 這樣你就不能說他 他其實是就是靠OCR OCR就是在圖片中 識別文字的一個技術 就你不能說他是單純靠OCR 把這個笑話先識別 成文字然後從文字做推理 你不能這樣講因為他圖片 的笑點他也看得懂這就代表 他真的有非常強的common sense 另外一個common sense的例子就是 Microsoft的人給GPC4V 一個人房間的照片然後給他prompt 說假設你今天是一個
(28:07~29:07) 偵探你可以從這個照片中 看出什麼東西然後GPC4V 就開始列點他列說這個 人有很多件夾克然後很多雙 鞋子代表他可能很重視 時尚然後再來這個人他的 夾克是很厚重的那個形式 代表他可能住在比較冷的地方 然後這個人住的地方可能比較 老舊因為我們可以看到這個 房間的一些管線都外露了 這些都代表這個GPC4V有非常 強的common sense再來 GPC4V也有非常基本的空間 概念Microsoft的人有給他一張 照片是一個人站得離這個 鏡頭比較前面所以那個人看起來 很大然後有一台比較遠 在遠的地方有一台車子然後比較小 這樣然後他的prompt就 問他說那個人跟那個車子 哪一個比較大然後GPC4V就 回答說應該是車子會比人 大但是從我們這個角度看過去 看起來人好像比較大 然後另外一張圖片是一個人在丟一個飛盤 的圖片然後GPC4V他可以看 出說這個人他看起來 好像剛丟出這個飛盤 這飛盤應該那所以這飛盤現在
(29:07~30:07) 應該是在遠離他的過程中 所以GPC4V也是有非常強的 這個空間概念那最後我想要 講的一點就是這個我不確定 要放在哪個類別當中啦但是 GPC4V有一種特別的能力 就是他可以看一個網站 的layout或者是你單純用手 畫一個一個網站的草稿 然後他就直接把那個網站的 code全部寫出來當然他就是寫基本的 HTML跟CSS啦 但是有了那個東西之後你之後 再叫他加一些 互動的功能加一些JavaScript的code 當然也是可以的 所以我們這邊做個小節好了 GPC4V在以下的能力是非常 強的第一個從圖像中做 邏輯判斷第二個描述 一張圖片第三個common sense第四個空間關係 的了解第五個看圖片 寫程式當然這不是GPC4V 唯一能做的事情他還能做的事情 還非常多那這也不是 他唯一擅長 的事情那而且說 真的這五點我覺得沒有分得非常 好啦就是嚴格來說
(30:07~31:07) 你敘述一個圖片 跟common sense是有重疊 的吧你敘述一個圖片也是要用到 common sense但是這就是 我自己從這個論文 掃過之後我抓出了幾個 重疊然後除了這些GPC4V 的長處呢這個論文呢也有 提到一些可能可以做的 prompt engineering的方向那如果你 還不知道prompt engineering是什麼 prompt engineering的中文就是提示 工程就是在思考 要怎麼樣跟這些AI 溝通要怎麼樣輸入 問題給這些AI才可以得到 得到最好的答案的一個 學問那我總結出論文 中大概有講的三個這個prompt engineering的方向第一個是 你給出明確的邏輯 指引他會做的比較好就是我們 如果回到最一開始我講的那個圖像 的邏輯題的例子 就是從前面三個圖像 判斷第四個圖像應該是長什麼樣 這樣那你如果單純 就是丟這個圖片給他然後跟他說 請幫我預測 問號中應該是長什麼樣的圖像
(31:07~32:07) GPC4可能做不出來 但如果你有在你的prompt中給出很明確 的邏輯指引跟他講 這個題目應該要怎麼解不用 跟他講答案喔你就是跟他說 你先看左邊這一 列的兩個圖像然後抓 出他們之間的關係然後再看 右邊他 在這邊的兩個圖像上面 圖像跟下面圖像會有 一樣的關係就跟他講完 這些東西之後他就做的出來了 第二個是你要很明確的 要求成功這點我就 很有趣喔這個是論文裡面他 論文裡面他是說他們有觀察 到就是這些AI 他不會想要成功 就是你單純問他說請幫 我數一下圖片中有幾個蘋果 他不會知道你想要 一個正確答案對他來說他沒有 這個正確的這個概念 所以如果你在你的這個提示中 你的prompt中有打出 我們要找到確定的答案 這句話他就會表現的比較 好他就可以數出真正有幾個蘋果 最後一個方法呢就是
(32:07~33:07) 他如果第一次回答 不出來的話你就多給他幾個 例子讓他先看了例子他就 回答的出來了這個方法其實在機器 學習的這個學科當中有一個專有名詞 叫做Fuse Shot Learning 在講的就是這件事情比如說GPD-4 其實有個弱點就是他讀不太懂 這個圖表的資訊 最簡單的一個例子他做不出來 的就是那個車子的車速表 他沒有辦法單從一張車 速表就跟你講說 現在這台車子的時速是多少 這樣因為那個那個針 不是都會指在假設他 指在80到100之間的某一個 刻度他是指著那個刻度 那刻度上面又沒有任何的字 他就是一個刻度 然後你要判斷這台車子現在時速多快 你要從80數到100 之間有幾個刻度 他是指在哪一個然後再 算一下是車速多少 其實這件事情對人來說 很直覺但是你解釋起來就會發現 這件事情要一個AI做 其實蠻困難的然後GPD-4V 也真的很好笑就是前面這麼多
(33:07~34:07) 困難的題目他都解得了 但他的一個車速表他都看不懂 但是無論如何這些 Microsoft的人他給一張 車速表直接叫他看他看不懂 那就給兩張然後跟他講說要怎麼看 他還是看不懂那就給三張 然後看了三張之後呢GPD-4 其實就已經學會要怎麼看了 好啦講了這麼多我這邊先做一個小節 重點有兩個第一個 我覺得GPD-4V是現在最強的 大型多模態模型 我覺得這點應該是無庸置疑 我覺得接下來最有可能打敗GPD-4V 的模型應該是Google接下來 發表的一個模型叫做Gemini Gemini聽說真的是 比GPD-4V強非常多啦 更大然後同時也是 多模態的這邊很多謠言 但我們就坐著看吧另外一個重點 就是GPD-4V有很強的邏輯推理能力 而且他有理解 的能力他確實會理解 這些內容他有對文字理解 也有對圖片的理解他 只是沒有自我意識而已 我想強調這點是因為我前一陣子 看到網路上有一個
(34:07~35:07) 一個網紅 他是在他做了一些影片 在講解AI 但說真的我覺得他講解的非常 不準就是他說這些 AI完全沒有理解任何事情 的能力但是我認為這些AI 像是GPD-4V絕對有 對於事情的理解他絕對有 理解事情的能力你看 我剛剛講了這麼多例子你還會覺得他 沒辦法理解事情嗎這些AI 只是沒有自我意識而已 這邊我覺得真的要深入討論其實 可以討論很久說真的 理解到底是什麼意思什麼叫做 理解什麼叫智慧什麼 叫意識但我覺得 這邊我們就先先放著因為 我發現我們接下來還有超級多 東西要講然後我現在其實 已經講有點累了所以說 我們趕緊進入下一個階段 我們現在知道了這個GPD-4他究竟 強的地方在哪裡那他 為什麼會激起這麼多討論我相信 大家應該也知道了吧他就是 很強這個這麼強的GPD-4V 究竟是怎麼做出來的呢 他跟那個單純的語言的GPD-4
(35:07~36:07) 是完全不一樣的模型嗎 還是說他其實是拿這個語言的GPD-4 來Find To來做一些 微調微調出來這個 視覺的能力呢先直接破題 好了答案是後者GPD-4V 就是從一個單純的語言 模型微調出來的一個視覺 模型講錯了應該不是視覺模型 是多模態模型先說 OpenAI沒有很詳細的講這件事情 他沒有公開而且詳細的講 就是依照他們的慣例嘛 就是這些這麼強的語言模型 他完全不會透露一丁點 消息但是從他們講話的 前後文就可以猜出說他們 就是從這個大型語言模型微調 出一個多模態能力微調 就是拿額外的資料對模型進行 再訓練的過程讓他學會 新的能力或是新的知識 但是具體來說要怎麼樣把一個 語言模型微調成一個 語言跟視覺都懂的 模型呢我先在非常高的層次來 回答這個問題用大觀念來回答 有一個大觀念是神經網路 什麼東西都學得會 一個單純視覺的模型跟一個單純
(36:07~37:07) 語言的模型跟一個單純聲音的 模型他背後全部都是神經 網路不一樣的地方是在於他們 處理這些資料的方式就是說 他們把這些資料進行了什麼樣的 處理之後才丟進神經網路 當中但最後都一樣是丟進神經 網路當中而且一樣是以向量 的形式丟進神經網路當中 向量就是一個你國中讀過的數學 物件就是一個中括號 然後裡面有一整排的 一整列的數字所以你今天 如果要一個模型可以同時理解 文字跟圖片你就要找到 一個方法把文字跟圖片 用差不多的向量來代表 意思就是說一隻貓這三個 字他變成了向量要跟 一隻貓的圖片變成 的向量是差不多的你有辦法 可以把文字跟圖片變成這種 差不多的向量你就可以同時一起 丟進這個神經網路當中然後 丟進神經網路就是同時理解文字跟圖片 好其實大觀念就是這樣 我已經講完了好但 我知道我的觀眾裡面很多非常 技術的人就是有 Machine Learning的PhD啊
(37:07~38:07) 有些Machine Learning Engineer所以說 我還是會接下來再講一些 技術的細節但是我會用 非常白話的方式講所以說就是 你沒有背景的人也不要怕不要跳過 首先具體來說是怎麼做 的呢我們要看一個Open Source 的專案叫做Lava L-L-A-V-A這個Lava 基本上是現在所有開源模型 當中最強的多模態 模型應該不是說所有 多模態模型拿來比較是在 這個語言跟視覺方面是 最強的多模態模型他 基本上就是一個開源版的GPT-4V 啦他的做到事情是跟 GPT-4一樣的就是你可以丟 圖片跟文字給他然後 他就是一樣的依照這兩個東西 進行回答這樣當然他的能力 比GPT-4弱非常多 但是呢儘管如此他已經在 11個Benchmark做到State of the Art了 Benchmark我剛剛 有講過嘛就是那些檢測 大型圓模型或者是這些AI 模型能力的一個資料集 然後State of the Art的意思就是說 他是最強的他的成績是
(38:07~39:07) 最好的就是這樣所以他已經在 11個Benchmark做到最好的成績 囉當然GPT-4進來一定是 這些圖榜全部圖榜全部都 變他第一名但是 Lava是完全開源的 就是說我們可以看得到這個Lava是 怎麼建出來的那他的結構 跟他的運作模式其實非常單純 我們就先從一個流程來看 那從過程中我們就可以看出他的 結構是什麼了那首先使用者輸入 圖片跟文字嘛那這個圖片 跟文字會被先被拆開這個圖片 會被丟到一個叫做Clip的 模型當中這個Clip是 OpenAI釋出的一個模型 他能做到的事情就是他 其實當然做到的事情很多但其中一件事情 是他可以把一張圖片 變成一些項量不會很多 就可能幾十個幾百個這樣 那每個項量我剛剛說了嘛 就是一串數字但這串數字 不是隨便的一串數字喔這串數字 裡面有包含這張圖片 的語意語意的意思 就是說這張圖片的意義啦 他的內容是什麼東西然後同時 呢這個Lava會把文字的部分
(39:07~40:07) 一樣丟到一個encoder當中 那這個encoder呢基本上 是在做一樣的事情就是把 這串文字呢 變成一個一個的項量 然後這個項量當然也有包含 每一個字他的語意 以及這些字的互相 他之間有什麼關係 聽到這裡可能會覺得好大功告成啦 就是我們圖片變成一大堆項量 然後我們的文字也變成一大堆項量 我們可以直接把他 攪合在一起然後丟進模型當中啦 這是不太行的因為第一個 你這個Clip做出來的這個圖片的 項量他可能跟文字的項量 維度差很多然後第二個就是 你怎麼確保這些圖片的項量 跟這些文字的項量他語意是 接近的畢竟這個Clip 是OpenAI train出來的模型 然後這個Lava的encoder是 連輸train出來的東西 用的資料也不一樣 train出來的東西當然也蠻不一樣的 所以Lava這邊做了一件事情就是 他又多塞了一個神經網路進去 然後這個神經網路 就是專門把這個視覺的
(40:07~41:07) 項量從Clip製作出來 的這些項量轉化成 跟文字的項量是同一個level的 這種項量然後這個外加 的神經網路基本上就是Lava 學習的一個重點就是你在 trainLava的過程中你其實 就是在update這個 神經網路他的權重 意思就是說你在train這個神經網路 好那其實基本上就這樣就結束了 對Lava就是這樣子而已 那從這邊你也可以知道Lava的 組成了他的組成就是 一個大型圓模型加 一個Clip再加一個MLP MLP就是一個神經網路 就是一個一般的神經網路我們叫做 MLP全名是 Multi-layer perceptron就是這樣 而已就是這三個東西然後 我必須說這個Lava真的是很神奇 因為首先他的成果 很好他成績超棒的就是他在 11個benchmark做到state of the art 就是你平時如果 可以訓練一個模型是可以在一個 benchmark做到state of the art 你就可以發論文了你就可以說哇 很屌很屌但他在11個
(41:07~42:07) benchmark做到state of the art很厲害 但是我們單看他用的模型 我們就知道這個Lava 模型還有很大的進步空間 為什麼首先他的 LLM是使用Vicuña Vicuña是那時候Lama 第一代剛出來的時候有一些 Berkeley的學生就拿 GPT-4做了一大堆資料集 出來然後訓練出來的一個 模型所以說很明顯 他並不是現在最強的圓模型 你現在隨便拿一個Lama 2 然後拿同樣的資料集去訓練 一個Vicuña 2也會比較強 而且他們也不是用最大尺寸 的這個Vicuña 就是我不確定Vicuña有沒有很大的 反正Vicuña他的 base model就是7B跟 13B嘛7個billion跟13個 billion的參數的Lama 但是我們現在有70billion 參數的Lama 2耶 我們拿70billion參數的Lama 2 然後再拿一個類似的資料集去 tune一個類似Vicuña的model 出來然後拿那個model當做 Lava的LLM
(42:07~43:07) Lava的這個結果會立刻 提升喔再來我覺得他們在 訓練資料的處理這邊雖然說他們已經 做很多事情了但我覺得 他們還是沒有使用最高品質 的訓練資料當然最高品質 訓練資料是要人自己去 用手做label那很明顯 不scaleable然後他們在做訓練資料 的時候他們是用GPT-4來幫 他們做我覺得已經算是現在 最好的方法了但假設 訓練資料的品質可以再提升的話 這個Lava的這個 成績會更加提升 而且最讚的是什麼Lava 完全開源喔而且他是認真 完全開源喔你知道現在這個 現在在大型 圓模型的這個時代開源 已經失去了他原本的定義了 原本的真正開源的東西就是 像是Linux那種才是 真正開源的東西嘛但現在 大型圓模型有一大堆是 假開源或是半開源 就是你可能公佈了全這種 公佈了模型但是你只公佈 Inference的code你不公佈訓練 的code或者是你不公佈資料
(43:07~44:07) 集之類的但這個Lava全部東西 都公佈給大家看直接全裸 真的是超棒的那我們回來講GPT-4 我覺得GPT-4應該 完全就是照Lava這個架構 做出來的而且他們用的模型 應該是一模一樣就是他們應該也是 用Clip為什麼因為Clip 就是OpenAI唯一的而且是最好的 這個我們稱作Image Embedding 的模型就是或是Image Encoding模型但是我覺得 我覺得他們應該有更 強版本的Clip沒有釋出 因為這個Clip還是有分 還是有強弱之分 這個Lava能用的就是現在 目前市場市面上開源 的最好的Clip但是我猜 OpenAI應該有一些 更高解析度更強的Clip他們 有做出來但是沒有公佈然後 他們應該是有用那個最強的Clip 在這個GPT-4V上他 才可以做得這麼好再來另外一個跟Lava 不一樣的點是我覺得GPT-4V 應該是Lava加 OCR就是他還有在外加 一個模型叫做OCR模型 那OCR模型在做的事情就是他
(44:07~45:07) 從一張圖片中抓出 那張圖片所有的字 直接把所有的字辨識出來 那我會這麼說呢是因為我自己實際 測試過就是 GPT-4V的OCR能力 真的是強到一個非常誇張 的地步非常噁心的地步 就是你菜單上很小的看得很不清楚 的那些字他都可以完整的 列出來非常強 但是Lava很明顯他沒有OCR 模型所以說他單純 從這個圖片 的向量當中很難去infer出 這張圖片裡面有什麼字 所以說自己測過之後就會發現 就是Lava這個OCR的能力是非常 非常弱那很明顯他就是沒有 這個OCR模型那我覺得GPT-4 一定有啦所以我們這邊就有個 大概的結論了我猜 GPT-4V就是Lava 加OCRModel 然後他的Lava是用了兩個 變換一個是他的Clip 用的是更強的Clip 然後他的LLM用的是GPT-4 不是Vicuña我猜大方向 應該就是這樣那接下來就是
(45:07~46:07) 一些細節的調整啊就比如說 資料集他們用想盡 辦法找出一些比較好的資料集 然後那個神經網路的架構 他們想辦法調一下 但我覺得基本上就是這樣當然啦雖然說 我還蠻自信應該是這樣的 但是我有沒有可能錯有可能啊 但是我錯了你們會知道嗎你們也 不會啊因為沒有人知道GPT-4 是怎麼做的啊好所以我們就先當 做GPT-4V就是Lava吧 那接下來呢我想花點時間簡單的 討論一下GPT-4V的 商業應用那原本這個 GPT-4呢他只有語言的時候 就已經非常有商業價值了 對吧他可以應用在非常多的地方 那他現在有了視覺 而且又是非常好的視覺 那他的商業應用真的是會廣到非常 誇張的地步我這邊就 簡單舉幾個例子就好了首先 第一個最明顯的就是在教育 產業我們都知道未來每一個 學生都會有一個大型 語言模型的家教嘛 那現在這個家教呢他不只是 只會看文字了他還 可以看圖片不管是網路上很多
(46:07~47:07) 人還是這個Microsoft的論文都有 講到他們都有拿一些 學術的圖片問他問題 他都答得非常好解釋 非常好我自己也有拿一些 Machine Learning的圖片問他 尤其我這次在看這個Lava的論文 的時候說真的Lava 的論文超多的他有兩篇 一篇是今年三月 還四月的時候出的一篇是 上禮拜出的然後為了準備這次 Podcast我真的是兩篇都看完 所以我真的是真的是花很多 時間在讀這些東西然後 其中我就是有直接把圖片丟 到GPT-4V叫他解釋給 我聽他解釋真的不錯 所以當然GPT-4V一定會在教育產業產生非常大的價值 接下來我覺得另外一個 可能蠻大的商業應用是 寫前端程式 這個當然也是很直接啦 就是你原本要叫GPT-4 寫網站的前端他可以寫得很好 他的HTML CSS JavaScript 是非常強的但是 問題是出在於你怎麼Prompt 對吧你要用語言講出
(47:07~48:07) 一個很視覺的東西還是 很難的你可能要講說 左邊有一個工具欄的Tab 然後他是在左邊 但是是靠中間然後上面 你很難講啊 但你今天如果想要做一個網站的Layout 你直接把這個網站畫出來 不管你是用電繪你是用手繪 還是你拿一個現成的網站叫他改 都可以你直接把他丟進去 他就幫你把整頁的HTML CSS寫出來了 然後有了這些Code之後 就簡單了嘛你之後要做什麼微調 你用語言的Prompt也很好 或者是你一樣用視覺下去 Prompt也可以 然後接下來後端的Code API的Code 資料庫的Code那個都簡單啦 那除了這兩項就是教育跟 寫Code以外應該還有很多很多的 應用啦但是他們都太雜了 或者是有一些比較 可能新的我還 沒有想得非常清楚 那我就等到我想清楚了再來跟大家 分享好那這集的最後呢原本 預計是沒有Q&A的但是 呢我看到一則留言是 他叫他的女朋友或是男朋友
(48:07~49:07) 特地幫他這個 在我的Podcast上面提問 因為他說他的留言好像 不知道為什麼在Apple Podcast上面看不到 所以我想說他應該是蠻 迫切需要我的回答所以說 我就在這邊幫他念一下 然後回答一下好那這個 留言的使用者名稱叫做 拜託選我選我然後 這個留言的主題叫做 超讚的Podcast選我選我 所以說看來是非常 想要被選中那我就選你吧 他說幫男友提問 他的留言不知道為什麼看不到 以下是他想對您說的話 哈利大大我是你的聽眾 上週才入坑你的Podcast 內容實在太棒了尤其結合科學 的硬知識已收到我的 必聽的Podcast另外 我有一個問題想請教自己的 工作材料科學相關 與AI和Coding 沒有關係而且自己沒有 Coding的背景但這幾年對AI Coding相當感興趣而且 而且有小學Python想問 除了您的電子書有推薦其他
(49:07~50:07) AI與Coding相關的書嗎 原文書也可以希望你能看到 這則留言如果可以回覆我會 很開心的也會繼續支持您 感謝您好首先謝謝你的 支持看到你的五星留言 我也是很開心不過呢首先你問 有沒有什麼推薦的AI跟Coding 相關的書嗎我必須直接跟你 講答案就是沒有我沒有推薦 任何一本因為首先 我根本就沒有在看書更正我是沒有 從書裡面學AI跟Machine Learning 的知識我不這麼做原因 有兩個啦第一個是我覺得 書過時的很快因為你要 知道AI這個領域變動非常 快非常大你知道嗎 11年前大家才剛開始 Train神經網路嚴格來說在那之前 就有人在Train了但是11年前 那個AlexNet之後大家才 開始認真地去Train 神經網路然後讓神經網路變成主流 再過了11年之後呢我們 有了Chat GPT-4V耶 這個領域現在真的是進展 神速啊那你要寫書 我覺得你至少要一兩年吧 我不知道大家寫書的速度多快啦但
(50:07~51:07) 那個教科書至少要一兩年吧 那你寫出來很容易你剛出版 的時候這本書就已經快要過時了 不過當然啦就是書會 很快過時這件事情會影響的 比較是比較後面的 學習者啦就是對於初學 學者來說是還好就是假設你 已經學到就是很高階了然後你在 學的是可能這些最 新的這些Transformer的這些用法 那當然你看不到任何一本書是在講 這件事情啊因為很多技術它可能 這個論文才上禮拜才剛出來 它怎麼可能會被寫進書裡但如果今天 你是一個完全初學者你可能 從線性代數跟微積分 開始學那當然你不用擔心嘛 就是線性代數跟微積分 就是我不知道牛頓 發明了多久啦我不知道 幾百年都沒變了吧但是對於 初學者來說我還是不會推薦 他們立刻去找一本書因為 這本書還有另外一個缺點就是它非常 不客製化然後因為不客製化 它會導致你的學習不效率 我的意思是這樣我覺得大部分 的教科書它編排非常糟糕 這是因為大部分的教科書
(51:07~52:07) 它是這個作者它作者對於 這個領域非常懂嘛它完全 懂了之後它再回去想 要學會這個領域應該要 從什麼東西開始學然後一直學 學到最後面也就是說它 編排這個教科書的方式是 以你如何精熟這個 科目為最重要的目的 而不是你如何理解這個科目 為最重要的目的所以常常看到 一些教科書就是一開始就是從一些基本 功開始教嘛但這些基本功 你在學的時候你根本不知道你為什麼要學 那個啊然後你學一學學一學你就會直接 迷失在裡面你就直接見數 不見零然後同時呢 一本書通常也會optimize for 完整性它會想要很完整的把 一個概念教給你這件事情的好處 呢是你可以了解到這個領域 非常完整的知識但壞處呢 是你會學到一大堆根本就沒有屁用的知識 舉個例子好了你不是要我推薦那個 coding的書嗎假設你今天買了一本 python的書然後它有一 它有一整個章節一整頁全部都在講 這個怎麼用tuple什麼 是tuple然後你在前面你 一定會讀到這一章嘛因為它也是這個書
(52:07~53:07) 的一部分然後你一定會把它讀完 因為你不確定你這個東西 要不要學啊那你assume這個東西 出現在這個書本上它就是要 學的東西但它其實根本就不是 你去問那些寫code很多年的人 到底有誰用過tuple我自己是幾乎 從來沒有用過這種資料形態但我 ok我其實我應該有看過幾 次在一些code裡面有看過幾次 但你不能看到 的時候再去查嗎反正每一個人 要學一個科目它的目的都不一樣 那沒有一本書是 可以完美的符合你的這個 目的的它一定會教給你 多教一大堆你用不到的東西然後一堆 可能你用不到的東西它 可能沒有教得那麼好所以我覺得要 解決這個問題我覺得對我來說 我自己學習的方法我一直以來 都是從我的目標開始 就是我想要達到什麼目標 我想要做到什麼事情比如說我想要 有能力可以end to end自己 一個人做出一個電腦視覺的專案 那我已經定好了這個目標 我再來想要達到這個目標 我要做哪一些學習ok我當然需要 python但我並不是所有python
(53:07~54:07) 知識都要我只要一些特定 的python知識就好我只要 知道基本的語法然後知道 某幾個library可能像是 nonepypytorch之類的就好了 你看書它一定會教給你一大堆 你根本就用不到的library那AI 這邊的知識呢你會看一樣是 從最高層次開始往下看你要 學什麼比如說你要做電腦視覺專案 所以說你要先學會什麼是 resnet這個東西你要用resnet這個 模型來做那你要學會 resnet你必須要先學會什麼你要先 學會什麼是CNN對不對 convolution neural network那要學會 CNN你必須要先學會 什麼是neural network對吧是一個基本 的neural network到底是什麼東西 然後你這樣一路的拆解下來你就會發現 你就會知道你有哪些東西是 你要先著手開始學習的 那你就從那些東西開始 一層一層學上去那在學習 每一層知識的過程中呢 你有可能會用到書沒錯你可能會 有一本書是講這個聲音 網路講得特別好了那你就去買 這本書你就去看一下你就去看幾個 章節就好但是你要知道這本書
(54:07~55:07) 就是在幫你填補你知識漏洞 漏洞中的其中一塊 你不要期待它會給你 整個知識架構整個知識架構 是你自己要建出來的從你的目標 建出來對不對我剛剛就有說 那建出來之後你在看 你是要用書去填補某些 知識漏洞還是想用線上 課程去填補某些漏洞 還是想用YouTube影片去填補某些 知識漏洞或是你要自己去看 一些論文或者是也都可以 那反正結論是這樣就是 我覺得我建議你你自己去想一下你 到底為什麼想學AI跟coding 然後找一些你自己最有興趣想做的專案想解決的問題 設定了這個目標之後 再從這個目標開始拆解 去做一個知識架構出來 那這個知識架構一定有很多知識漏洞 然後你之後再透過各種 地方找來的資源 慢慢填補這些知識漏洞就好了 那我自己有幾個我覺得 超讚的學習資源可以推薦給大家 第一個呢如果你想要 學數學你就找一個YouTube頻道 叫做3Blue1Brown
(55:07~56:07) 真的相信我你絕對不會後悔 我尤其大推他線性代數系列的課程 哇那真的是 幫我開啟一個新世界 然後你如果想學AI的知識 我建議大家去搜尋一個叫做 StatQuest的一個YouTube頻道 一樣是YouTube頻道我都從YouTube學習的 StatQuest的拼法可能比較難 就是STAT然後 QUEST StatQuest 這個StatQuest的頻道他講這個 Machine Learning的概念講得非常好 而且我不只從他的頻道學到超多 這個Machine Learning的概念 他也是我人生中的一個Role Model 就是他背後的那個人 叫做Josh Stammer Dr. Josh Stammer 他真的是我非常崇拜他 那Coding的話我就沒有特別 推什麼啦但我就不用怕啦 就你如果真的你是為了AI 學Coding的話真的不用怕 你就是學Python就好啦Python那麼簡單 如果你真的是很想看一本書 那我真的很抱歉我沒有辦法給你 一個很好的建議但希望我剛講 那些對你有用好那本集最後 最後也要再感謝一下我們這一集的 乾爹Keychron機械鍵盤
(56:07~56:29) 真的是非常好用的一個鍵盤 本集的Show Note就有產品連結 然後記得在10月31號之前 輸入專屬折扣碼 Harry200就可以折200塊喔 另外你若是廠商然後你的產品很好 想要找地方打廣告 你可以考慮一下科技朗寄個Email給我 我就會跟你談詳細的Podcast數據 以及報價等等相關資訊 那最後祝大家有個愉快的一週
