(00:00~01:00) 【音樂】 哈囉大家好 歡迎收聽科技浪 我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂 但是又深入的方式 帶你了解時下最火的科技話題 好 那今天在進入主題之前呢 我要先跟大家推薦一堂 我覺得超讚的投資課程 這堂課呢 是由復果這間投資公司 推出的超級投資力課程 好 那從我開始做自媒體以來呢 我接過最多的業配邀請 就是投資相關的業配 但是你如果追我夠久你就會知道 我從一開始到現在我接了幾堂投資業配 答案是0 我從來沒有接過投資業配 我把他們全部都拒絕了 因為絕大多數這些投資業配 我覺得我一進去看我就知道 這個東西就是在騙人錢的 他們以為我是一個理工宅不懂啊 但是我其實大學是商學院的 投資的東西我也是讀過很多的 但前一陣子啊 這個復果的人就有找我說 誒 他們有這堂投資的課程要給我推薦
(01:00~02:00) 那在這之前我就有聽過復果了 所以我知道復果這間公司裡面 都是一些台大政大的聰明人 所以我就想說OK 那我可以來看一下 然後我看完了他們發給我的體驗課之後 我立刻就跟他們說OK 這堂課我可以推薦 因為這堂課的含金量真的是非常的高 我覺得這堂課好主要有三個原因啦 首先他教導的投資觀念是很正確的 再來他的方法論 非常的嚴謹非常的完整 最後這些講者 真的都是很厲害很專業 一聽就知道是聰明人 首先為什麼我會說他們觀念是正確的呢 當然這部分有一點我自己主觀的意見啦 你可以disagree 但我覺得他們這個方法是最有邏輯最正確的 最有科學根據的 他們在做的事情就是從這間公司的基本面出發 非常完整的分析 這間公司的一切包括內部外部的因子 然後再搭配財報上的量化分析 真正的算出這間公司的估值 那跟這種看基本面的投資相對的呢 就是跟這個公司的估值相對的 那跟這種看基本面的投資相對的呢 就是看技術面的投資嘛 那我這邊並不是在說技術面的投資比基本面爛
(02:00~03:00) 或是他是不正確的投資方式 只是在我自己主觀的意見當中 我比較認同的 然後同時也是我自己有在做的 是基本面的投資 就是比起可能短期內靠著這些 價格走勢跟交易量的資訊 在那邊殺進殺出 我比較喜歡好好的靜下心來研究一間公司 把它全盤研究得非常徹底 看出它真實的價值究竟在哪裡 好的話我就投錢下去 一同參與它的未來 這才是我自己最認同的投資方式啦 同時我也覺得這應該是我自己 被國外的這些投資大師 像是巴菲特查利蒙格影響之後的想法 而且我覺得學習這種基本面的投資法 不僅是增加你未來投資賺錢的可能性 不僅是增加你未來投資賺錢的可能性 還是一個提升自我的好方法 因為在你深入的研究這個公司這個產業的過程中呢 因為在你深入的研究這個公司這個產業的過程中呢 同時你是在不斷地鍛煉你自己的思維 跟你的眼界 你研究完一間公司你都會成長超級多 學到超級多東西 所以我覺得復國推出這種從基本面出發的課程 我覺得是非常棒 再來我說復國這堂課啊
(03:00~04:00) 它不僅是觀念正確 它的方法論也是很嚴謹很完整的 要知道同樣是基本面的分析 也有很多很多不同的派別嘛 有很多很多不同的方法論 那很多這些方法論呢我一看就覺得 挺糟糕的 因為先不論這個方法論有沒有用 你最低最低的標準就是你的框架要完整嘛 你的分析框架必須要完整包含到這間公司 以及這整個市場 所有會影響股價 會影響這間公司估值的因素 你如果連這個框架都抓得不完整 就漏洞漏稀的甚至有一些分析還重複了 重疊的 那就不用看這個分析框架到底有沒有用 一定沒有用嘛 那復國這個框架呢我一看就知道這是很不錯的一個框架 它把一間公司的內部因子跟外部因子 切得非常乾淨 然後也沒有遺漏任何重要的東西 而且他再繼續講下去我就發現 這個框架底下做的每一個分析都是非常嚴謹的 他們在看一間公司他的產品 他的商業模式的時候 以及看他這個公司在市場上 這個產業中他的競爭力 以及需求端的分析的時候 我覺得都做得非常的棒
(04:00~05:00) 那量化分析的部分呢也就是他們從財報的數字 結合之前這個基本面的直化分析 做出來的分析 我覺得也做得非常棒 尤其他們在解釋這些財務指標的時候 真的是解釋得非常好 那最後呢就是不只這個觀念正確 方法論也很嚴謹 這些講者也都是非常厲害的人 這堂課是由復國的創辦人 暨投資長以及復國的 首席研究員共同開課的 這兩個人一開口就知道是聰明人 所以這堂課我覺得不管你是 投資新手還是老手都還蠻適合 上這堂課的尤其你如果是新手 然後你還沒有建立自己的投資 觀念建立一套你自己的方法論 的話我覺得你蠻適合參考 一下這堂課而且說真的這堂課 其實不只教你投資而已他還教你 商業分析的思維 商業分析的思維我真的覺得 是在這個AI的時代 是非常有用的一個軟實力 現在到我這集的Show Note你就可以看到 這堂課的資訊連結了 有興趣的朋友建議趁還有優惠的時候 趕緊下手而且我這邊還可以再提供給大家 一個優惠碼的資訊
(05:00~06:00) 這是我自己專屬的優惠碼叫做 Harry500你在結帳的時候輸入 Harry500你還可以再折500塊 想買的人要趕緊抓住早鳥優惠 然後也不要忘記輸入我的優惠碼 那業配時間就到這邊結束了 謝謝復國的贊助 那我們今天呢所有的話題其實都是 圍繞著一間公司 那就是CloseAI OpenAI 那我們在講這間公司是誰 然後他做了什麼事情之前呢 我們要先從我們這個Podcast的 逐字稿講起沒錯 科技浪從這集開始呢 終於有逐字稿了每一集我都會在 Show Note放下這個逐字稿的連結 我知道很多人會聽我的Podcast聽很多遍 所以我覺得提供這個逐字稿可能多少 對某一些人來說會有一點幫助 然後這同時呢也是我這個 更加妥善利用這個Podcast 內容的第一步因為有了逐字稿 之後呢我就可以對於這個Podcast的文字 做一個分析不管我是要 總結還是要搜尋 都可以做得到但這一部分 就是我未來還在規劃的東西啦 我還不確定怎麼利用這個Podcast
(06:00~07:00) 逐字稿對於大家來說是最讚的 或者說有人想幫忙做 也是可以啊那總之呢我有了 這個逐字稿那這個逐字稿呢 我建議大家可以點進去看一下 這個逐字稿現在完全 都是用Whisper這個模型產生的 Whisper這個模型呢就是 OpenAI釋出的一個語音辨識 模型我真的很推薦大家 打開這個逐字稿看一看因為它 真的是精準到爆大家要知道 這個逐字稿100%全部 都是由Whisper產生的它產生 之後我完全沒有動工我就直接 把它這樣放上去你可以看到它 錯字多少具體來說呢 這個Whisper其實是有不同的大小 它從那個Tiny, Small, Medium, Large 都有那我用的是 Large V2是第二版 的Large模型也就是最大的 模型那我還記得Whisper這個模型 去年剛出來的時候呢 它只有到Large它沒有Large V2 然後那個時候我就有使用過Whisper了 我是直接使用那個Large的 模型再辨識中文然後發現 還蠻糟糕的 雖然說比其他的語音辨識
(07:00~08:00) 模型已經好很多了但它 還是蠻糟糕的當然它辨識 英文的能力已經是頂級了 就是它基本上已經把英文辨識 這個問題已經解決掉了 解決掉了的定義是什麼呢 在我的個人定義當中我覺得就是 當一個AI可以做得跟一個正常的人類 一樣好的時候就代表 它已經把這個問題解決掉了 那在英文的部分Whisper Large 就已經把這個英文的 語音辨識解決掉了因為它做的真的是 近乎完美啊它的WER WER就是我們平時判斷 這種語音辨識模型最常用的 指標之一它的全名叫做 Word Error Rate 翻成中文就是文字錯誤率啊 那這個錯誤率它在算的就是 你100個字當中你會辨識錯幾個字 然後這個Whisper Large它在 英文的辨識WER呢 它可以做到4.5 意思就是說100個字當中 它只會辨識錯4.5個字 而且這4.5個字並不一定是全部錯喔 它可能只是一個沒大小寫 或者是一些Formatting的問題 或者是有些它訓練資料當中
(08:00~09:00) 根本沒有出現過的專有名詞 所以說這個已經跟一個正常人 差不多甚至比正常人還厲害了 所以我覺得英文已經完全被解決了 但是在中文呢在中文這個 Whisper Large它能做到的WR 就是19.6 這很明顯就不夠好嘛就是你 100個字當中你只能你會辨識 錯20個字然後確實啊 我那時候就有它剛出來的時候我就 有用了一下這個Whisper Large來辨識 中文我那時候拿的資料集我是 我是用古癌的資料古癌就是在台灣 很有名的一個投資Podcast 我自己是沒有在聽啦但是 中文的Podcast我真的知道沒有很多 我自己有在聽的就是 Mula這個M大M觀點 那我那時候就拿古癌的資料 意思就是說我把古癌一集下載下來 然後讓Whisper去做辨識 然後那時候Whisper Large做出來的結果 蠻糟糕的就是 湊字連篇啊然後同時我在網路上 看到另外一個人他是拿Whisper Large 去用一個中文的資料集去Find Tune Find Tune就是微調的意思嘛 意思就是說你拿一個新的資料集 再讓這個模型再多訓練一點再多加強
(09:00~10:00) 他某一部分的能力 那這個人是用這個中文的資料集 來Find Tune這個Whisper模型啊所以說 這個Find Tune過後的這個Whisper Large 應該是比較會中文的 Whisper同時他要把這個 模型放到Hugging Face上面 Hugging Face基本上就是這些機器學習的人 存放自己模型的地方啊 這個平台上存放了超級 無敵多的模型然後我看到有這個模型 可以用我就把他抓下來用用了之後發現 欸確實他在古矮的辨識是 好非常多的但是還不到 那種我覺得可以直接放出來使用 的地步然後在那之後呢我就沒有 在特別關注Whisper這個模型 但沒想到他們在12 月的時候去年12月的時候 悄悄釋出了一個Large V2 這個Large V2他跟V1 的模型結構基本上是一模一樣 的唯一有改變的地方 是他多了2.5倍的epoch 我們在Machine Learning裡面我們講到epoch epoch這個字拼法是epoch 我們在講到這個字的時候 我們的意思就是說一個AI 模型把整個資料集看過一遍 訓練過一遍這個叫做一個epoch
(10:00~11:00) 所以說這個V2的epoch 比V1的epoch多2.5倍 意思就是說他把這個資料集 多看過了幾遍假設這個 WhisperLarge V1他 總共只有把整個資料集看過 四遍的話這個Large V2呢 就是把這整個資料集看過十遍 這是他最主要的改變啊但是 他出來之後呢 其實沒有什麼新聞因為12月那時候 是什麼時候那是ChatGVT 出來的時候嘛那時候大家都 在看ChatGVT誰在管Whisper 所以在我的印象中Whisper這個模型 他語音辨識中文的能力就是 不夠好我自己也沒有去用過這個Large V2然後一直到上個禮拜 我想說OK我覺得 應該要來為我的Podcast做一個 逐字稿那這個時候我第一個想到 的當然就是Whisper這個模型嘛 因為儘管我在我印象中他的 中文不夠好他也是現在所有 語音辨識AI模型中最強的了 而且最讚的是什麼Whisper這個 模型是開源的他的論文 他的code他的權重全部都 公佈給大家那我自己也是非常 擁抱這個開源社群的所以說
(11:00~12:00) 要用我當然是用Whisper這個模型 然後去講到說這個Whisper模型 啊他的中文辨識能力就不夠 好嘛所以說我要做的事情呢 就是先蒐集我這個Podcast 的正確逐字稿 我們在Machine Learning裡面我們叫做 Ground Truth有了這個正確逐字稿 之後我在拿這個正確逐字稿 去Find Tune一個Whisper Large 把它變成哈利科技浪版的 Whisper Large這樣子應該就會 夠好了然後要做這件事情 我當然可以自己做我就是 先用Whisper先翻譯出一個版本 然後再把那個版本修成 正確的版本然後再拿這個正確 版本再去訓練Whisper嘛 但我覺得很麻煩所以我就想到 前一陣子好像有一間AI的新創公司 來聯絡我這間新創公司 我記得都是台大的人 然後他們在做的是中文的Text to Speech Text to Speech就是 文字轉語音啊然後他們前一陣子 就有聯絡我說他們也是 科技浪的聽眾然後他們想要 拿我的聲音去訓練他們 第一版的AI語音模型 就是幫我做一個AI
(12:00~13:00) 語音的分聲的意思我看到 我當然覺得讚喔當然可以 所以我就授權我的聲音給他們用 但我上禮拜就想到他們在做 這件事情的時候他們一定有一個 資料集是我的聲音跟他對應的 逐字稿的資料集 那個資料集根本就是我現在需要的 資料集啊所以我直接跟他們要就好啦 那確實呢我就是寄了一封 信給他們之後他們隔天立刻 就把他們的資料集傳給我我覺得超讚的 然後他們寄給我這個資料集的時候 他們是跟我說這個資料集呢 完全是由Whisper Large V2 製作出來的 然後我點進去一看之後發現 哇不得了這個超級準啊 這個中文的WER呢絕對在 各位數啦我覺得 這辨識的真的是非常準確 所以說呢我也省了工我根本就不用拿我的資料集 自己再去微調一個Whisper 我直接拿這個現成的Whisper就可以啦 我覺得我去微調大不了 就是這個Whisper它對於 某一些字眼它的辨識度 會變強就比如說深層式AI 這個詞呢在Whisper資料集 應該是沒有什麼出現啊畢竟這個詞
(13:00~14:00) 是我們可能2023年才開始 比較常講的你現在如果有立刻 在看那個逐字稿你應該就可以看到 我剛剛有講個幾次嘛我現在又再講一次 深層式AI 我猜它應該是沒有翻譯出來啦 那如果我多花很多力氣去微調 這個Whisper呢它最多就是把 這個深層式AI學會 那我覺得這個這impact太小啦 我覺得現在這個 這個將近各位數 的這個WER我覺得就已經夠好了 所以我在這件事情的take away 有幾個第一個呢Epoch 書很讚很重要 可以大幅的影響這個模型的 改變你想讓它進步你可能就多train幾個Epoch 當然這個也不是很單純的 就是越多越好啦 因為這個Epoch它還是有它自己的trade off 就是你如果Epoch數量太 高的時候你的模型很容易 overfit意思就是說它直接把 你的資料集背起來完全死 背起來然後你真實在使用的時候 它遇到了新的資料它就不知道怎麼反應了 但它確實是一個可能可以大幅 改變模型表現的這個 超參數另外一個take away呢
(14:00~15:00) 就是Open Source超讚 為什麼呢因為我這次用Whisper啊 我現在在這個2023年的 9月用Whisper跟我2022 年的時候使用Whisper不只是中文 的辨識變強而已喔現在的Whisper 模型的速度變得超快 模型的大小變得超小 我那時候在使用的時候我記得啦 我用那個large的模型啊它辨識 的速度比這個音檔的長度 還長意思就是說我40 分鐘的一集podcast它要超 過40分鐘它才可以全部辨識 出來但是我上禮拜用 這個Whisper我一集podcast40 分鐘我6分鐘就全部 辨識出來了為什麼呢這當然 要感謝這個開源社群啊 因為這個Whisper模型它是開源的 它的code都有公佈出來所以網路 上這個開源社群的這一群鄉民呢 就會用這個這一年很流行 的一些加速AI 模型或者是壓縮AI模型的方法 把這些方法寫進那個code當中 讓Whisper可以跑得更快 然後用更少的記憶體 這就是開源社群很棒的地方你 模型只要開源你一釋出你什麼東西
(15:00~16:00) 都不用做一年之後它會進步 這麼多我甚至還有看到 有一個人在做這個Whisper Jax 這其實是有一個粉絲回覆我的 限動我才想起啦就是 他提到Whisper Jax這個東西 那我印象中我也有看過好像是 今年5月6月還是什麼時候出來 的一個新聞就是有一些人 使用Google的一個機器學習 架構叫做Jax來寫 Whisper的推論的code 那Jax這個架構呢我記得我在上 一集好像有短暫的提過 他是Google最近開發的這個機器 學習的架構他強的地方呢 就是在於他可以非常快速 的做這些AI相關的 這些數學運算尤其是這個 矩陣成法然後聽說 呢用Jax這個框架來跑Whisper 這個模型呢比Pytorch快超 級多然後我自己也是試了 一下我發現40分鐘的 引擋兩分鐘以內就全部辨識 完成了真的是快到爆 所以說呢這個就是開源社群 的力量所以我們在這邊非常感謝 這個OpenAI那時候開源了 Whisper這個模型但是
(16:00~17:00) 很可悲的是呢Whisper 應該是OpenAI最後一個開源 的重要模型在Whisper 之後的所有模型全部都是 完全閉源的閉源的意思就是說 你不公佈這個模型的論文 你不公佈這個模型的code 你不公佈這個模型的細節 當然你也不公佈這個模型本身 然後一般大眾要使用這個模型 只能透過你們家的API來 使用意思就是說這些模型 全部都是部署在這個 OpenAI他們自家的伺服器上面 或者是應該說是Azure上面 因為他們現在跟那個微軟 簽訂了一個合約然後他們可以使用 這個微軟的雲端服務也就是Azure 然後我們一般人完全不知道這個 模型的任何細節嘛我們唯一 可以碰到這個模型可以使用這個模型的方法 就是從我們自己的client side 也就是我們自己的裝置 像是我們的筆電我們的手機 我們發一個request到 OpenAI的這個伺服器 然後這個伺服器呢把算完了之後 把這個結果回產給你 我們完全不知道這個過程中 這個模型他們究竟是怎麼handle
(17:00~18:00) 這個request怎麼算出這個結果的 我們完全不知道然後在這之前 OpenAI其實真的都會開源他們的模型 像是GPT2就是 完全開源的所以說呢現在很多人 都會把OpenAI稱作是close AI 甚至馬斯克前一陣子在 一個高峰會上面說他覺得 OpenAI現在應該被稱作close for maximum profit AI 也就是幣源且盈利最大化的AI 然後這個OpenAI上禮拜 其實有一個非常大的新聞 我覺得算是AI界的頭條啦 現在這個OpenAI每次發新的 模型基本上就是會變成 這個AI界的頭條為什麼會是 頭條呢因為大家都很關注 這個OpenAI這間公司為什麼大家都 很關注這間公司呢如果你還不知道 的話大名鼎鼎的ChatGPT 就是OpenAI做出來的 然後有些人可能也會知道在 這之前有一個AI繪圖 模型輸入文字它就產生圖片 的模型叫做Dali2 D-A-L-L-E-2 Dali2 也是OpenAI做出來的 所以大家都有這個想法就是
(18:00~19:00) OpenAI做出來的模型一定都是 最重量級的因為他們不僅他們 做出了很多很屌的產品他們OpenAI 的研究team也是超級屌 有很多我自己這個非常非常 崇拜的Machine Learning Researcher 都在OpenAI好那他們這一次 公布的模型呢就是Dali2 的下一個版本Dali3 但我覺得我們在講Dali3 之前啊我覺得我們應該要先 前情提要一下跟大家 簡單介紹一下OpenAI這間公司 從古到今他到底做了哪些 事情他是怎麼樣的一間公司 說真的我們身為一個講AI的頻道 NVIDIA我們講過了蘋果 也講過了Google也講過了怎麼可能 不講OpenAI呢OpenAI其實 最應該講他是ChatGPT 元老啊他是十組啊 意思是說把這個生成CEI帶到 大眾的眼前的就是這間公司 那我覺得如果你是Machine Learning 的圈外人呢你應該可能 是今年你才認識這個OpenAI 這間公司然後今年說真的他們 曝光率蠻高的尤其是Sam Almond 他到處接受一大堆訪問 Sam Almond就是他們的CEO啦
(19:00~20:00) 我不知道中文怎麼講他應該沒有中文名字 奧特曼嗎 但我覺得說真的我覺得大部分人 沒有辦法透過這些訪問 了解OpenAI究竟是什麼樣的一間 公司同時也不可能了解 就是這間公司從一個非 盈利組織變成了一個盈利公司 他這之間經歷的轉變 為什麼會有這些轉變他的理念 有怎麼樣改變之類的所以我們就先從 最一開始講起好了那這間 公司的源頭呢其實我們 要先從Elon Musk 開始講Elon Musk就是那個Elon 馬斯克Elon Musk那接下來內容 呢一部分是我聽馬斯克 傳聽到的內容如果你不知道的話 最近出了馬斯克傳這一本 書是由賈伯斯傳的作者 寫出來的我覺得真的是寫得非常 好我自己是買有聲書 所以我是用聽的然後我現在聽了 大概超過一半一點點 跟大家推薦一下超讚的一本書 馬斯克在2012年 的時候也就是11年前喔 他認識了一個叫做Demis Hassabis的人這個Demis Hassabis是一個超級無敵聰明的AI
(20:00~21:00) 專家他同時也是這個 AI新創公司DeepMind 的創辦人那馬斯克跟這個 Hassabis立刻就變成好朋友 因為他們聊得來然後聊天的過程中 馬斯克更認識AI這個東西 他也更發現說AI 毀滅人類是一個真實的風險 喔這其實很厲害喔就是在 2012年13年那個時候 那個時候的AI跟現在的AI比正是 訓到一個爆但是那個時候馬斯克就 意識到說AI毀滅人類會是 一個風險當然這個風險現在 已經變成是所有AI專家 都在討論的一個真實風險了 你如果想更了解這個風險你可以去聽 我的EP2第二集我有很完整的整理這個 正反方他們所有的論點 然後同時呢這個馬斯克 也知道他的好朋友就是Larry Page Larry Page是谷歌的創辦人 他知道Larry Page他對於這個 AI毀滅人類的風險沒有很認真 他覺得這個其實是一個Sci-Fi 就是科幻小說的東西 然後在2014年的時候谷歌宣布 他們要買下DeepMind也就是 DemisHassabis的那間公司 然後馬斯克看到這件事他就說
(21:00~22:00) 哇大事不妙一個對於AI 毀滅人類風險這麼不正式的一個人 竟然收購了現在最強的AI公司 他覺得我們把AI的未來 也就是人類的未來 交給Larry Page 是非常不正確的選擇 所以他覺得世界上必須要有一股 新勢力可以跟谷歌抗衡 所以他在2015年的時候 也就是谷歌收購DeepMind 之後的隔年他就聯絡了一些 朋友包括Sam Almond 成立了一間公司叫做OpenAI 然後還花了超報告的薪水 把谷歌的一些頂尖的AI科學家給挖過來 所以OpenAI成立的初衷呢 就是跟谷歌抗衡的一個組織 而跟谷歌抗衡 他背後要做到的事情 他真正的這個Mission 是要確保AI並不會毀滅人類 而是讓人類走到一個更好的地方 那這個是他們最大的使命 那他們的研究方向呢 主要是朝AGI走 AGI是Artificial General Intelligence AGI的意思就是 它是一個人類能做到的所有事情 它都能做到
(22:00~23:00) 而且可以做得跟人類一樣好的一個AI 這其實就是所有在研究AI的人 在追逐的一個聖杯 那AI所謂Artificial Intelligence 就是讓機器在模仿人類智能這件事情 而模仿人類智能的一個重大里程碑 就是人類智能能做到的事情 它都可以做到 然後大家可以去看這個OpenAI的官網 它其實它有寫出它的Mission Statement 它的Mission Statement就是 Ensure that Artificial General Intelligence AGI benefits AI AGI benefits all humanity 翻成中文就是 確保AGI可以讓人類變得更好 再翻譯一次呢 就是說建一個好的AGI 當初馬斯克創這個公司的初衷呢 你也可以看到 它並不是要賺錢 它是要跟Google來抗衡 它是要為了這個人類的利益著想 因為它覺得Google在做的事情 有可能會損害全人類的利益 所以說這間公司2015年在成立的時候 它是一個非營利組織 好那OpenAI成立了之後呢 它一開始的研究方向 是Reinforcement Learning
(23:00~24:00) 增強式學習 這個大概是它從2015年到2018年的 研究主軸 然後我那時候也是透過這個Reinforcement Learning 認識OpenAI的 就是那個時候所有在學Reinforcement Learning的人 一定都會接觸過OpenAI 首先什麼是Reinforcement Learning呢 什麼是增強式學習呢 這個增強式學習啊 它是一個讓AI學習的一種方式 比較常接觸到的這種AI學習方式 都是監督式學習 意思就是說你自己先整理好 一個資料集 然後你把這個資料集餵給AI 讓AI從這個資料集中學習 學習好了之後AI再看到新的資料 就可以自己做判斷了 但增強式學習不一樣 它是直接讓AI把AI放到一個環境中 讓它自己行動 並從不斷試錯的過程中學習 意思就是說AI會自己在這個環境中行動 那它每做一個動作 它就會觀察一次這個動作會造成什麼樣的後果 然後它如果發現呢 在這個A環境下A情況下 它做X行動是有好的結果的話 它下次遇到A情況
(24:00~25:00) 它就會多做一點X行動 相反的如果它發現在B情況 做Y行動是不好的 那它下次遇到B情況的時候 它就會少做一點Y行動 然後會嘗試一下其他的行動看看會不會有更好的結果 反正就是讓AI自己去摸索這個環境 自己去做很多很多的嘗試 然後從無限次的錯誤中學習 那OpenAI用Reinforcement Learning這個技術 推出的產品當中呢 最有名的有兩個 一個是OpenAI 5 OpenAI 5就是一個它會打 Dota2的AI啦 Dota2就是一個推塔遊戲嘛 就跟英雄聯盟有點像 那這個Dota2打得很強啊 就是比99%的玩家都還強 它做到這件事呢 就是透過Reinforcement Learning 就讓這個AI自己在這個Dota2這個遊戲環境中摸索 讓它發現說 什麼樣的策略什麼樣的行動 做什麼事情在什麼情況之中 是最好的 另外一個有名的產品是OpenAI Gym 那大部分人就是透過這個 認識OpenAI我也是透過這個認識OpenAI OpenAI Gym是一個
(25:00~26:00) 提供了很多要訓練這些 Reinforcement Learning的AI所需要的 環境的一個工具組 最有名的就是Atari系列的環境啊 這個Atari呢中文叫做 亞塔利 說真的我完全沒有聽過這個中文 我不確定我講這個中文會不會有人認識 但反正它就是一系列的這些 復古遊戲就是那種像素風格的 簡單的小遊戲 像是就是你有一個戰機 然後前面有些敵人然後 你可以上下左右移動然後要射那些敵人 就這樣然後大家就是可以用這個 OpenAI Gym提供的環境呢 來訓練一個AI是可以把這些 遊戲玩得很好的 然後訓練的方法呢當然就是用 Reinforcement Learning的方式訓練 那說真的啦就是OpenAI在這個 這個領域的貢獻真的是蠻大的 很多人呢也透過這個 OpenAI Gym認識了 Reinforcement Learning然後也實做了很多 Reinforcement Learning的專案 但說到底啊Reinforcement Learning 還是不太夠OpenAI一開始 會想要研究Reinforcement Learning呢 是因為他覺得Reinforcement Learning
(26:00~27:00) 是最接近人類學習 然後人類做決定的方式 因此應該也是最有可能 帶我們人類走到AGI的方式 為什麼這麼說呢因為人類 人類在學習的時候 跟Reinforcement Learning其實很像嘛 我們也是在未知的情況中學習 然後從錯誤中學習 但這個Reinforcement Learning一直很難被 運用在實際現實世界中的問題當中 他通常都是被拿來 就是解決一些遊戲的 讓AI自己去玩遊戲玩Dota2 但現實世界中的Task 就很難用Reinforcement Learning解 這是因為現實世界中的問題 通常你的情況跟行動 會更複雜會複雜非常非常 非常非常多像是我剛剛講到那個 飛機射擊的遊戲啊他所有可以 遇到的情況就是你這台飛機 他所有可以去的地方 以及所有敵人的位置 然後你可以做的行動就是上下 左右跟射擊這五種但假設 你今天要解的問題是一個自動駕駛 的問題好了你可以遇到的情況 有多少種超級無敵爆多種 然後你說行動行動其實沒有說變
(27:00~28:00) 很多種嘛就是方向盤左右 跟彩油門剎車啊但你要知道 這個Reinforcement Learning他的困難點 不只在於情況跟行動的多種 還有在於這個獎勵 要怎麼定義獎勵要怎麼定義 是最最tricky的我這邊所說的獎勵 啊就是你在訓練一個 Reinforcement Learning的AI的時候 你必須先定義在什麼情況 之中遇到了什麼結果 這樣子的結果是好還是壞應該 要給多少獎勵我們明確定義 的每一種結果他的好壞 AI才會知道要爭取哪些結果 避免哪些結果嘛在一個那個 飛機的遊戲很簡單啊你 打掉敵人就是好的結果啊 你被敵人打掉就是壞的結果啊 但是自動駕駛呢你的好結果 跟壞結果要怎麼定義反正這些OpenAI 的人呢就看這個Reinforcement Learning 就覺得AI會自己玩遊戲是很 酷沒錯啦但他好像沒有辦法帶 我們走到AGI直到2017 年的時候Google有一部 震驚世界的論文問世 這篇論文呢叫做Attention is all you need這篇論文 他最大的貢獻就是他介紹了一個叫做
(28:00~29:00) Transformer的架構 這個架構現在是非常非常重大的 一個發明為什麼呢沒有這個架構 的話就不會有現在這一波生成 是AI因為現在所有這些大型 元模型他背後的架構都是 這個Transformer的架構 那這邊很多技術的細節我就不講啦 但反正Transformer這個架構 非常有名的幾點除了那些 什麼Attention以外就是 他非常非常Scalable Scalable的意思就是說你可以把他的 規模做得非常大他會這麼Scalable 主要的原因就是他可以平行處理 很多的訓練資料就是比起 當時的其他架構什麼RNN LSTM他們可能一個一個 資料處理很明顯他們就無法Scalable 但Transformer可以Scalable然後 2017年那時候呢Sam Almond 一看到這篇論文他立刻就說 this this is it沒有了沒有 他聲音應該沒有那麼低應該是this is it 他立刻就把他們研究的主軸 從reinforcement learning帶到Transformer 他們直接all in這個Transformer 的架構然後也是從這個時候 他們慢慢從一個非硬力組織 轉向了一個盈利組織
(29:00~30:00) 這個轉變他背後的一個很大的 原因我自己覺得應該就是 資源問題非硬力組織 太難獲取資源了而他們現在 訓練的這些Transformer的模型 因為他們會把Scal到很大 很大的一個規模幾百億幾千 億個參數這種規模 所以他們會需要很多很多的運算資源 所以Sam Almond是覺得我們如果變成 一個for profit的公司我們 可以得到創投投資人的錢 然後我們可以把這些投資人的錢拿來 做一個產品讓那個產品賺錢了之後 再把那些賺的錢 再投資回來做更大的產品 然後他們就秉持這個理念 開始做了GPT,GPT2,GPT3 一直到GPT2都還是開源的 但是到GPT3就整個開始 閉源了我猜應該是這樣 就是GPT2真的還是 笨笨的你自己去用過你就知道 蠻廢的但GPT3就真的 有商業價值了他已經夠聰明了 那確實他們就有拿GPT3 去做了一些不同的模型然後 去賣這些API嘛 說真的GPT3那時候剛出來的時候 我覺得他紅但他沒有
(30:00~31:00) 紅出圈外,意思就是說我那時候 有在看Machine Learning的東西我就有 看過我就有看到他那時候好像是 2020年還是2021年吧 蠻久以前的那時候出來 就是有看到就是OpenAI用GPT3 Demo他講笑話然後解 一些邏輯題目那時候我就覺得 哇操這個真的是非常 非常厲害但是那時候我 身邊的就是一般大眾都完全 不知道GPT3這個東西 甚至不知道OpenAI是誰因為他們沒有 把他真的做成一個產品啊他就 真的就是一個AI Research的形式在發表 所以就只有紅在圈內而已但是在 這個2022年啊2022 年的4月OpenAI釋出了 Dolly2Dolly2就是 我一開始講的那個就是繪圖 模型嘛你輸一行文字他 就會產生一張圖片哇那一次 真的是爆紅我覺得那一次就是 第一次紅出圈外因為OpenAI 做了一個網站讓大家都可以試玩這個 Dolly2你要waitlist啊你要 你要先去等待一開始你要等 我記得我等了超久我等了可能一兩個 月吧他才給我那個access
(31:00~32:00) 他一給我access我就開始 爆完然後哇我真的是 我整個晚上我停不下來因為真的是 太震驚了太好玩了 當然依照現在的標準隨便一個Stable Diffusion或者是Mid Journey都可以 屌打Dolly2但Dolly2那時候 剛出來我真的是第一次看到 AI可以做到這種程度真的是非常 非常震驚然後那時候啊我還記得 我常常在網路上看到一些人 他們指著那個Dolly2做出來的 圖片說這個AI他就是 在做一個Google search找相似的 圖片而已啊或是有些人會說 這個AI在做的就是他把一些 相似的圖片抓出來然後 剪輯成一個新的圖片啊 我聽了我真的覺得又可笑 又生氣這些人真的是 我什麼都不懂然後在那邊亂講話 那這些人呢當然再過幾個 月到到了這個2022年的 12月或者是2023年 初的時候他們全部都閉嘴了 因為ChatGPT在 2022年12月問世 他們發現AI 真的變得非常聰明了 那我覺得Dolly2呢是
(32:00~33:00) OpenAI第一次紅出圈外 但說真的他的名聲在圈外 還沒有很紅就有些人知道 有Dolly2這東西有知道 有繪圖AI但他們不知道他是 OpenAI但ChatGPT呢 是紅出是爆紅 是爆紅出圈外紅到爆炸 而且大家都開始認識OpenAI 這間公司了那時候大家嘴巴上都 掛著一句話就是ChatGPT是 人類歷史上成長最快的 科技產品他花了兩個 月就達到一億的用戶 跟他相對的IG花了 30個月才達到一億用戶 抖音花了九個月才達到一億 用戶那接下來的歷史就不用我講啦 接下來就是他們在2月 的時候發了這個Code interpreter 大家要知道就是Code interpreter 這個東西啊雖然說最近才爆紅 可能7月還是8月的時候 才爆紅甚至有些人現在還 不知道但他其實2月的時候 就出來囉然後2月的時候我就有看到 他在做Alpha測試但那時候 當然就是我是一個無名小卒他 也不會拿來給我測試我也用不到 但那時候我就已經知道有這個東西而且
(33:00~34:00) 我有看過一些Demo真的 非常非常非常屌然後再來 的就是他們3月的時候出了GPT 4嘛然後再來呢 就是上禮拜他們推出的Dolly 3好接下來我們來講一下 Dolly 3這個模型我覺得很有趣喔 這是一個我會想要用的模型 這個模型呢跟Dolly 2 有點類似一樣是你輸入文字 然後產生圖片但他有三個 特點第一是他對於細節的 了解非常強你可以在 你的文字裡面輸入非常非常細節 的文字他全部都可以理解 然後畫出來第二他 畫的出文字文字一直以來都是 繪圖AI很大的一個弱點但他可以 畫的出來第三他是直接 跟ChatGPT綁在一起 出來意思就是說他不會單獨 作為一個模型釋出他是 會變成ChatGPT的一個外掛 程式釋出意思就是說 你要用這個模型你必須透過ChatGPT 來用這個模型透過ChatGPT 來問他問題我們來簡單評論 一下這三個特點首先第一個 他對於細節的了解非常 強大家可以去他的官網看他
(34:00~35:00) 每一個展示出來的圖片他背後的 那個Prompt就是他輸入的那個文字 都非常非常細節 然後那個圖片中確實也把每一個細節 全部都畫出來了超扯 我給大家舉個例子他有一張圖片 他的那個Prompt是這樣 我直接把它翻成中文了 說了大自然多樣化之美和數學 陰謀的精髓 這麼長的一串文字 就是在形容這張圖片然後他 畫出來那張圖片我覺得真的有 喔好啦其實我不是很清楚什麼是 墨比烏斯黛但你可以自己去查一下 反正他所有的細節他 都可以全部畫出而且畫 的非常好再來這個AI Dolly3他也寫得出文字 他可以在圖片中呈現出
(35:00~36:00) 讀得懂的正常的文字文 字這個問題對於繪圖AI來說困難 是因為他真的太多變了他的 Pattern太多種了這個AI很難 從他的訓練資料中把文字 的知識給Generalize那這邊Dolly3 呢他是有展示出一些圖片 呢上面是有寫著非常 完美的文字但說真的我覺得 這個feature應該不會有大家想像 的那麼好因為最近有一間 新創公司也是爆紅我這個在我的 IG前幾天我有講過這間公司 叫做Idiogram那這個Idiogram 他也是一個Focus在做 這個繪圖AI的公司然後 他們Focus的方向是Focus在 能夠了解文字的繪圖AI 能夠畫出文字的繪圖AI 然後我自己去試玩一下我發現 你如果輸入一些比較常見在圖像中 比較常見的單字或是片語 確實他可以畫得很不錯 就像是你要他產生一個Wanted 的字樣那他可以畫得出來 可以畫得非常好因為他已經看過 很多這種通緝令的海報下面 就寫著Wanted他知道Wanted應該長什麼樣 但你如果要他畫一個是 他訓練資料集中不可能有資料
(36:00~37:00) 上面有完整字樣的這種單字 比如說我叫他畫 TechWave Tech.Wave 那就是我們這個科技浪的 英文名稱他完全畫不出來 完全沒有辦法但是你要他 畫Tech他是畫得出來的 所以說他理解文字的方式一樣 還是以一個繪圖AI的角度 去理解他並沒有真正 像我們人類一樣理解這些 字母然後他拼出來的意思 他就是把那個文字當作 圖片在理解這樣啊所以我猜這個 這個Dolly3他應該也是沒有辦法 畫這個TechWave出來的 我們就等下個月測試了看一下吧 喔對了就是你如果有買 Try GPT Plus的話像是我有買 你10月的時候你就可以測試Dolly3 你沒有買的話你可能就還要 再等一下這樣別忘了OpenAI現在是 CloseAI他們要賺錢好不好 我覺得他們這樣賺錢並不是說沒有道理啦 我幾分鐘前也有講嘛 他們這麼做是為了做更大的 產品出來就是Sam Almond也有 他的原因啦但他們這樣究竟有沒有 違背他們一開始創立OpenAI的初衷 然後這樣做究竟
(37:00~38:00) 對於人類的總體利益來說 是好還是壞我覺得是一個很深 的話題我今天就先不要討論 再來Dolly3的最後一個特點 就是他直接跟Chap GPT做 在一起你要用Dolly3 你就得透過Chap GPT來使用 而你的使用場景會是這樣 你想要做什麼圖片的時候 你就把那個簡單的idea跟Chap GPT 說然後Chap GPT會自己 幫你產生幾個非常 非常細節的prompt 然後用那些細節的prompt去prompt 那個Dolly3然後你不滿意的話 你就自己在你再跟他說哪裡要 修改然後Chap GPT一樣他會 自己幫你寫prompt然後prompt 那個Chap GPT3Dolly3 這點很有趣喔就是 欸他不讓你自己寫prompt 我看到這件事情我的第一個想法是 這個方向我喜歡這個方向 是指什麼方向呢我們把prompt Engineering交給AI來 做promptEngineering就是這個 中文應該叫做提示工程 但我覺得講中文應該沒有人會知道 就是promptEngineering 這個專業在研究的就是
(38:00~39:00) 我們究竟要怎麼樣寫 prompt給AI才可以得到 最好的結果啊我想起來 有些人可能會說是永暢師 是不是AI永暢師 那這個promptEngineering呢算是 這個2023年新產生的一種 專業一種能力因為 2023年的這一波生成是AI 這些非常大型的語言模型 跟繪圖模型呢他們的潛力 真的是無窮無盡的 然後你如果沒有一個很好的prompt 很好的提示文你很難 把他們的潛力發揮出來 甚至有些公司在招什麼promptEngineering 就是專門在想怎麼寫 更好的prompt的然後在那邊 年薪隨便就幾千萬然後有一些 主流媒體就是也就跟著報導說 哇你看AI的新職業 叫做promptEngineering每個人 都可以賺年薪破千萬喔 那我一直以來我其實我都沒有 很看好promptEngineering這種專業 ok我了解就是 我也認同就是你如果可以寫出 更好的prompt你確實可以得到 更好的結果這些AI真的是 太大了然後他們的潛力真的是太
(39:00~40:00) 強了有太多寶藏可以挖了 但是有幾個問題第一個 每一個模型prompt的方式都 不一樣你同樣一個prompt你在 不同模型上就會有不一樣的效果 而且就算在同一個模型上 你使用這個promptok 當這個這模型train出下一版 的時候用新的資料tune過了之後 你這個同樣一個prompt可能就失效了 所以promptEngineering是有一點 non-transferable的技能再來 我們有看到一個趨勢就是說越來 越多人讓AI做promptEngineering 就是chatGPT這個舉動不是 新的喔一直以來都有一大堆 人用chatGPT去幫他們 寫mid-journey的prompt再來 前一陣子有些人發現說 你在這就是叫chatGPT解 一些邏輯問題的時候你在你的 prompt最後面加上一句話說 Let's think step by step 就是我們一步一步來 這樣子chatGPT的表現會比你不打這一行 更好而且好非常多 但我前一陣子在這個Google 的一篇論文他們是最近發的一篇論文 叫做large language models as optimizers
(40:00~41:00) 它裡面就有發現說Let's think step by step 很不錯但它不是最讚的 就是你如果打說 在每個模型上是有不一樣的 比如說你在POM2模型上你就必須 要打說Take a deep breath and work on this and work on this problem step by step 就是深吸一口氣然後我們 一步一步來它這樣子的表現 會比Let's think step by step還更好 那他們是怎麼找到就是說 還要講說Take a deep breath Google是用LLM 自己去找到這件事情意思就是說 他們用AI找出 怎麼樣寫這個prompt 可以得到最好的結果意思 就是說用AI做prompt engineering 的意思啦就是比起我們人類 自己去不斷的試措試各種 方式直接讓AI找出最好的方式 然後這些東西說真的 都不是人類可以想得到的 你怎麼想得到要Take a deep breath 你要叫GPT take a deep breath幹嘛 你想不到嘛你怎麼可能想得到 然後甚至像是GPT4喔 它發現AI發現在 GPT4的這個prompt裡面打說 Let's combine our numerical
(41:00~42:00) command and think clearly and quickly and accurately decipher the answer你怎麼可能想得到這串文字 所以說prompt engineering已經 變成是一個太複雜的專業 而且這件事情是可以用AI 來做的那為什麼人類要去學 應該說啦就在這個時代我們 學一點是不錯我們學會 怎麼樣跟自己的AI助手溝通 是最好是OK的但你要 知道這個技能啊prompt engineering 這個技能它並不是長期 可以帶給你價值的一個技能 所以我覺得他們OpenAI直接把 Dolly3做在ChadGPT當中 是非常好的因為Dolly3 這種需要非常非常 細緻的prompt才可以激發潛力的AI 真的就只能靠AI來prompt 好那我會把這個Dolly3 它的官網呢也放在 ShowNote大家可以自己去看一下 好啦那今天OpenAI的內容就先聊到這邊 說真的啦其實OpenAI還是有挺多 其他可以聊的內容 比如說我覺得OpenAI裡面的每一個人 都很有趣像是Sam Almond Sam Almond就是一個很屌的人啊 他不只是這個OpenAI的CEO
(42:00~43:00) 他以前還在YC幹過我忘記他 在YC是做什麼啦就是 YC就是一個創投在美國 非常非常有名的一個創投 全名叫做White Combinator 所以說這個Sam Almond他有很強的投資背景 然後呢區塊鏈加密貨幣 他也有參與卡他是個World Coin Project的創始人嘛 那我知道他自己在這個BioTech這部分的投資 他也是非常的活躍 所以他真的是挺斜槓的一個人 而且聽他講話就知道這個人 很聰明很厲害 但同時臣服也很深 我覺得他真的臣服很深啊 但是聽他講話我就覺得這個人 感覺有點心機很重的感覺 我也不知道為什麼我覺得他太從容了 他真的太從容了他回答什麼困難的問題 都是感覺很從容的很有自信的 好像他已經準備過一百萬遍了 在那邊 Of course well I've thought about this It's A B and C 這麼從容啊我覺得就是 感覺有點刻意從容啊 我不知道 我知道我現在聽起來像是陰謀論者 當然這部分基本上是陰謀論
(43:00~44:00) 但這就是我自己的個人感受 然後除了Sam Omen以外 其他人也都是大有來頭喔 有超強的Andre Caparti 他是我的偶像 他是我覺得是世界上所有工程師排名 他可能是前十的那種程度 他一開始就是從OpenAI創辦的時候 他就待在那邊 但後來他被挖去Tesla做AI Lead 然後後來他跟馬斯克做累了之後 他又跑回來 他現在在OpenAI 然後還有Elia Suskiver 我忘記在哪一集了 反正我前面有一集有講到 AlexNet那一集 他就是AlexNet團隊的其中一個人 也是非常非常厲害的AI Researcher 然後除了人以外還有很多 像是在AI Safety這邊 OpenAI也做了很多事情 AI Education是最近他們非常Focus的一點 然後還有AI Detection 其實他們做得蠻爛的一點 這些東西我們都沒有辦法在一集裡面討論完 所以說這就買個伏筆 在未來的集數你也會聽到 偶爾會討論OpenAI這間公司 好那這集的Q&A section也先暫停一次
(44:00~45:00) 主要是因為 第一個就是我沒有收到非常多的問題 我非常非常喜歡大家的留言 我看到我真的是 大部分的留言我看到我立刻就是心花怒放 非常的開心 這個就是我現在做下去的動力你知道嗎 因為我這個節目我才剛要開始盈利 我們今天才剛接到第一則業配 在這之前都沒有賺錢的 那這段期間真的督促我 可以持續做下去的真的就是 各位的留言 因為我知道我的節目真的有幫助到別人 但是這個每一集後面的留言Q&A 這邊我還在規劃我在想 我要怎麼做會比較好 包括怎麼挑留言然後哪一集 後面要放哪一集後面不放 因為說真的我覺得前幾集 這個Q&A section我沒有做得非常好 我看那個Retention 蠻多都是從這個Q&A這邊 就有些人就會跑掉了這樣 那這邊我還在規劃大家敬請期待 然後我逐字稿要怎麼利用 那這樣大家也是敬請期待 或是有什麼好的想法也可以在底下留言跟我說 那最後一樣呼籲下大家 喜歡的話請幫我五星評分留言
(45:00~45:08) 然後把我的節目分享給你的好朋友們 科技浪節目都是免費的 你的分享就是你支持這個節目的方式 好那這集先聊到這邊
