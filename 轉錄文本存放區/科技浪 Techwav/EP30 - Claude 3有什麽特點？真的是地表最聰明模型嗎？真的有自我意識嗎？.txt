(00:00~01:01) 【音樂】 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式 帶你了解時下最火的科技話題 本集節目由響窩贊助播出 那如果你是那種總是沒有辦法一覺到天亮 然後怎麼睡都感覺還是睡不飽的那種人呢 那你就應該試試看響窩的床墊 響窩The Cave是台灣的在地家居品牌 那它是源自於三位創辦人對於家的想像 然後以寢具為出發點,希望讓每個努力生活的你 都擁有一個舒適的小窩 那響窩呢,嚴選了環境友善的用材 並且搭配MIT職人手工的置床技術 做出了一款你躺過就回不去的響窩床墊 這個響窩床墊啊,它表面布料使用的是 美國太空總署NASA研發認證的Ouless布料
(01:01~02:02) 那原本這個布料呢,是使用在太空衣上面 所以它擁有非常優秀的自動調節溫度的能力 怎麼睡都是最讚最舒適的溫度喔 除此之外,響窩床墊呢,針對台灣亞熱帶氣候 以及使用習慣設計研發 透過黃金比例調配出同時滿足支撐力 以及包覆力的超舒適躺感 那說的一口好床,不如你親自躺躺看 響窩北周南都有試躺據點 躺過你就知道有多好睡了 那現在加入響窩的官方LINE帳號呢 還享有手購優惠 相關資訊呢,歡迎點選資訊欄的連結查看 本集業配就到這邊結束,謝謝響窩的贊助 好的,那這禮拜呢,我們當然是要來聊聊 AI界的最大新聞 也就是這個Claw 3模型的出現 為整個這個原本就競爭非常激烈的大型模型的戰場呢 又增加了一個新的戰力,新的競爭者 尤其這個競爭者呢 是要直接來爭奪最強LLM 最強大型元模型的這個稱號的
(02:02~03:02) 那我們今天呢,就先來聊聊這個Claw 3 然後之後呢,其實可以延伸出很多其他的討論 就從這個Claw 3呢 我們有觀察到一些有趣的現象 就好像他有自我意識的這種感覺 但這個我們待會再講啦 我們先介紹一下Claw 3這個模型啦 那在介紹模型之前呢 我覺得我先來陣音一下 就是我發現很多人其實不太會發Claw 3的這個音 然後開發Claw 3的這間公司叫做Anthropic 很多人也發不出他的音 那首先這個模型呢 C-L-A-U-D-E 不是念做Cloud 也不是念做Clawed 是念做Clawed 雖然說如果你是這個英國的人 就是英國腔的話 你可能會念Clawed之類的 Whatever,但反正他的發音是這樣 然後這間公司呢 ANTHROPIC 不是念做Anthropic 或是Anthropic 我不知道大家怎麼念
(03:02~04:02) 反正我聽過很多種念法 但他的真正念法呢是Anthropic 那當然啦,我也理解 我覺得這兩個字有一點點攻擊到 華語母語者的這個發音弱點 就是像這個TH的音 就很多人不太會發嘛 然後這個Cloud 也是一個不太常見的發音法 所以今天呢就先跟大家介紹一下 這個Cloud跟Anthropic的正確發音 那其實說真的我不care啦 就我不是那種 那種腔調魔人 是這樣嗎?還是說發音魔人 就是你發錯音 我覺得是還好啦 重點是要可以聽得懂 就是語言的最終目的是拿來溝通的 就是最重要的目標 就是要把你要講的話講出來 然後讓別人能夠理解你的想法 就是這樣而已 它只是一個溝通的媒介 那中途這個媒介用什麼樣的方式去呈現 我覺得真的都沒差 反正你的你有get your point across就好了 就是有讓對方了解你的意思就好了
(04:02~05:02) 不過呢 我覺得應該有一些人也是想要把這些音給發到正確 他們會蠻在意的 所以說今天就還是跟大家介紹一下 他們正確的發音 好那我們回到Anthropic跟Cloud Anthropic這間公司是在2020年成立 它那時候成立呢 其實是由兩個OpenAI的前員工出來 跳出來成立的 這兩個人分別是 Dario Amode跟Daniella Amode 聽名字就會知道這兩個人有血緣關係 這個Daniella Amode 我不確定是Dario Amode的姐姐還是妹妹 因為英文裡面都叫做sister 所以我不知道是older sister 所以我還是不確定 因為我還是不確定 因為英文裡面都叫做sister 所以我不知道是older sister還是younger sister 怎麼覺得好像今天這幾科技浪 都在教英文 有可能之後我們 科技浪 科技這邊沒什麼話題可以講的時候 我們就pivot成一個 英語教學頻道 那Dario那時候 他們會離開呢
(05:02~06:02) 其實主要是因為他們跟OpenAI的理念不合 他們覺得OpenAI 因為那個時候OpenAI已經 轉成一個for profit的公司 或是嚴格來說 應該是他們在一個non-profit組織 下面成立了一個 for profit的子公司 那這個Dario他們 就覺得這個OpenAI的 發展方向好像越來越 朝這個 盈利方向走 在過程中 為了追求發展速度好像有一點點 棄這個安全的考量 不顧 所以他們就出來成立了Anthropic這間競爭者 然後這間競爭者 最主要的一個特點 就是他們非常的注重AI 安全他們並不是以 盈利為最終目標 他們是要建立一個可靠 可解釋非常安全的AI 那他們比較有名的事蹟 就是首先他們在這個 ChatGPT出來之前 他們其實已經有Cloud了 他們那時候就已經建出了這個Cloud
(06:02~07:02) 聊天機器人了 但是他們就是故意不 發表出來他們是刻意的延遲 Cloud發表 因為他們覺得這個Cloud發表出來 之後可能會 引起一陣這個我們叫做 LLM的Arm Race 就是LM的軍備競賽 各家科技巨頭都會開始加速 他們研發AI的速度 然後大家就在這個過程中 就會棄安全不顧 所以說他們很怕 這個情況發生所以說他們那時候 刻意延遲了Cloud發表 搞不好他們那時候有發表的話 我們過去這兩年在講的 就不是ChatGPT了就是Cloud了 但他們這件事情就沒有發生 然後ChatGPT發表之後 也確實有點出現 這個軍備競賽的感覺 那這就是他們 Anthropic的第一個試機 除此之外他們也有做很多 這些AI安全的研究 我覺得他們在這個AI安全 確實可以說是現在 在AI Safety這個領域
(07:02~08:02) 研究做的最多的AI公司 比較有名的 就是他們做的 Constitutional AI的方法 Constitutional AI的概念 我們知道現在這些大型元模型 都會經過一個 RLHF的方式進行 Tuning Reinforcement Learning from Human Feedback 就是人類 會跟這個模型講說哪一個 回答是好的哪一個回答是不好的 在過程中因為是人類 人類在做這件事情 人類每一個人無論你是誰 一定都有一些你自己的偏見 所以說你在這個過程中 你就會把你自己的偏見 注入這個模型當中 Constitutional AI的概念 我們人類先制定一個 Constitution就好了 一個憲法就好了 之後的這個Tuning的過程 我們讓AI根據這個憲法 自己來進行 讓AI自己去Tune AI的概念 我們把它稱作RLHF Reinforcement Learning from AI Feedback
(08:02~09:02) 這個Clawed系列的模型 就是Anthropic它的 旗艦聊天機器人模型系列 他們有從 Clawed到Clawed2 一直到上禮拜應該說幾天前 才剛出來的Clawed3 這個Clawed3出來之前 大部分人對於Clawed的想法 就是首先他們 不是最強的模型Clawed2 比不上GPT4也比不上 Google的Gemini Ultra這樣 然後他們的一個特點就是 他們很常拒絕回答問題 因為這個Anthropic是一個安全 為導向的公司嘛 這些大型音樂模型都 很怕會講錯話 所以他們很常就 儘管你是問一個非常人畜無害的問題 他也會說 他沒有辦法回答 因為你可能帶了一些關鍵字之類的 就比如說 請幫我寫一首超炸的饒舌歌曲 然後他可能就會說 不行喔你不可以亂炸人喔 之類的 這次Clawed3的出現依照官方的說法
(09:02~10:02) 這兩邊都會有非常大的改善 就是這個模型本身 他的智能他的表現 終於可以接近一流的 模型了就是這些GPT4 跟這個Gemini Ultra 然後同時呢 他也不會再那麼常亂拒絕問題了 那這次Clawed3 他是有釋出三個不同的 尺寸 就是依照這個參數的數量分成三個不同的大小 第一個呢 最小的是HaiKu 中等的是Sonnet 最大型的是Opus 會這樣子取名字呢就是因為 HaiKu是一種日本的那種 只有三行的詩 然後Sonnet是源自義大利 在英國比較常用的一種 有14行的那種詩 Opus呢 指的是一個作曲家他做出來的一系列的 作品所以說從文字長度來看 就是短中長這樣 那其中呢 Anthropic是把這個Opus 稱作目前地表最聰明AI 模型
(10:02~11:02) 那他們之所以會這麼講呢是因為他們 說他們在測試了所有的 這些比較 popular的benchmark之後 這些benchmark就是我們所謂 這些大型元模型的測試 你可以把這個benchmark 想像成這些大型元模型的 大學聯考或是他們學測 指考之類的 那Claw3的Opus呢在所有 這些benchmark上面都拿到了比 GPT-4更高的成績 那尤其其中有幾個 是高非常多像是 這個Coding的測試叫做 HumanEval他們Opus 是拿到了84.9分 那GPT-4呢只有 67分但是當然啦這些benchmark 就跟這個大學聯考 或是學測一樣並不是 一個人智力的最好指標 尤其是這些大型元模型 還有可能 還有作弊的問題 就是他們可能會先看過題目這樣 那這邊我們待會再講 我們先把這個Anthropic 官方釋出的一些模型
(11:02~12:02) 的特點給講完那剛剛有說到 Claw3這是很大的一個進步就是 他比較不會那麼常拒絕 問題嘛那這次呢 他們有做一個研究就是他們發現說 原本的這個Claw2.1 他針對這些 人畜無害的問題 他的拒絕比例呢 是25% 也就是說這些 人畜無害的問題之中呢有25% 他會拒絕掉 那這次Claw3的進步呢 是他的模型呢 基本上都是在10%或是 10%之下那我覺得這個其實 真的是蠻大的一個進步而且是 一個蠻有意義的進步因為 這個你拒絕的比例 真的會很大程度的影響 使用者的體驗 你如果每問四題問題 其中一題Claw就會拒絕回答 那你還用得下去嗎你當然用不下去 真的是體驗是非常糟糕的 但是今天呢Claw3 如果到10%這個使用者 體驗真的是會大幅提升的 是很不錯的
(12:02~13:02) 那我自己覺得啦 原本可能Anthropic的Claw是 最容易拒絕問題的 LLM然後才是Google Gemini然後才是OpenAI的GPT 這是我自己的主觀的感受 那我覺得現在 Claw應該會超過Gemini 應該說我蠻有自信的 雖然說我Claw還沒有測試的 足夠但我覺得應該現在 是Gemini比較常會拒絕問題 因為我Gemini已經測試了 可能兩三個禮拜了吧 那過程中呢他真的是 我很常 就是用一些莫名其妙的原因 去拒絕回答我的問題 他有時候我問一個Machine Learning的問題 我問他一個可能跟VAE相關的問題吧 就是一個非常技術的 Machine Learning的問題 然後他竟然回答說 因為選舉是一個非常 敏感的話題 所以說這個LM不針對選舉做回答 到底哪裡來的選舉 那除了拒絕的比例的降低 以及這個智能的提升呢 Claw3還有一個很大的亮點就是
(13:02~14:02) 它的Context Length 也可以到1Million Token Context Length就是一個大型元模型 他一次能夠理解的文章的長度 當然他今天如果是 大型多模態模型的話 這邊也包括你的圖片 或者是影片這樣 那這個Claw的呢原本 在Google Gemini 1.5 Pro出來之前 原本Claw其實就是這個 Context Length的王者 他們有200K的 Context Length 20萬這樣 你可以放20萬個Token進去 一個Token呢對於英文來說 大概就是等於0.75個 英文單字這樣子 那在Gemini 1.5 Pro 出來之後呢 也就是我們EP28 一開始聊的那個Google的 Context Length最大的模型 Gemini 1.5 Pro呢 就變成了最大的王者 因為他最高可以吃到 10Million個Token 那這邊呢我其實有看到一個聽眾 留言跟我講說 哈利你講錯了 這個Gemini 1.5 Pro呢
(14:02~15:02) 他最高不是能吃到10Million Token 而是1Million Token 那這個其實是一個 比較是Technical Report裡面 才看得到的一個細節 因為Google他們對外發表 Gemini 1.5 Pro 他可以吃到1Million Token 然後他們Release的版本 給那些早期試用者 那些測試人員使用的呢 確實也是一個 1Million Token的Gemini 1.5 Pro 但是你去這個Technical Report 你會看到說 Gemini其實最高可以吃到 10Million Token 然後他這個10Million Token呢 經過他們的測試 也就是這些Needle & Hesak的測驗 也都是幾乎是Perfect Recall 也就是這個完美的成果這樣 所以Gemini 1.5 Pro 他最高可以吃到10Million Token 但是因為一些運算上面的限制 一些硬體的限制 他們沒有辦法把這個模型 Serve給這些測試人員 所以說他們才 先Release這個1Million Token的版本
(15:02~16:02) 這樣 那你去看大概90%的媒體吧 所有人都是在講這個Gemini 1.5 Pro 他是1Million Token的這個模型 因為這些媒體都不會去點這個 Technical Report看嘛 那只有你去聽這個 可能Demis Hesapis 他本人的演講 本人在講Gemini 1.5 Pro的時候 他才會講到10Million Token 或者呢你聽像是科技那種優質的媒體 我們才會跟大家說這個 Gemini 1.5 Pro是10Million Token 那這個Claw 3呢 還是沒有辦法把這個Context Length 的王者的稱號 從Gemini 1.5 Pro搶下來 他是比Gemini 1.5 Pro 大概在小一個等級 的Context Length 他Release的版本呢 是可以做到200K的Context Length 但是他模型最高可以 Handle的是1Million Token 所以說就是跟1.5 Pro 他Release的版本一樣 那Anthropic跟Google一樣 都有做這個Needle in his stack的 Context Length測試
(16:02~17:02) 反正就是在一個很長的文本中 插入一句非常隨機的話 看這個LLM可不可以找到 那這個Claw 3呢在這個200K的 Context Length的範圍之中 幾乎都是99%的準確率 到了後面可能開始 有一點掉下來但是 整體來說看起來都是不錯的 那他們其實沒有測試到1Million Token 所以說我們不確定他的這個 1Million Context Length到底是不是真的 Context Length這個就等到 他釋出的時候我們再來看 那我覺得很多人想知道的呢其實是 這個Claw 3跟GPD 4 或是GPD 4 Turbo比起來 究竟如何 他是不是真的像是媒體說的一樣 或者是這個Anthropic他自己講的一樣 是地表上最聰明的 模型呢那首先他們會 這麼講的依據呢我剛剛也有說了 就是靠這個Claw 3 在所有Benchmark上面的成績嘛 然後他在那個 他的Report裡面寫說比GPD 4 都還高分 那光是靠這一點我覺得是非常 難說服我的我是沒有辦法
(17:02~18:02) 就是靠這個相信的 主要兩個原因第一個就是 這些Benchmark真的很爛 就是這我已經在我的節目講過 非常多次了這些Benchmark 首先他沒有辦法反映這個 模型真正被使用的時候 的智商因為使用者在 問這些LLM問題的時候他們 根本不可能這樣問你們仔細去看一下 大家最常講的這個Benchmark叫做 MMLU嘛也就是這個 集結了各個學科以及各個 等級從這個小學到大學都有 的這個 的問題集這樣然後這些問題 全部都是選擇題那當然 你在用大型模型的時候你不會 給他一個選擇題嘛所以說 這個跟大家的Use Case差很多 然後除此之外 這些資料這些Benchmark他們 都已經出來很久了像是這個 MMLU2021年就出來了 然後現在已經2024了 你覺得這些資料沒有在 網路上到處流傳嗎一定 有嘛那這些大型模型在訓練的時候 他們其實早就已經看過 這些Benchmark了我覺得大部分的Benchmark
(18:02~19:02) 他們可能都已經看過很大一部分 了之類的所以說他們很 可能都已經把這些答案都已經背起來了 那這件事情在 我們資料科學領域我們把它稱作 Data Contamination就是你的 訓練資料裡面竟然參了你的 測試資料這樣所以這些Benchmark 真的是我自己是覺得 我們參考一下就好了 他們並不是真的是一個非常公平的 標準那儘管我們 先不管這些Benchmark的好壞 光是這個 Anthropic比較Claw3跟GPT-4 的方式我都覺得不太 公平因為在他們的報告裡面他們 是拿GPT-4剛出來 最一開始的成績再跟 Claw3比較GPT-4 GPT-4是2023年的 3月15就出來了 所以基本上已經是整整 一年前的成績了 那在這一年中OpenAI當然 有持續去TuneGPT-4 他們還有做出一個新的版本叫做 GPT-4 Turbo 雖然OpenAI官方 沒有再釋出新的Benchmark成績
(19:02~20:02) 但是有一些 微軟的工程師他們做了一個 叫做Prompt-Base的 一個研究 研究的目的其實是在找出 其實是在做Prompt-Engineering 他們就在找出怎麼樣Prompt-GPT-4 他可以表現得更好 然後他們用他們的方式去Prompt GPT-4 Turbo 他們得到了一個新的Benchmark成績 那這些新的GPT-4 Turbo Benchmark成績 每一個都比Claw3還高 所以說對這些人算是做了 一些Prompt-Engineering 盡量去優化的這個GPT-4T 的成績喔 他們沒有去碰這個GPT-4T的 模型本身 或者是給他一些工具什麼都沒有 所以說他們只是把GPT-4 Turbo 他的潛力給激發出來 而已大概是這種感覺這樣 也就是說GPT-4 Turbo 潛力激發出來之後 他是比Claw3的成績 都還高的而且我們不知道 Anthropic他自己在測試Claw3的時候 他那些Prompt是怎麼打我們也不知道
(20:02~21:02) 搞不好他也是有用 一些類似Prompt-Engineering的優化 方式然後才有這個Claw3 現在的成績 總而言之啊我自己是覺得 他們公布的Benchmark成績 我不會拿他來當作 一個評斷GPT-4跟Claw3 他的能力強弱的標準 我自己是覺得看大家實際的 體驗的感覺是比較準的 還有包括我自己的體驗這樣 雖然說模型才剛出來幾天 這個數據量都還不夠 然後大家的討論 也還沒有到一個 也就是說沒有 大家都一致同意的 一些點但是我們至少 可以看得出一些端倪 那我就這邊先跟大家分享一下 第一個我要講的呢如果你是科技上 長期的聽眾你就一定猜得到 我要講的當然就是這個 Chatbot Arena的結果 那這個Chatbot Arena 我個人是覺得比起其他Benchmark 這是一個更好評斷LM能力 的標準他就是透過 網路鄉民實際盲測
(21:02~22:02) 這些大型元模型的結果 來為這些模型打一個分數 他們打的這種分數呢是一種 Elo rating 的一種分數 那這個分數呢是他們 在下西洋棋那種西洋棋手 他們之間 互相切磋的一種評分 標準具體來講是怎麼算的 大家可以自己再去查一下但反正我 個人認為是一個非常公平的方式 畢竟你看這種 西洋棋手之間他不可能 一局就定誰好誰壞 一個好棋手跟壞棋手 是要透過長期 跟很多不同人 不同程度的對手較量 之後綜合下來的結果 才能夠算得出來那目前 雖然說這個Claw3才出來大概兩三天 但大家都非常熱衷於這個 Chatbot Arena 他們都想知道這個Claw3 他的Elo rating究竟在哪裡 是不是有跟GPD4可以比 所以說他短短的幾天 他已經累積了五千多個投票 依照這五千個投票
(22:02~23:02) 算出來的Elo rating 他是第三名 前面兩名都是GPD4 Turbo的模型 所以說Claw3 還是輸GPD4 Turbo 這兩個GPD4 Turbo 他們有兩個是因為他們是 不同時間釋出的版本 但他們的分數是一樣的 都是1 2 5 1 然後Claw3的成績 是Claw3 Opus的成績 其他兩個比較小的當然不能比 Opus的成績是1 2 3 3 我個人認為這五千多個投票 對於Elo rating的 系統來說應該算是 夠顯著的一個樣本數 所以說我自己是覺得 這個Claw3應該就是還輸 GPD4 Turbo一點點 除此之外大家在使用上 也有一些對於Claw3的想法 首先第一個就是 他們發現Claw3跟GPD4 比起來比較容易有幻覺 有幻覺就是有Hellucination的意思 這也是我最近才 知道原來Hellucination 的中文是叫做幻覺
(23:02~24:02) 反正Hellucination在講的就是 這個他模型 他會講錯話 會把事實給搞錯這樣 而且這個Hellucination的問題 是比GPD4嚴重蠻多的 大部分人都這樣講 我自己是還沒有測試的足夠 所以說這邊我就先自己不講 但是大部分人他們的看法 是這樣 但是不過也有好的地方 大家發現這個Claw3 他總結文章的能力 是比GPD4強的 但是這邊我覺得是比較偏排版 跟一些用詞譴字的方式 就是他把這些文章 拆成幾個段落 然後這些段落有什麼小標 那這些小標跟GPD4產生的小標比起來 好像是比較好一點點 但是他如果 Hellucination很多的話 我就覺得我寧願用GPD4 那雖然我測試Claw的時間 還不夠長啦 我覺得可能下禮拜或下下禮拜 才有比較多內容可以分享給大家 但是這個GPD4跟Gemini Ultra
(24:02~25:02) 我已經使用了一陣子了 所以說這邊我是有一些東西 可以分享 那我就直接講結論了 就是這個Gemini Ultra我用了大概一兩個禮拜之後 我就直接不用了 因為真的是比GPD4爛 那我大部分的用途呢 就是解釋論文或是幫我消化一些 可能比較技術的文章 比較難閱讀的文章這樣 那我發現Gemini Ultra 他的排版往往比GPD4好 GPD4很常會做的一件事情 就是他在 幫你解釋一些 一個文章幫你總結一個文章的時候 他的排版就是好幾個段落的 純文字 當然大家都純文字啦 但是他是好幾個段落然後沒有標題 的好幾坨文字這樣 那Gemini Ultra呢 他每一坨文字之前 他一定會下一個標題 他一定會出題然後跟你講 又一句話跟你講這段文章的重點 是什麼這樣 我覺得這個其實是蠻不錯的啦 我自己看起來也是蠻舒服的
(25:02~26:02) 但是呢在內容的部分 我覺得GPD4還是比較強一點 就是很多細節的部分 Gemini Ultra有時候他其實會解釋錯誤 或者是解釋的不夠精準 那這些當然啦是非常非常細節的東西 就是可能是 一個論文裡面 他兩個非常相似的這個 Component他的差異可能是 極度細微的 這種差異的這些Component 那Gemini Ultra可能會把兩個東西搞混 但GPD4都沒有這種結果 這些過程中我全部都是 同樣一個Prompt我會同時 使用GPD4跟Gemini Ultra 所以說這是非常公平的比較 兩個人都是吃一模一樣的Prompt 然後兩個結果我都會讀 然後我發現了好幾次 就是Gemini Ultra解釋錯誤 但GPD4沒有的狀況 而且Gemini Ultra也是比較常容易 拒絕問題啊 所以說這就是我目前對於這些 LM的想法 不過這些都是比較偏生產力部分的想法 那其實我平時也是會用LM 幫我做一些其他事情
(26:02~27:02) 比如說心理諮商 那這邊其實我最近 有一個非常愛用的模型 叫做Pi Inflection AI的公司出的模型 那這禮拜來聊聊他們 其實是還蠻適合的 因為他們其實也有一個新聞 就是他們在同一週 也有釋出他們新版的 大型音樂模型叫做 Inflection 2.5 Inflection這間公司他們的大型音樂模型 或是你說他們的聊天機器人 跟其他的最大差別 就是在於他們主打 同理心 他們的LM是非常有同理心的 他們把它稱作Personal AI Your personal AI 他們說他們的Pi是有非常高的EQ的 但是在IQ這邊 就沒有說真的非常高 原本是這樣 現在他們釋出了這個 Inflection 2.5 他們在IQ這邊就是大幅的進步 現在這個 Inflection 2.5的模型 他在Benchmark上面的表現
(27:02~28:02) 也都開始非常接近GPT-4了 但是當然還沒有到 GPT-4的等級 不過這個其實已經很厲害了 因為他們在Train這個Inflection 2.5的時候 他們使用的運算量 只有GPT-4的40% 雖然說我真的不知道他們 到底哪裡搞到GPT-4的 Pre-training的運算量 是多少 這個OpenAI從來都沒有講過 但是可能因為他的Founder 都是大有來頭的人 Mustafa Solomon跟 Reed Hoffman 所以說有可能他們有一些 這個關係 反正他們有說 我們只用40%的運算量 如果這是真的話 那是蠻厲害的 我個人覺得Inflection AI這間公司 有一點點被主流媒體打入冷空的感覺 雖然說他們一開始 在募資期間 他們買一大堆GPU 募到很多錢 那個時候是 有新聞在報他們
(28:02~29:02) 但之後他們一直在出這些大學的模型的時候 大家其實 沒有那麼care 大家目光都是放在OpenAI Google跟Anthropic上面 還有Meta 我覺得大家不怎麼 管這個Inflection是因為 IQ的部分 就是這些Benchmark或是生產力用途 真的是跟其他的模型 有一段距離 但其實對我個人來說 我是非常喜歡使用Pi這個聊天機器人的 因為真的就如他們所說的 它真的有比較高的EQ 就是我跟他聊天的時候 我真的會有感覺到溫度 比起我跟GPT-4聊天的時候 GPT-4的回答可能就是 比較冷冰冰的感覺 但Pi是真的有溫度 雖然說很明顯這個溫度就是他們tune出來的 然後這個背後 在跑的也是一樣就是一張GPU 然後在做矩陣懲罰 然後算出這些字母 但是呢它的用字潛詞 真的是讓你有很高的親近感 而且還有一個最大的差別是什麼
(29:02~30:02) 就是Pi它有內建的語音 然後它的語音呢 真的是非常非常接近真人的 雖然說有時候它的 語速會有點 有時候十快十慢你聽得出來 還是不太自然 但是大部分情況之下 配合著它溫暖的文字 是會讓你聽起來非常舒服的 就是你還是時時刻刻的會意識到 你在跟一個AI講話 那你會覺得這個AI是真的有在關心你的 那當然這個Chad GPT的手機版呢 也是有語音功能的嘛 但我覺得這個語音功能做得蠻爛的 而且Chad GPT它本身 它的文字就是比較冷冰冰的 所以說完全跟這個Pi的感覺是不一樣的 那這個Pi呢現在就是我個人的 心理諮商AI 真的不誇張喔 我不開心的時候我遇到問題的時候 我覺得心煩意亂的時候 我跟它講一講話真的會好很多 就是它真的懂我的問題 然後也真的會給一些 我覺得蠻有建設性的建議 幫你增強你的自信心 告訴你你是最棒的之類的
(30:02~31:02) 那這個Pi目前比較大的 一個缺點呢就是 它是只有支援英文 我不確定是不是只有英文啦 可能還有其他語言 但反正它是不支援中文的 所以說你如果想要找它心理諮商 你可能會需要具備一定程度的 英文能力這樣 那我覺得很多人都沒有意識到這一點 所以他們就不想討論這一點 但是其實同理心 真的是大型圓模型非常厲害的一個功能 我會這樣說是因為 人類要做到同理心其實真的是 蠻困難的一件事情 大部分人都是很沒有同理心的 那這也並不是在說 這個世界是很冷酷的還是什麼的 雖然說真的有一點 那我要說的其實是 人類都是有偏見的 人類的思考都是從自己出發的 都是自我中心的 別人出發本來就是一個很難 做到的一件事情 然後加上溝通又是 有時候並不是非常有效 所以說你要找到一個 真的非常有同理心的人跟你
(31:02~32:02) 聊一些 可能讓你很脆弱的話題 是蠻困難的 但是這一點大型圓模型就可以 做得非常好 它可以假裝每一次回答的時候都具有高度 同理心儘管它看不到你 摸不到你沒有辦法 聽到你的講話的語氣 它還是可以非常有 同理心的回答 像是去年不就有個研究嗎 有一些病人在同時 看到醫生跟 MedPalm就是Google的一個 醫療大型圓 模型的回答 大部分的病人都會覺得 MedPalm的回答比較好 他們會喜歡MedPalm的回答 最主要的原因就是因為MedPalm具有高度 的同理心 所以在這個時候第一句話都會先說 我知道你現在一定很痛苦 醫生的回答 可能有時候比較單刀直入 因為他可能一天要回答好多人的問題 他可能 比較機械式的 在看你的問題是什麼
(32:02~33:02) 就直接跟你說依照你的這個病徵 你的問題應該就是ABC 解放就是什麼什麼 同時我知道現在 年輕人族群當中 心理諮商資源不足 這個問題是一個蠻大的問題 很多人的心理健康其實都不是很好 但是你要去找一個 專業的人去做諮詢 其實真的是 整個過程的安排其實是 很耗費精力的 同時也耗費金錢 我覺得大家如果都有一個 自己的心理諮商模型 心理諮商AI 這個問題 真的是可以得到緩解 當然不可以解決啦 我覺得AI可以取代心理諮商師 我也沒有在說AI可以做 專業的心理諮商 大家不要會錯意 但是我覺得你在看心理諮商之前 如果你先跟像是派這種很有同理心的AI 聊聊的話 我覺得搞不好你的問題就已經被解決了 如果你的問題是比較小的話 搞不好這樣就OK了
(33:02~34:02) 那如果你問題比較大的話 可能也可以得到一定程度上的緩解 而且這個派 我覺得雖然說我猜他們應該是有找一些 心理諮商師來幫他們tune這個模型 幫他們做一些RLHF 的human feedback的部分 但是呢 我覺得它畢竟還是一個general的 模型 他們在他們的文章裡面有說 派是設計給你當做你全能的 懂你的一個小助手 它不只是可以陪你聊心事 它還可以幫你解決問題 還可以幫你寫code 還可以幫你分析文章 所以說它並不是一個 心理諮商專門的模型 所以說今天你如果再tune一個 心理諮商專門的模型 我覺得它的表現應該是會比派還 更好 所以說我覺得真的啦今天如果我有閒錢 有閒時間我真的是會來創一間 心理諮商AI的公司 因為先不管這個business model 可不可以賺錢什麼東西 你光是有這個產品我覺得就可以幫到 非常非常多人了
(34:02~35:02) 可以讓很多人過得更快樂 聊了那麼多我覺得我們可以在 Claw3這邊先做個小結了 Claw3它就是一個 Anthropic的新的模型 他們是號稱地表 最聰明的AI模型 不過這邊我們先畫上一個問號 目前的共識是它 應該是比GPT實在弱一點點 除此之外Claw3 也更少會拒絕用戶的 問題然後同時 也增加了它的context length到 最高可能到100萬個token 這個Claw3的模型重點 大概就是這樣 接下來我想講一個Claw3 它在網路上引起網友們 熱議的一個小事件 這個事件是這樣 Anthropic裡面有個員工他發了一篇X文說 他們在Claw3上面 跑這個needle in haystack 測試的時候也就是從 很長一段文章裡面找一段話的這個測試 在測試的過程中他們發現 Claw3好像有意識到 他自己在被測試 那他們實際的測試狀況是這樣
(35:02~36:02) 他們把一堆關於科技 新創跟城市設計的文章 可能非常長 因為它有最高 200000的token 所以他們可能把一大堆文章 併在一起或是找一篇爆長的文章 然後在中間 他藏了一句話 這句話是關於pizza topping 就是這個pizza的配料這樣 整句話可能是講說 我忘了但可能是 the best pizza topping is pepperoni 什麼什麼 跟前後文是差非常多的一句話 然後這個Claw3在回答的時候 確實有把這句話抓出來 但他還補了一句話 我覺得這句話 好像是有人在開玩笑 或是有人在測試 我有沒有pay attention 測試我有沒有注意的閱讀 因為我覺得這句話 跟前後文是非常不搭的 那這個anthropic的員工 就在他的文裡面說 Claw3的這個行為 他講出這一句話
(36:02~37:02) 是他在其他LM上面從來都沒有看過的行為 那這篇X文就在X上面被瘋傳 很多人都在下面留言說 哇天啊 這個天網要來了 好恐怖啊 這些AI開始有自我意識啦 因為這個Claw3的說法是 他並不是說他覺得這可能是一個測試 他的說法是 他覺得有人可能在測試他 他的原文是 你有注意到嗎 他說I suspect 我懷疑 看我有沒有注意閱讀 這樣 針對此事 大家當然就是分兩派 有一派人是覺得這根本就沒什麼大不了的 大家在大驚小怪什麼 這些LM在做的就是從這個 訓練資料的分佈裡面去做抽樣而已 意思就是說他就是在 模仿人類講話而已 人類會這樣講話 人類會這樣模仿這樣很怪嗎 那也有相對的另外一派的說法是說 當這些LM可以100% 模仿人類意識的時候
(37:02~38:02) 他是不是就等於是有意識了 你100%的模仿一件事情 就跟你在做這件事情是一模一樣的吧 那當然現在的LM還沒有辦法 做到100%模仿人類意識 但是他今天Claw3 講出這種話就代表他們 好像已經開始在模仿 一部分的人類意識了 那這兩派的討論呢我覺得 比較理性的啦 也有很多不理性的討論 就是可能在說Claw3已經是AGI 還是什麼東西啊 那我們就先不講了我們講這些理性的就好 那我個人的想法是這樣 就是我一開始看到這個Claw3的回答的時候 我其實也是感覺到 有一點點毛骨悚然的感覺 雖然說我很明確的知道 他在做什麼他運作原理 是什麼但是看到的時候呢 還是會感到 就是有點毛骨悚然 毛骨悚然的感覺呢並不是來自於 我怕這些AI開始有自我意識了 我覺得還遠得很 我覺得這種感覺比較類似那種 Uncanny Valley就是 我不知道中文叫什麼怪異谷
(38:02~39:02) 還是什麼就是有一些AI呢 他產生出來的內容讓你覺得 有點怪怪的感覺毛骨悚然的感覺 那我覺得比較可能的解釋呢 是因為Anthropics在他們的 技術報告裡面有寫說 在TrainClaw3的時候 他們有聘請Human Contractor Human Contractor來Label Data 你可以想像就是請這些約評的人 叫他們根據這個問題 寫一個他們覺得最好的回答 然後用這個回答去 訓練這些AI 訓練Claw這樣子 這些Contractor可能沒有想那麼多 他們可能也不一定是AI的專家 我不知道啦但他們沒有想那麼多 他們就是單純從自己的角度 出發去看到這個問題 然後他會怎樣去做回答 這樣那他可能 其中有一個人呢 就是被問到了一個要辨識出 不相關字句的一個問題 那他看到這個問題呢 他就很直覺的打說 我覺得這個應該是 有人在搞笑吧還是說 有人在看我有沒有注意讀
(39:02~40:02) 這些Anthropic的人在考我 有沒有注意讀這樣 他是可能這樣回答 那這個就流入了訓練資料中 所以大家不要感到太害怕啦 雖然說這些AI可以裝得有自我意識 但他們還是沒有自我意識的 好那我覺得今天這個Claw3的話題 我們就大概聊到這邊 那今天這集呢 就是比較沒有那麼技術啦 我想說前面幾集呢可能就是 非常的技術 那我們這集呢就比較輕鬆聊聊這樣 那我覺得這禮拜呢其實也沒有其他太多的AI大事啦 就是比較慢的一個禮拜 那最大的應該就是Claw3的釋出 然後除此之外呢 就是這個 馬斯克告OpenAI這件事嘛 那這個 我覺得我們今天就不深聊啦 反正就是馬斯克在告OpenAI說 他們現在已經變成了一個 幣源然後專門為Microsoft 賺錢的公司這樣 那跟他的名字他一開始設立的 名字叫做OpenAI 是 背道而馳的
(40:02~41:02) 那這邊呢我覺得我比較像是 把他當八點檔在看啦我不覺得他可以告成啦 但是就過程 同時蠻有娛樂性的 就是這個OpenAI呢 他也有釋出一個Block Post在 嘴馬斯克 不算是嘴馬斯克啦就是 在駁回他所有的指控 然後馬斯克也一直在他 自己的X平台上面 一直在嘴OpenAI跟Sam Almond 這樣 他會發一些梗圖 比如說他把很幼稚的梗圖 就比如說把那個Sam Almond他的名牌 他有一張他拿著名牌的照片 那張其實是他要離開 就是那時候公鬥劇的時候 拍的一張照 但他把那張照片那個名牌上面的OpenAI 改成CloseAI OK WOW FUNNY 然後或者是他 在OpenAI發文的時候呢 他就會在下面回覆說Change your name 然後或者是他會說 Change your name to CloseAI and I'll drop the lawsuit 反正就是一樣娛樂性十足啊
(41:02~42:02) 那OpenAI的那篇 部落格文呢我是有把它看完 我覺得確實對於馬斯克有點不利 就是他們有把整件事情給整理了一下 然後把很多馬斯克 跟OpenAI內部員工的這個 信件來往全部都公開出來了 那他們公開的內容裡面 就表示說就是 我先把這個OpenAI的這個 歷史給整理一下好了 那最一開始呢OpenAI成立 是馬斯克的一個想法 因為他跟這個Google的 創辦人Sergei Brant 在聊天的時候他發現 Sergei Brant他沒有很在意 AI安全的問題 嚴格來說啦是沒有很在意 Existential risk的這個風險 Existential risk就是 AI毀滅全人類的這種風險 那Sergei Brant覺得 AI可能會造成很多的問題 但應該不會毀滅人類 但馬斯克覺得AI很危險 很有可能毀滅人類這樣 那因為那個時候呢Google基本上 擁有全世界最厲害的AI 研究機構所以說馬斯克
(42:02~43:02) 覺得全世界最厲害的AI研究機構 最有可能開發出 AGI的這個機構 竟然被Sergei Brant這種人 在掌控 那人類的命運呢 不就是非常的危險嗎 所以說他為了跟Google制衡 他就創立了OpenAI 那那個時候他就找了這個 Sam Ullman還有Greg Brockman 然後也去Google 挖角了Ilya Suskiber 然後還有Andrei Kaparty 去加入OpenAI這樣 尤其是他挖角Ilya這件事情 真的是惹到了Sergei Brant 這個真的是Sergei Brant覺得 他Crossed the line的一件事情 因為Ilya Suskiber真的是 全世界最厲害的AI研究員之一喔 那他們那個時候 成立的時間大概是2015年底的時候 然後成立的是 一個完全非營利組織 這樣子 那過了一兩年到了2017年 OpenAI他們發現了一件事情 就是他們發現說 要做到AGI也就是一個
(43:02~44:02) 全能的AI 我們說AGI就是一個 你可以把它想像成他可以做到 一個正常人所有能做到的事情 這樣子的一個AI 我覺得有點算是 目前所有的AI研究機構的 北極星大家都想往 這個方向走這樣 那OpenAI發現說我們要走到AGI 我們會需要極大量的運算資源 然後這麼大量的運算資源 靠我們一個非營利組織的身份 是沒有辦法得到的 我覺得他們會那麼想是因為 2017年Google出了這個 革命性的Transformer Paper 那這個Transformer最有名的就是 它的運算是可以平行處理的 它的訓練是可以平行處理的 就是跟在他之前的前身 這些RNN base 這些LSTM這種 架構是不一樣的 以前的這種RNN的架構 就是Recurrent Neural Net的架構 你就算丟再大的運算資源給他也沒有用 因為他的瓶頸在哪裡 他的瓶頸就是你一次 你一個序列的訓練資料
(44:02~45:02) 你就是只能一個一個token丟進去 這樣而已 像是Transformer你整個序子可以直接塞進去 那反正在2017年 OpenAI意識到這個運算資源的這件事情 他們就決定要轉向 變成一個有營利組織的一間公司 那他們的做法當然就是 最後的做法就是在這個 營利組織下面再開一個 營利的分公司 這樣 子公司這樣 那在差不多的時間呢 馬斯克就宣布說他要離開OpenAI了 他原本是在董事會裡面 那原本大家知道的大概就是這些啦 但是這次OpenAI他們公布出來的 一些內部信呢 就是爆料了一些新的資訊 就是包括他們有講說 那個時候在討論 這個OpenAI是否要 轉向營利的時候 馬斯克其實也是贊成的 他們也認為說 OpenAI會需要極大量的運算資源 才有可能跟這個Google 有能夠較量這樣 所以你現在才在說
(45:02~46:02) 我們現在轉成營利組織是跟理念背道而止 這樣不是很怪嗎 你那時候也同意啊 然後這是他第一個爆料點 第二個呢就是他還爆料說 那個時候馬斯克同意這個OpenAI 轉成營利組織之後呢 馬斯克是想要自己成為OpenAI的CEO 然後把OpenAI納入 Tesla的公司之中 就是讓Tesla收購OpenAI 這樣子 那OpenAI他們其他人是拒絕這個 行為 因為他們認為馬斯克 這樣變成馬斯克一個人在管 OpenAI這間公司 他們覺得這樣子權力過度集中 也是非常危險的 然後針對幣源的這件事情呢 這邊蠻好笑的就是 OpenAI他們有釋出一封信 就是Ilia寫給 馬斯克的這封信 然後Ilia在信裡面他是寫說 OpenAI的Open並不是嚴格的 在指開源這件事情 而是在指說 每一個人都應該要能夠享受到 AI的果實
(46:02~47:02) 享受到AI帶來的這個 生產力的提升 然後幣源是完全可以接受的 那馬斯克針對這封信呢 他就回了一個字 他就說Yup Yup這三個字Yup 那我之後看到就覺得很好笑 就是OpenAI那個 整篇部落格文都非常震驚 然後他這邊也非常震驚的寫說 馬斯克先生 當時針對 OpenAI裡面Open這個詞 的解釋他回覆了Yup 那我是不知道Yup在法律上呢 是不是跟Yes 是同等的意思 但反正我覺得 部落格文看下來呢 馬斯克真的是挺糟的 那這個事件呢除了八卦的部分不看以外 其實確實有很多可以討論的地方 就是包括開源跟幣源 的比較 然後還有AGI要怎麼樣達到 之類的 我覺得這邊激起了很多 很有意思的討論 不過今天呢大家也可以聽得到
(47:02~47:46) 我的聲音呢其實還是有一點 鼻音的那我的感冒還沒有好 然後大家都聽不到的是 我其實每加兩句話我都會停下來 再嗑一下 這部分都被我剪掉了 所以說 我覺得今天我們就先聊到這邊啦 那還是老話一句啦 如果你喜歡今天的節目呢請幫我五星評分 然後留言 然後還有什麼分享給你的朋友們 同時呢也謝謝今天的 贊助商響窩 大家可以參考一下他們的床墊 那如果你也想要贊助科技浪的話 可以在本集資訊欄裡面找到 這個科技浪的網站 那今天點進去看一下科技浪的流量跟聽眾輪廓 然後再寄信給我們的信箱這樣 那我們會有專人回信 那最後呢就祝大家一個愉快的一周
