(00:00~01:00) 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式,帶你了解時下最火的科技話題 本期節目由NordVPN贊助播出 那我覺得VPN這個東西呢,真的就是大家都會需要的 那我自己用到VPN的方式呢,通常是兩個 第一個就是我在需要有資安保護的時候 就比如說我在使用一些公共的Wi-Fi,比如說機場的Wi-Fi或是咖啡廳的Wi-Fi 這個時候我就開我的NordVPN 因為我覺得用公共Wi-Fi的時候,然後如果我還要輸入一些我的敏感資訊的話 這些敏感資訊真的都是透過Wi-Fi這樣傳出去 然後如果有有心人士在使用同一個公共Wi-Fi 然後在做一些package sniffing,就是截取這些資訊的話 它是真的可以截取到我的個人資料的喔
(01:00~02:02) 這是蠻恐怖的 所以我就會開NordVPN,讓他們就算截,也只能截到亂嘛 那接下來呢,我常用NordVPN的方式就是 我如果想要使用一些國外的服務 但那個國外的服務在台灣是沒有開放的 這個時候呢,只要使用NordVPN就可以輕鬆跨去去使用那些服務 那當然除了我剛剛講的這兩個功能以外 VPN還有很多很多其他的功能 就是包括很多人喜歡看國外的劇,玩國外的遊戲 這個時候就需要用VPN跨去 或者是呢,有一些很厲害的小資族 他們知道國外買一些東西比較便宜 像是機票,有時候在跨區買是比較便宜嘛 這個時候呢,就可以直接跨出去,直接省下一筆錢 那我個人真的是覺得在所有的VPN當中呢 NordVPN是我最新的過 然後我覺得他們的連線速度最快的 所以一直以來我都是用NordVPN 那如果你也想要我剛剛講的所有好處 就是包括這個資安的保護,包括一些跨區的體驗
(02:02~03:04) 那我強烈推薦你使用我們科技量的優惠碼來購買NordVPN喔 因為這是非常非常棒的優惠 那你現在呢,只要使用我們的專屬連結 nordvpn.com slash techwave techwave的拼法是T-E-C-H-W-A-V-E 然後或者是使用我們的優惠碼 T-E-C-H-W-A-V-E 你就可以享4個月免費 而且還有30天無條件退費 這真的是蠻棒的一個優惠喔 那這個專屬連結呢,還有優惠碼 我全部都放在本集的資訊欄裡面 大家可以直接去取用 本集的配置就到這邊結束,謝謝NordVPN的贊助 那就在剛剛,我剛剛開始錄音之前呢 我看了一下IG 然後看到一張讓我十分震驚的一張照片 就是大家還記得那個在國外爆紅的 台灣男高中生Ray嗎 他是他的IG上PO了一張 他跟Kim Kardashian的合照 哇操,這Ray你會不會太扯了 你從街頭巧遇開Snype 跟他變成朋友之後
(03:04~04:04) 到現在你跟Kim Kardashian在hangout 哇,我只能說這個成功啊 我原本就覺得你應該是會爆紅 但是你這種成功啊 是我完全沒有預料到的 真的是太扯了太扯了 金卡帶三耶 你可以跟金卡帶三在一起hangout 是什麼樣子的概念,太扯 我前一次就看到那個Ray跟Kevin Hart混在一起 那Kevin Hart我覺得在美國應該也算是 非常前段般的一個藝人演員了啦 喜劇演員這樣子 但我覺得他跟Kim Kardashian 還是差了一個等級 而且Kim Kardashian在更上面 現在Ray這樣連Kim Kardashian都認識了 我真的覺得他未來的前途啊 前途無量 同時我也覺得很感動啊 我從他剛開始爆紅的時候 追他追到現在 大家還記得很久以前的一集科技浪 我有講到這件事情嗎 那我那時候講這件事情的時候呢 基本上台灣沒有人知道Ray
(04:04~05:05) 完全沒有媒體在報他 大家也沒有在講他 台灣沒有人在看Kyzen M 我當然也沒有在看啦 但是我正好是被演出人法打到這個影片 然後我就知道了 那沒想到這個Ray呢 在一年之內不但完成了他的高中學業 還做出了一番實業 現在跟Kim Kardashian混在一起 真的是太厲害了 真的給他跪了 太厲害了太厲害了 那接下來聽說他是要進去 要進去當兵了嘛 要當一年的兵 那這個這邊就 祝福他一切順利 好那上禮拜最大的一個科技新聞呢 我想應該就是非這個 蘋果的開發者大會莫屬了 那這個蘋果的開發者大會呢 英文是叫做Worldwide Developer Conference 那簡稱WWDC 然後你如果夠潮的話 你可以把它念成WWDC 那在這次WWDC之前呢 大家都已經大概有譜了 就是蘋果這次的WWDC會是一個 充滿了AI的一個WWDC
(05:05~06:06) 發表很多很多AI相關的內容這樣 那確實實際的狀況也跟我們想的差不多 就是在這個最一開始呢 一大堆蘋果的高層 在Apple Park裡面 跳來跳去飛來飛去轉來轉去之後呢 這個蘋果的執行長Tim Cook 他就出來跟大家說 Good morning 我們今天要發表AI 但我們的AI不是Artificial Intelligence 是Apple Intelligence 對大概就是這樣 他們就是發表了他們版本的AI Apple Intelligence 那你如果不知道我剛剛在講什麼的話 你可以去YouTube找一下這個WWDC的影片 你都可以看得到 那反正他們今年呢 他們就是標榜今年的WWDC是一個 Action Packed的WWDC 就是充滿了各種Action的 各種活力各種動作的開發者大會 然後他們怎麼呈現這一點呢 就是所有的高層在 他們PVT之前呢
(06:06~07:06) 他們都是用一個極限運動入場 他不是走過去 他們就是可能騎腳踏車 飛到空中轉一圈 然後落地再走過去 或者是像他們這個Suffer Engineering Team 很有名的這個Kraik Federici 他就是講到一個段落呢 他就會從二樓跑酷到一樓 就是在那個樓梯間跳來跳去 樓梯都不好好走 這邊飛來飛去轉來轉去 然後跳到一樓然後繼續報告這樣子 那我那時候看到我是真的笑出來了 我覺得超好笑的 因為他們講的內容真的就非常震驚啊 就說Mac OS Mac OS Sequoia什麼有的沒的 但是他們在那之前 就一定要這樣跳來跳去 就很過動就很好笑 好那我們今天呢 就是要來跟大家深度解析一下 蘋果的WWDC他發表了一些AI相關的內容 當然他們除了AI以外 也有發表一些他們蘋果產品的一些
(07:06~08:06) 原本的OS上面的更新 但這邊我們就先不琢磨太多 我們就主要來講他們這次發表的重點 也就是這個Apple Intelligence 不過我覺得在講這個Apple Intelligence之前呢 我也會想要帶大家把整個蘋果 在這之前做的所有AI相關的努力 都先梳理過一遍 這樣子大家對於蘋果這間公司 在AI這邊的發展的策略 然後以及他們目前做到的所有事情 會有一個更加深入的了解 然後在這集最後面呢 我還是無論如何 不管那個時間剩下多少 我都還是要跟大家做一個 SpaceX的最新update 因為他們是有進行了這個新建的第四次試射 這個在我的IG也有講 那這邊就無論如何一定要跟大家介紹一下 因為我覺得是一件大事 但蘋果還是今天的重點 所以我們就先從蘋果開始 那有一些人會說 蘋果在這次WWDC之前呢 真的沒有在做什麼AI相關的事情
(08:06~09:06) 他們在AI這邊呢是非常落後的 那我覺得也不盡然是如此啦 雖然說確實他們在生日式AI這邊呢 是有一點落後的 就是他們這次WWDC 真的是他們第一次推出了 生日式AI相關的這些功能 在這之前呢他們 儘管生日式AI已經紅了一年半了 他們是真的是沒有什麼生日式AI相關的軟體 但在這之前呢他們確實有在使用AI 有在做AI的事情 有把AI融入產品 也有讓自己的產品有能力跑AI 只是他們從來不講AI而已 他們用的詞呢可能是 Machine Learning用Deep Learning用Neural Network 但他們就是不講AI 那為什麼不講AI呢 其實我覺得也不是AI這個詞特別有什麼啦 只是蘋果這間公司呢 他一直以來就是比較喜歡 獨樹一格的感覺 就是他們說 我才不要跟你們這些猴子一起玩 你們在那邊講什麼 元宇宙啊 在那邊講什麼AI啊 我才不要鳥你們
(09:06~10:06) 我出的這個頭盔呢 是叫做Special Compute 然後我手機裡面跑的這些AI軟體呢 是Machine Learning 雖然說確實啊 AI背後就是Machine Learning嘛 但蘋果就是想要獨樹一格 他就是想要跟別人不一樣 就是不想要用這種大家都在用的Buzzword 這樣子的感覺 可能他們這麼做可能也是因為 怕會被這些名詞給臭到 因為像元宇宙有一陣子 我覺得我記得也是挺臭的嘛 就那個熱潮一過啊 那個熱錢離開了之後呢 大家就開始臭它了這樣 那個蘋果呢可能也是怕被他們臭到 那他們這次的WWDC呢 是終於講了AI嘛 不過他們是把它變成這個Apple Intelligence這樣子 所以說還是獨樹一格 還是不一樣 我們的AI還是跟你們的AI不一樣 然後就算今天這個AI這個名詞呢臭掉了 大家跟元宇宙一樣 大家開始討厭這個字的時候呢 你們也跟我沒有關係
(10:06~11:08) 因為我們的AI是Apple Intelligence 你們討厭的是Artificial Intelligence 對不對 好總而言之呢我想講的是 蘋果雖然說他死也不講AI這個字 但他確實有把AI融入他的產品之中 而且這件事情並不是在今年WWDC他們才開始做的 他們在這之前非常早以前 他們就有在AI這邊做非常多的布局了 那我們就先從這些布局開始講起好了 那我覺得最早呢要先從2017年蘋果出的iPhone 8開始講起 那這一代iPhone 8呢他們有一個很特別的事 就是他們裡面的晶片是叫做A11 Bionic 但在iPhone 8之前iPhone 7呢他的晶片是A10 那你有沒有發現這他並不是A10變成A11而已 他還多加了一個詞叫做A11 Bionic 那Bionic這個詞呢他的中文是翻成仿生 仿生這個意思呢就是你做出一個機器 是可以模擬一個動物一個生命體的行為的
(11:08~12:09) 或者是模仿人類這樣子 那你其實看Bionic這個詞的來源 你其實就會知道為什麼他是這個意思啊 因為Bionic他其實就是Biology跟Electronic這兩個詞的結合嘛 那個Biology是Bio就是什麼生命相關的嘛 Electronic就是比較機械相關的 那這兩個東西結合就是用一個機械去模仿一個生命 那什麼東西是用機械用人工的方式去做出一個生命的行為呢 就是人工智慧嘛 人工智慧就是機器在模仿人類的智能啊 那A11這一代的晶片呢之所以多了Bionic這個形容詞呢 確實也是因為他在人工智能的運算這邊的能力提升了非常多 那這個就是因為他們在A11這一代呢 首次在晶片裡面加入了專門運算AI的處理器 叫做Apple Neural Engine 蘋果的神經網路引擎 簡稱ANE 那在iPhone 8之後呢所有的蘋果手機
(12:09~13:09) 蘋果的電腦裡面的這些他們的Apple Silicon 他們這些蘋果自己研發的晶片呢 裡面全部都有加上ANE 然後這個ANE呢也是有在不停的變強 這個核心數不斷的變多 然後算力不斷的變高 那現在最新的這個M4的晶片裡面的ANE呢 已經比iPhone 8裡面A11 Bionic裡面的ANE快了60倍了 所以可以說是在2017年之後呢 蘋果就讓他的所有裝置都具備了跑AI的能力 雖然嚴格來說在ANE之前呢 這個裝置也是可以用GPU跑嘛 但是有ANE之後呢這個ANE呢就是專門跑AI 或者更嚴格來說專門跑神經網路的這些處理器 能夠跑得更快以及更省電更有效率這樣子 所以你如果是蘋果的用戶呢 你常用到的這些AI功能就是包括可能Siri啊 可能臉部辨識啊 臉部辨識解鎖嘛 然後可能這個 可能這個你在相簿裡面的一些
(13:09~14:11) 這個字體的辨識啊人物的辨識啊 這些東西呢只要他背後有一個神經網路在跑 那他很有可能就是在ANE上面進行運算的 那我剛剛講的這些功能呢 比較像是蘋果他們自己開發的軟體自己的功能嘛 那第三方的軟體第三方的開發者可不可以使用ANE呢 其實嚴格來說是可以但是不容易 那首先呢要先跟大家介紹就是 假設你今天在開發一個蘋果的軟體 不管你是iPhone上面的APP還是這個Mac上面的應用程式呢 你在開發這個軟體的時候 你想要在你的軟體裡面加入AI 加入Machine Learning的Model的話 你就要使用到蘋果他們的一個Framework叫做CoreML 就是你要把你的模型先轉變成這個CoreML的形式 然後再把它加入你的APP裡面這樣子 那這個CoreML呢 它會不會用到這個ANE去進行運算呢 其實會 但是你不能指定它要去用ANE去進行運算
(14:11~15:12) 你只能跟它說能用ANE的時候就用ANE 但它實際上它也是會自己去選擇說 我們現在是要用CPU還是GPU還是ANE這樣子 所以說這些開發者呢都必須要去努力去figure out說 這個模型用什麼樣子的架構啊 然後在什麼樣的情況之下呢 所以這個CoreML才會用ANE去跑它 然後又要進行很多次的Trial and Error 很多次的實驗 然後這個Documentation也寫得不是很好這樣子 那當然這部分我自己沒有開發過啦 我是看網路上的一些工程師的抱怨這樣子 但確實就是Apple在這個ANE的Support這邊 它開放的真的非常的少 我也不確定為什麼是這樣 然後我們從去年年底蘋果推出的一個 專門為蘋果晶片設計的一個AI深度學習架構 叫做MLX 我們也可以看到這一點 那正好我們現在可以來講一講這個MLX 因為我覺得它也算是蘋果在AI這邊佈局
(15:12~16:12) 蠻重要的一部這樣 那首先呢如果你不太知道什麼是一個AI的深度學習架構的話 那它基本上就是一個AI工程師要建一個AI模型的時候會使用到的工具 最常見的呢就是PyTorch 就假設你今天要建一個神經網路的模型好了 你只要使用PyTorch 你大概可能十行code左右 你就可以把這個模型給建出來了 為什麼呢 因為你只要非常高層次的定義這個模型它的架構就好了 就是它可能幾層哪些Hidden Layer幾個Node 然後它的這個Activation Function是什麼啊 要用什麼Lost Function去Train 用什麼Optimizer 你把這些東西用Python就是非常接近人類語言的一種語言 去簡單把它定義出來 基本上你的模型就建完了 那接下來你實際在使用這個模型在訓練這個模型的過程之中呢 它背後所有進行的這些數學運算全部都是PyTorch幫你搞定的
(16:12~17:14) 它會直接你寫很簡單的語言 它把這個語言再轉換成複雜的這個數學運算 然後再把這個複雜的數學運算 看你用什麼晶片 就Map到那個晶片上面的指令這樣子 那這個MLX你就可以把它想像成專門為蘋果晶片設計的PyTorch 那它一樣就是你可以透過MLX很簡單去Define一個神奇網路的AI模型 或者是你的這個Training的Script這樣子 那這個MLX能做到的事情跟PyTorch差不多 然後其實比PyTorch少很多啦 但就是因為它是比較新的一個架構 但它有一個很特別的地方 就是它專門是為蘋果晶片設計的 那這一點呢最明顯就是體現在記憶體的使用這一邊 因為我們知道蘋果的晶片它的記憶體是非常特別的 我在這邊講的晶片是M系列的晶片啦 就是它的這個MacBook裡面會使用的嘛 那M系列的晶片呢它的記憶體是所謂的Unified Memory
(17:14~18:16) 也就是說它的所有處理器 這個CPU GPU跟Neural Engine 它們都是共用同一個記憶體 它的那個記憶體就叫做Unified Memory 那在Windows系統這邊呢都是分開的嘛 就是你的CPU呢使用的是自己的記憶體叫做System RAM 然後這個GPU呢你可能買一個NVIDIA的GPU嘛 你NVIDIA的顯卡裡面它也有它自己的記憶體嘛 叫VRAM Video RAM 那你今天在跑一個AI模型的時候呢 在某一些情況之下 就比如說你要跑非常多次非常快速的這種AI的推論 就快速的讓這個模型運算很多次 那這個時候你可能要CPU跟GPU之間 一直互相丟資料丟來丟去這樣 那你如果是Windows這邊分開的話 你可能就就是資料一直要在System RAM跟VRAM這邊傳輸傳輸這樣 但如果你是Apple的這種Unified Memory 你GPU跟CPU還有NPU你都用同一個記憶體池 你就不用你就省下這個搬運的成本了
(18:16~19:17) 因為大家都是從同一個記憶體裡面拿資料出來 那這個MLX的好處呢就是比起PyTorch 它可以更妥善的運用蘋果晶片上面Unified Memory這個優勢 去讓這個模型跑得更快這樣 不過我也必須要說啦就是這個MLX呢 它畢竟還是一個比較初期的一個架構啦 不像是PyTorch已經被開發了這麼久了 所以說它在很多的這個一些數學運算上面的優化呢 還沒有做得像PyTorch這麼好 所以說很多的事情呢你用MLX比起用PyTorch是比較慢的 但這個MLX呢也很明顯的就顯示了蘋果 想要讓更多的人在他們的蘋果晶片上面 使用AI模型或甚至是訓練AI模型這樣子的一個想法 然後也確實 雖然說我相信大多數人聽到 訓練AI模型的晶片大家都會想到回答 就想到NVIDIA 但是呢其實開源社群就是網路上的這些工程師們 他們其實是很愛使用蘋果的電腦去跑AI模型 或者是訓練AI模型的
(19:17~20:17) 很多一些最主流的這種開源的 跑大型模型的工具啊這個 繪圖的工具啊 比如說什麼LAMA CPP啊之類的 他們其實最一開始呢都是專門為了AppleSense 這個回答的資源呢是之後才被加入的 那大家之所以會比較少聽到 我們用蘋果的晶片去跑AI呢 然後都只聽到這個用NVIDIA的晶片呢 是因為我們現在講到這種AI運算 通常都是在講這種大型圓模型的預訓練啊 這種需要極大量的運算資源的 或者是這種trillion parameter model的推論啊之類的 那這種情況下呢 都是會需要用到資料中心的伺服器在做運算 那這邊呢當然就是被NVIDIA獨霸啦 你有聽上一集的科技狼你應該也知道 但這邊就是跟大家補充說 其實在這種一般的人家裡呢 你想玩一玩甚至是AI 甚至是訓練一種比較小的甚至是AI模型呢
(20:17~21:19) 其實那個蘋果的晶片 蘋果的電腦是一個popular choice喔 那其實這個晶片呢 是一個popular choice喔 那講完了這麼多MLX的介紹呢 我們回扣到我們剛剛說 Core ML在Ane資源不是很好的這個部分 其實MLX這邊不只是資源的不好 甚至是完全沒有資源 就是你要用MLX去train一個生存式AI的模型 或者是跑一個生存式AI模型 你都無法使用Ane 你就是純粹是使用這個M1晶片M2晶片裡面的GPU 在進行訓練而已 你是沒有辦法engage Ane的 那為什麼是這樣其實我也是不知道啦 反正就是回扣的剛剛說 其實Apple在Ane這邊啊 真的是感覺蠻private的 感覺support都沒有做得非常好 也不確定為什麼 好那我們剛剛呢就是簡單介紹完了 蘋果在硬體跟軟體這邊分別做的一些AI布局嘛
(21:19~22:21) 在硬體這邊呢是他們在裝置裡面加入了 Apple Neural Engine Ane 專門運算AI的這種處理器 然後在軟體這邊呢他們有一些自己開發出來的這種軟體的功能 AI的功能啊 臉部辨識啊segmentation之類的 但除了這些以外呢 他們也有開發CoreML 可以幫助開發者把AI加入他們的iOS或是MacOS的App裡面 然後也有像是MLX 可以讓開發者呢在蘋果的晶片上面去訓練 或者是推論這種AI模型 那以上的這些呢 基本上就簡單總結了蘋果在這次WWDC之前呢 消費者能夠接觸到的所有AI 蘋果的AI這樣 但除此之外呢 蘋果其實也有在持續做一些AI的研究 他們的Machine Learning Research Team呢 會不定時的發一些paper出來 然後都是很低調的發 就是他們不會透過蘋果的官網呢
(22:21~23:22) 可能就是釋出他們最新的研究這樣子 像Google這樣 他們可能就是很低調的把自己的論文放在archive上面給大家看 就是單純做一個學術交流這樣子啦 但儘管他們是想要低調 他們還是沒有辦法低調 因為畢竟他們是蘋果嘛 然後他們如果推出這種生成世界相關的論文呢 一定被一堆這種媒體分析師拿出來就是 去做一個標題嘛 就是說蘋果終於有生成式AI了 這樣子之類的有的沒的這樣 像他們應該是幾個月前 還是可能年初的那時候發的一篇 叫做MM-1的論文嘛 那個就是他們在研究多麼太模型這邊的生成式AI模型 那他發了這篇論文之後呢 就有很多人就在那邊說 蘋果的MM-1究竟多強 什麼時候會釋出什麼有的沒的 那我看到那個會覺得很好笑 因為你仔細去看那篇論文 他就是在做一個ablation study
(23:22~24:22) 那篇論文的重點甚至不是MM-1這個模型本身 他們只是在實驗在整個training的過程中呢 拿掉哪些部分會有什麼樣子的影響這樣 然後這MM-1就是一個實驗的結果而已 他不是一個他們要推出的產品還是什麼的之類的 然後蘋果在那之後呢 也發了另外一篇論文是這個Open ELM 或是Open ELM我不知道他怎麼念啦 反正就是一個大型圓模型嘛 小圓模型 然後他們主要也是在研究一些不同的training method 不同的architecture這樣子 我記得他們好像是研究了layer-wide scaling之類相關的 反正anyways 就是從這些論文這種低調的論文發表呢 我們頂多就是看出說蘋果有在做生成式AI相關的研究 他們有在注意這一塊 他們不是完全放棄這一塊這樣子 然後他們研究方向大概是什麼 然後他想要跟研究社群的人交流的想法是哪一些
(24:22~25:22) 大概是這樣子而已 然後除了這些論文以外呢 我們也可以從一些其他地方看出說 蘋果好像慢慢的有把生成式AI當成一回事了 就是我們有聽到一系列相關的新聞嘛 就像是他們說 他們把他們原本要做電動車的business給deprecate掉 整個部門全部都關掉 然後把裡面的人轉到genAI的team裡面 來搞生成式AI這樣子 那我們也有聽到說 他似乎要跟Google去partner推出AI的產品功能 然後也有跟OpenAI在聊這件事情 然後最後呢就是先破題啦 就今天WWDC蘋果是跟OpenAI合作了 但這個Google的合作傳聞呢是蠻早以前就有了這樣 然後除此之外呢就是 Tim Cook在他們的earnings call裡面 也開始慢慢的有提到這個在AI這邊的投資了這樣
(25:22~26:24) 所以說呢這次的WWDC 全部的人都預期蘋果會發表一大堆AI相關的東西 那確實他們也發表了很多很多AI的功能 只是他們把他們都包成同一個 用同一個包裝來包住他們 就是Apple Intelligence這樣子 講到這邊呢你會發現我們已經接到了 我們下一個主題也就是 今年的WWDC的內容 也就代表說呢 我們剛剛已經把蘋果在WWDC之前呢 在AI這邊做的所有事情 所有重要事情啦 然後還有一些其他相關的新聞呢 都已經聊過了 所以我們接下來呢 可以進入WWDC2024了 那今年的WWDC呢 基本上就是分成主要兩段 前半段呢就是在講他們 目前所有產品的這個 作業系統的一些update 有沒有什麼新的功能啊之類的 從這個iOS再講MacOS再講TVOS 全部帶過一遍這樣 那後半段呢全部都是在講Apple Intelligence
(26:24~27:24) 那前半段這邊我就不會特別著墨啦 就一些酷酷的小功能這樣 然後很多就是安卓早就有的功能這樣 那後半段這個Apple Intelligence呢 我覺得一句話來講呢 基本上就是中規中矩 跟大家預期的差不多 那具體來說它究竟是什麼呢 反正就是蘋果裝置裡面 所有的這些生成式AI功能 他們全部把它們包成一包 叫做Apple Intelligence 包括更聰明的Siri 包括一些書寫的輔助 然後包括一些你可以即時產生 一些圖片新的貼圖這些功能 全部都是Apple Intelligence Apple Intelligence背後呢 有三種不同大小的AI模型在跑 你所有的功能裡面最簡單 最單純的那些事情呢 會交給最小的模型 也就是在你的裝置上面跑的這些模型去處理 那比較困難比較複雜一點的問題呢 它會交給一個中等大小的模型去跑 那這個中等大小的模型呢 當然沒有辦法在你的手機或是電腦上跑得動嘛
(27:24~28:25) 所以說這些模型呢 是在蘋果他們自家的伺服器上面跑 也就是蘋果資料中心裡面的電腦上面跑這樣 那你的裝置呢會跟這個伺服器做一個連線 然後把你的問題丟給這個伺服器 讓這伺服器上面的模型算完了答案之後呢 再丟回答案給你 然後如果是更複雜的問題 連中等模型都解決不了的話 它就必須要連到最屌的模型了 也就是Chat GPT 這邊蘋果沒有再比中等模型更大的模型 更屌的模型了 所以他們是直接使用這個OpenAI 目前最厲害的模型叫做GBT-4O 也就是說你今天遇到的問題真的是非常困難 你的裝置無法回答的時候呢 它就會問你說 要不要把這個問題交給GBT-4O來回答 然後你要明確的點下是 你的問題才會被傳給OpenAI這樣子 那具體來說哪一些問題是哪一個類別 這個他們沒有細講啦 但這個我相信也不重要啦 大家你如果是蘋果的使用者
(28:25~29:25) 未來自己使用的過程中 你就會慢慢發現 哪一些問題呢是蘋果的模型無法回答的 要交給OpenAI的這樣 然後哪一些問題呢是直接在本地的這個模型上面 就可以跑了就可以解決了 那麼具體來說呢這個Apple Intelligence 現在究竟能做到哪一些功能呢 我這邊很快的帶過一下 那這邊我接下來講的有一些功能呢 其實是還沒有開放的 就是我接下來講的所有功能 所有功能都是他們WWDC宣布的 但他們宣布的所有功能之中呢 其實只有一部分會在 這次最快的這個iOS18 放出去給大家使用這樣子 所以並不是所有功能都是大家可以在接下來的可能 一兩個月用到這樣子 如果你是蘋果用戶的話 好那首先呢是一系列的這個寫作輔助工具 就是他會幫你做Grammar Check 他可以用AI幫你Rewrite你的文章 把他寫得更Friendly 把他寫得更嚴肅之類的
(29:25~30:26) 然後也有Smart Reply 直接幫你你一個草稿出來 或者是Summarize幫你Summarize一些文章 或者是訊息也是可以Summarize 他會自己幫你抓出說 接下來你所有訊息之中哪一些是比較重要的訊息 然後給你一個簡單的摘要這樣子 然後通話的時候呢你也可以產生出逐字稿 然後順便幫你做一個總結摘要 然後接下來是Siri的一些Update 這個Siri他變聰明一點啦 就是他現在可以理解更複雜一點的語言 Obviously因為他背後有LM嘛 那比如說呢他們給的一個Demo就是 你原本是叫Siri設鬧鐘嘛 這就是Siri最主要的功能嘛 你就跟他說 不是鬧鐘啦計時器 你就跟他說Siri幫我設一個5分鐘的計時器 那這是原本的做法 那現在呢你可以跟他說 Siri幫我設一個鬧鐘 不對不對我要設一個計時器 設10分鐘好了 不對不對還是把它變成5分鐘好了
(30:26~31:27) 你可以這樣子講然後他可以理解你 哇好棒好棒喔 那這個Siri不只是語言理解能力變強了 他還多了兩項能力 第一個就是Context Awareness 第二個就是實際去操縱其他APP的能力這樣 Context Awareness就是他多了更多前後文嘛 他多了你更多的個人資料 就是他能夠取得你的日曆 你的筆記你的photos 你的email的這些權限 當然如果你給他的話 那也就是說你可以問的問題 就像是你直接問他說 我的舞蹈課是什麼時候 他就跟你講 他直接去抓這個你的日曆裡面的資料 或是你問他說 我的護照號碼是幾號 然後他你可能有在你的圖片裡面拍過你的護照 他就可以自己去找說 你的護照是這張圖片 然後他的號碼是幾號這樣子 然後跟你說 那這個能夠操控其他APP的功能呢 就是比如說你現在看著一張照片 然後你就直接跟Siri說
(31:27~32:28) 把這張照片用的更鮮豔一點 他就會直接操控你的相簿裡面的Photo Editor 直接幫你調一下對比度 飽和度有的沒的 幫你調一下這樣子 以上講的這些所有功能 都是跟LLM或者是Transformer Model比較相關的 接下來就是跟Diffusion Model比較相關的功能了 這邊就是跟圖片有關係的 比如說你可以直接把一張現有的圖片 變成一個不同的風格 好像只有三種風格可以選 就是卡通版啊、素描版啊 有的沒的反正三種 接下來還有一個功能叫做Gem Emoji 這個基本上就是你可以製造出任何你想要的Emoji 你只要用自然語言就可以了 比如說你打入一個Race Car Driver 就一個Race Car Driver的Emoji出來這樣子 這個基本上你如果還嫌現在幾百個Emoji不夠用的話 你可以再多加幾個啦
(32:28~33:28) 雖然說我現在可能用到現在 我一天不會用超過三個Emoji 除此之外呢 你也可以用自然語言去進行圖片的搜尋 或者是用... 這個其實不是Diffusion Model 這個應該是可能跟Clip比較相關的Model 但反正它是圖片生成相關的功能 它會放在同一類 你可以做圖片的搜尋 或者是你可以去直接用AI去進行修圖 你可以把圖片之中一些不必要的部分 直接刪除掉這樣子 然後它會再幫你補上這些人刪除掉之後的背景 Apple Intelligence非常快的帶過大概就是這樣 你會發現這很多的功能 其實在安卓的一些手機上早就有了 這沒有一個功能是新的啦 我們早就知道AI可以做到這些事情了 然後也大概預料到蘋果會做這些事情
(33:28~34:28) 所以我相信你如果有在關注AI 有在聽科技量的這些人 應該是沒有一個人被這些功能所驚艷 但其實說真的 蘋果真的沒有必要端出那種非常創新非常驚艷人的一些Feature 因為iPhone其實已經不知道幾百年沒變了 不知道從第幾代開始就幾乎沒帶到一模一樣 所以它...然後儘管如此啊 還是一堆果粉會升級嘛 所以基本上多了這些功能呢 儘管它們不是那種就是其他人都做不到的非常酷的功能呢 還是我覺得對於這個iPhone的銷量一定還是有很大的幫助啊 那這也是為什麼蘋果的股價在這次WWDC之後是上漲了嘛 那除了這個Apple Intelligence它的功能以外呢 蘋果也有發表說這個Apple Intelligence呢 它們做了非常多的隱私相關的保護 那這邊當然就是蘋果一直以來非常主打的一塊啊
(34:28~35:29) 非常堅持的一塊就是它們要把個人隱私做得非常好 那針對那個最小的模型直接在你裝置上跑這些模型呢 那這邊隱私當然就不是一個問題啦 因為這個裝置你都買了 你是在你已經擁有了它這塊晶片了 然後你是在你自己的晶片上面跑 這邊當然是沒什麼好怕的啦 但這個中型模型呢就會把資料傳到蘋果的伺服器嘛 那這邊他們就Promise了非常非常多關於Privacy的一些保護 包括你的資料永遠不會被存在蘋果的伺服器 然後它只會把相關的資料傳給伺服器 不會傳任何多的資料 然後也會請第三方的一些Verifier來去Verify他們的整個process 他們的程式嘛有的沒的 那大模型這邊呢也就是OpenAI這邊呢 這個可能就我不確定大家有多少人會買單啦 畢竟你的資料還是必須被傳到這個OpenAI的伺服器那邊 但這邊呢就他們我記得他們是有說
(35:29~36:32) 他們會把你的ID給scramble啊之類的 這個OpenAI不會有任何可以identify你個人的東西之類的 反正他們這邊也盡量做好隱私權的保護啦 那除了隱私權以外呢他們也有公布一些跟開發者比較相關的 就是我剛剛講到的這些所有Apple Intelligence的聖人士AI功能呢 它現在全部都是在蘋果他們自己的軟體上面運作嘛對不對 像這個Siri啊Fotos啊他們Calendar E-mail 這些都是他們自己的App嘛 那第三方的App可不可以使用他們聖人士AI的一些功能呢 包括他們的一些模型啊或者是Vector Database 其實是可以的就是他們有開放一些新的App Intents 這些API啊Framework去給開發者使用 就是比如說未來這個Notion的App裡面呢 它可能就會整合他們的這些AI寫作助手 這個AI寫作助手是iOS裡面的一個功能嘛
(36:32~37:32) 但是這個Notion的開發商呢可以用他們的蘋果的官方的SDK 他們的API去把這個功能導入Notion裡面 所以以後那個iPhone裡面的Notion可能就會有自動的Grammar Check 自動的這個Rewrite這些功能 雖然說現在這個Notion裡面我記得也是 他們也是有自己的雲端的AI可以做到這件事情 但搞不好就是未來他們 If they want to, you know,他們可以整合Apple的AI進去 好那接下來重點來了 哪一些裝置可以使用Apple Intelligence 首先在這個電腦這邊呢基本上全部都可以 除非你是非常非常老的那種還在用Intel的chip的裝置呢 只要是換到M系列的晶片的全部都可以 基本上所有都可以 那手機這邊就比較悲慘了 它基本上是只有現在所有手機裡面最強最高級的iPhone 15 Pro Max 跟iPhone 15 Pro可以使用Apple Intelligence 在那之前的每一代
(37:32~38:32) 甚至包括是iPhone 15跟iPhone 15 Plus 全部都全死完全不能使用 那我這邊就有聽到有些人說什麼 好賤喔這逼我們要升級要買最貴的這個Pro跟Pro Max 然後也確實有看到有些人 就因此就原本要買可能15 Plus或15 他們就因此就升級了一下買了Pro跟Pro Max這樣子 那我自己是覺得應該不是這樣啦 蘋果並不是不願意下放到前幾代的手機 而是前幾代的手機真的跑不動 應該是所有iPhone裡面唯一能跑Apple Intelligence的 應該只有這個15 Pro跟15 Pro Max 那我會這樣講是因為現在所有的iPhone手機裡面 只有15 Pro跟15 Pro Max有8GB的RAM 其他所有手機就算是14的這個Pro跟Pro Max 也都只有6GB或甚至是更低的RAM 這個RAM就是手機的記憶體嘛 那我們知道在跑AI模型的時候呢
(38:32~39:33) 你一定要把這個AI模型Load到你的記憶體裡面 也就是說你記憶體要放下這個模型 你才可以去使用這個模型去做運算嘛 那蘋果有在他們的一篇部落格文裡面有講到說 他們的這些on device的小模型呢 是差不多3 billion參數的模型 30億參數的模型 那30億參數的模型呢 他們沒有公佈這個模型究竟有多大 但這個是大概可以推算出來的 只要你知道他的參數量有多少 然後他的quantization level到什麼樣的程度 那他是Q3.5這樣 所以你可以大概推算他的大小 那我自己推算了一下 我覺得他大概是1.65GB的大小這樣 也就是說你今天在用這個Apple Intelligence的功能 然後是用到這個小模型on device模型的時候呢 他會直接佔用你1.65GB的RAM 那這個iPhone15 Pro以外的模型呢 都是6GB的RAM 那其實說真的啦 一般人在用iPhone可能3GB的RAM就夠了
(39:33~40:33) 因為這個蘋果的手機呢 其實是蠻memory efficient的啦 就是他們垂直整合做得非常好嘛 就從他們最底層的這個晶片 是他們自己設計的 然後再上來的這個iOS也是他們自己設計的 然後上面所有的App也都是 用他們自己的程式語言這個Swift去寫出來的嘛 他們全部的東西都有做這個垂直整合 所以三個東西呢他們 這個Memory Management就可以做得非常好 那反正就正常人用iPhone可能3GB的RAM就夠了 但是你如果是比較認真的Gamer 或者是你要同時進行非常大量的Multitask 要開一大堆不同的App 然後一直切換切換去 你可能會需要用到6GB 那這個時候呢 如果你的手機本來就只有6GB的RAM 那你應該是不可能跑得動一個Apple Intelligence 你不可能再讓Apple Intelligence去佔用掉1.65GB嘛 你的手機一定會當到爆
(40:33~41:35) 所以說這個除了iPhone 15 Pro跟Pro Max以外 其他所有的手機都是6GB的RAM 他們應該就是這輩子是 可能沒有機會可以跑Apple Intelligence 除非這個蘋果有一些什麼小模型的Breakthrough 要用更小的模型就可以做到一樣的事情 是有機會啦 可能我們都知道一年之內模型進入了140倍嘛 所以搞不好可能一兩年之後是有機會的 但就目前來看啊 短期你是不用想這個Apple Intelligence下放了 那這個15 Pro跟15 Pro Max他們有8GB的RAM 我覺得跑Apple Intelligence就差不多啦 就儘管你是超認真的Gamer或Multitasker 你用到了6GB的RAM 你還有2GB的空間可以用Apple Intelligence 所以說我覺得這邊應該是沒什麼問題 那我覺得這邊Apple也是蠻賽的 我不知道他們是不是賽的啦 但他們剛好選擇在A15 Pro這一代晶片升級他們的RAM
(41:35~42:35) 我覺得他們很可能是剛好升級喔 為什麼 因為他們就我們知道你在設計一張晶片的過程 那個lead time很長嘛 晶片是很複雜的東西 你要花很長時間去設計 然後去take out 然後再production 這整個過程是非常長的 所以說他們很可能這一代的晶片 我先說這我不是專家 我不是半導體的專家 但很可能他們15 Pro的這個晶片 也就是A17 Pro的這張晶片呢 可能是在甚至是AI ChaiGBT爆紅之前 他們就已經設計好了 因為這個15 Pro是去年9月出來的嘛 那ChaiGBT是去年年初爆紅的嘛 那這個時間只有間隔9個月 那雖然我不是專家 大家可以就是指正我糾正我 但9個月 我覺得這個晶片的lead time不會這麼短啦 應該是在那之前就設計好了 所以他們剛好選擇在這個15 Pro這一代升級RAM 真的很可能是賽到 因為他們在那之前
(42:35~43:35) 我剛有去查就好像是從iPhone 12開始 就RAM就一直沒變了 就是一直是6GB的RAM 因為6GB真的就很夠用啦 就儘管是對超級hardcore gamer也是夠用 所以說他們其實沒有很大的升級的必要 但他們剛好選擇在這一代升級 如果他們那個時候沒有選擇在這一代升級 而是選擇可能在下一代或下一代再升級的話 蘋果的AI又要再等一年了 那真的是那真的會有點GG 那根據有一些媒體跟分析師的爆料呢 接下來的下一代的iPhone 16呢 會全部改用新一代的晶片A18的晶片 因為我們知道這個Apple他們有時候是 就是他們下一代的iPhone呢 他們可能只有Pro跟Pro Max使用新的晶片 他們的一般的model跟Plus的model 可能是用上一代的Pro的晶片 就像是iPhone 15跟15 Plus 是用iPhone 14 Pro跟14 Pro Max的晶片嘛
(43:35~44:35) 但是這個iPhone 16呢 是四支全部都換新的晶片這樣 就是A18的晶片 那我覺得這個A18晶片呢 應該就是有更強的NPU 也就是更強的Apple Neural Engine 然後也會有足夠的RAM 8GB的RAM去跑Apple Intelligence這樣子 所以說呢 我也沒有在推薦大家買iPhone啊 但如果你原本就是想要買iPhone的話 然後你原本現在在想 要不要為了Apple Intelligence 升級15 Pro的話 我會建議你可能就 你可以等個幾個月 然後直接升級16 因為我覺得16跟16 Plus 應該就可以跑Apple Intelligence了 他們這一代的晶片呢 應該是有參考了這個 生真式AI的爆發去進行設計的 所以說一定會給你足夠的RAM 跟這個A&E的效能 好那我剛剛有稍微帶到就是 蘋果好像有釋出一個
(44:35~45:38) 這個Technical的Block Post 在講他們的模型嗎 那這邊確實你們大家可以去查一下 這篇文 我覺得是挺不錯的 我覺得他們就是一個Technical Block Post 然後他們基本上是揭露了 所有他們能夠揭露的Technical細節這樣子 那我覺得這個事情是真的還蠻不錯的 因為他們真的很多的細節 他們是真的沒有必要去公開跟大家說啦 但他們願意做到這一步 然後願意這麼透明 我覺得是很棒 但他們當然也沒有透明到哪裡去啦 就他們也是比較講一些比較High Level的東西 但你不至於看完了整篇之後 什麼東西都沒得到 像是可能一些OpenAI的Technical Report 都有這種感覺 好那這整篇的Technical Block Post 我全部都看完了啦 然後我其實寄了爆多筆記 然後是有蠻多可以跟大家分享的 但我覺得這個很多東西呢 其實真的是比較技術一點啦 你大部分的人其實也不用Care到這麼深的東西
(45:38~46:38) 然後有興趣的人其實也可以自己去看一下 我會把這個Block Post連結放在本集資訊欄的最下方 但我就挑一些我覺得蠻酷的東西跟大家分享就好了 那首先呢就是他們整篇呢 非常注重在一個點上 就是非常注重在如何把這個模型變得更有效率 讓它能夠吃更少的記憶體 然後被算得更快 這是他們整篇在Focus的重點 那當然確實啊 他們要在手機上面跑一個生成這個3 Billion的模型 3 Billion模型雖然說就目前的大型模型的等級來看算是小的 但它還是有30億格參數啊 然後也是要佔1.65GB的記憶體 那這個如果跟一些傳統的軟體比起來 這還是非常大還是很Loading很重的一個軟體這樣 所以說他們在Optimization這邊下了很多功夫這樣 那大家可以細看啦
(46:38~47:40) 有一些可能比較業界標準他們做的事情 就可能GQA Group Query Attention然後Quantization 他們把它Quantize到3.5 bits 他們不是4 bits quantization 他們Quantize到3.5 bits 也就是說它是一個2 bits跟4 bits的混合精度這樣子 然後還有一些KVcache的一些Trick啊什麼 他們做很多這些事情 剛剛這些技術的名詞聽不懂也沒關係 這些可能你如果沒有在開發LM的軟體呢 你也不用知道這些啦 你如果只是想就是知道一下科技趨勢你不用了解這麼深 但有一點我想特別講 就是他們有用所謂的Laura的方法 也就是用Adapters來微調他們的模型 在我解釋它是什麼之前呢 我先跟你講為什麼我想提這件事情 我想提是因為我覺得這個做法 很可能接下來會變成AI PC跟AI手機裡面的業界標準 我覺得大家應該都會採用這種做法
(47:40~48:40) 或甚至是可能Copilot Plus PC也有這麼做 也不一定只是他們沒講而已 我從他們的這些Document裡面從來沒有看到Adapter這個字 或者也可能是我忽略了 反正我沒有看到 但我覺得未來大家在做AI PC跟AI手機裡面的時候 一定都會用Adapters 那什麼是Adapters呢 我覺得我們要先從Fine Tuning開始講 Fine Tuning一個模型也就是說你要微調一個模型 意思就是說你要讓這個模型呢 針對一個特定的資料集去進行小規模的再訓練 大概是這樣子的意思 那這個特定的資料集可能是一個你特別想教給他的一個技能 或者是特別想教給他的一個風格之類的 就比如說你今天你剛訓練出了一個大型元模型 他對於所有事情都有一個General World Knowledge很好的嘗試 但他沒有任何一件事情是特別擅長的 但你今天想讓他特別會寫Email 你就要用你的Email的資料集去Fine Tune他
(48:40~49:40) 那通常Fine Tuning會有兩個做法 一個做法呢就是其實基本上就是跟你一般在訓練這個模型一樣 你就是直接讓這個模型呢一次一次的把你整個Email的資料集全部吃進去 然後不斷的更新他的權重 所有的自己腦中的權重全部都調整過一遍 那這個就是一般的做法 但你還有另外一種做法叫做LORA 那LORA的全名呢是Low Rank Adaptation 也就是我們今天要講的Adapters 這些Adapters就是LORA 那LORA的做法呢就是你今天不要直接拿你的資料集去Tune這個模型的大腦 你先做一個比較小的大腦 然後你在訓練這個模型的過程中 在微調這個用這個Email的資料去微調的過程中呢 你把這些微調過程中學到的所有東西都用這個小的大腦去學 所有的Email的知識都放在這裡面 然後大的模型這原本的大腦呢是原封不動的
(49:40~50:40) 那整個訓練完了之後呢 基本上你就你的模型基本上是完全沒有變的 但是你多了一個裡面存有所有Email知識的一個小型大腦這樣子 那之後你在使用這個模型的時候呢 你可以直接把這個小型的大腦放大 然後直接加進這個原本模型的大腦之中 那你這個原本的模型呢 就會立刻學會了這些Email相關的知識 所以就有點像是原本的做法呢 是你真的是刻苦的用功讀書把這些所有知識都學進去 學進去之後你就哇你變得更有知識了這樣子 那另外這個Laura的做法呢 就有點像是那種The Matrix那種 你直接把那個知識包按一鍵直接下載進你的腦袋之中 你自己完全不用去做那些學習 你就直接把知識包Load進你腦袋之中 然後就哇立刻學會武術 哇立刻學會原意之類的whatever 那你如果想知道更多技術細節的話呢 我們知道現在所有這些大型的模型
(50:40~51:40) 他們腦袋的這些權重啊 也就是他們腦袋的這些知識呢 都是用這個矩陣的方式去進行存在電腦裡面嘛 或嚴格來說是Tensor啊 反正他們腦袋裡面就是有一大堆這種數學矩陣 然後你實際在用這個大腦做推論的時候呢 你就是把你的資料變成一個個向量 然後拿這些向量跟這些矩陣做矩陣乘法 就這樣而已 他就在送一些矩陣而已 根本不是什麼什麼魔法這樣 Anyways這個一個Laura的Adapter呢 它其實是兩個小矩陣 兩個小非常非常非常多的矩陣 超級小的矩陣 但這兩個小矩陣乘起來呢 會跟這個模型它的 你想要Tune的權重的矩陣是一樣大的 這個就是一個矩陣 你可以回去再學一下線性代數啦 反正就是一些矩陣分解的一些做法啦 那你今天在Train的時候呢 你就是Train這個Laura的兩個小矩陣而已
(51:40~52:40) 更新他們的權重 然後最後呢就把這兩個小矩陣乘在一起 然後直接用加法加回你的這個 原本模型的大腦的權重裡面 這樣子而已 你在加的時候當然也可以列一個權重啦 就是你要加70%的強度 還是加50%的強度 還是加100%的強度都可以這樣 其實如果你有在玩Stable Diffusion的話 你對於Laura應該就蠻熟悉的 因為這個是非常常見的做法 就是大家要Find Tune一個Stable Diffusion 一個特別的風格的時候 很多人都是用Laura去Tune嘛 對不對 就比如說一個美式漫畫風的Laura 那你今天你只要有一個一般的Stable Diffusion Model 你再把這個Laura加上去 你的這個Stable Diffusion就立刻會產生出 這個美式漫畫風的一個圖片這樣 那蘋果呢他們這次發表的Apple Intelligence 就是非常非常廣泛的使用這個Adapters的概念
(52:40~53:41) 你的手機裡面呢 你只會存一個大信語言模型 但是你會存超級多個不同的Adapters 那他們會這麼做呢 是因為這些模型有非常非常多的事情要做 就是儘管只是在就是輔助寫作這邊呢 就有可能20個不同的Task之類的 有寫Email有把Tone改得更Polite 有把Tone改得更專業 然後也有這個Grammar Check 然後也有Rewrite 有超級超級多種不同的這個Task要做 那你今天如果想要你的模型 每一個Task都做得很好的話 你要嘛就是用一個很大的模型 然後大到任何Task都精通 就像是GPT-4O 你叫GPT-4O做以上的任何一件事情 它都可以做得很好 但Obvious你不行嘛 你要在你的手機的 用可能2GB以內的記憶體去跑 你只能跑大概3Billion左右的模型 那3Billion左右的模型 很難做到就是所有Task都可以做到完美這樣子 那你還有另外一種方法
(53:41~54:43) 就是用傳統的Fine-tuning 你每一個Task你都Fine-tune一個Model出來 然後把這些Model全部存在你的手機裡面 然後真正要用到哪個功能的時候 你就把相對應的Model load到你的Ram裡面 當然你可以這樣做沒錯 但你的儲存空間就會悲劇了 因為這個一個模型就要1.6GB 你是要存20個模型進去 使用者用屁喔 還買個128GB的iPhone回去 就哇靠北怎麼剩下20GB之類的 當然是不能這樣嘛 所以Laura真的是最好的做法 因為蘋果現在只要存一個模型 到你的手機裡面 然後可以存20個不同的Laura 每一個Task都有一個相對應的Laura 那一個Laura 蘋果他們在Technical Report有詳細的寫 他們是用Rank16的Laura 我們知道Rank就是 比較現新代數的概念 有點像這個矩陣的維度有多高 它維度越高它就越複雜 可以存越多知識但也越大嘛 但他們是使用16,Rank16 也就是說
(54:43~55:43) Task的Laura只要10MB左右大 超級小 也就是說今天你只要手機裡面 多存一個10MB的Laura 你就可以讓你的模型多學會做一件事情 這個是非常非常強的 所以我覺得未來啊 不管是Microsoft Copilot Plus PC 還是Google的Android 他們一定都是 如果要在PC或是手機上使用AI的話 應該都是使用Adapter的技術 我覺得蘋果的AI 包括在生日是AI之前 還是生日是AI之後的Apple Intelligence 我覺得我都已經介紹差不多了 接下來我們可以整體的 來聊一聊蘋果的AI這個話題 我也可以給大家一些我自己的看法 首先第一點我想聊的就是 有些人會拿蘋果的AI 來跟Google的AI 或者是OpenAI的AI來做比較 我覺得說你看蘋果落後這麼多 但我自己是覺得 這個比較並非公平的比較
(55:43~56:45) 因為蘋果大家要知道 他們做AI的這個方向呢 從來都跟Google還有OpenAI的這些公司是不一樣的 像是Google的他們的AI研究的組織DeepMind 還有OpenAI的他們的Lab 他們研究AI的目的是要做出AGI 他們是要把AI研究到極致 研究出最強最強的AI 什麼都能做的AI 但Apple的蘋果他們研究AI的方向呢 只是在想說現在有AI這個東西 我們要怎麼樣把AI融入我們的產品 讓我們的產品變得更好 他們是在想要做什麼樣的feature出來而已 他們當然也有在做一些可能跟他們的產品 沒有最直接關係的一些 這個LM的research 但他們也不是為了 就是要try to figure out AGI 在做這些事情 他們是非常非常踏實的去想說 我們現在有這個技術 要怎麼樣把它變得更好 所以我們的產品才可以benefit from this
(56:45~57:48) 所以這個也是為什麼蘋果這麼擁抱開源社群 就是你看他們前面發的那兩篇這個 生日式AI的論文呢 他們是真的非常開放 首先他們有發論文這件事情 就代表他們有開放的心 再來他們在論文裡面 研究過程寫得非常非常詳細 模型的架構全部都寫出來 寫得非常詳細 甚至他們選擇這些架構背後的想法 都有寫出來 他們是盡量開放了 最重要的這一塊 也就是訓練資料他們用哪些這一塊 他們也是沒有講得很清楚 他們其實有講他們的source是哪幾個 但他們有進行一些filter 實際來說是怎麼樣filter 這個我們就不知道了 但他們已經盡量開放了 因為他們就跟meta一樣 對他們來說AI是基礎設施 不是產品 他們是拿來幫自己的產品變得更強的基礎設施 所以說應該開放出去 讓大家集思廣益 一起把這個基礎設施變得更強更強
(57:48~58:49) 之後的蘋果手機才會有更強更強的Apple Intelligence 那再來呢 我也有看到一些針對蘋果這次 跟OpenAI的合作的一些討論 這邊很多的討論呢 蘋果未來會不會自己做一個大型元模型 然後取代掉OpenAI 或者是會不會哪一天把 把OpenAI換成Google Gemini 針對這一題呢 我自己的想法是 我覺得他們不太可能會 自己去做一個LM來取代OpenAI 應該說我覺得他們是會想要怎麼做 但是這麼做是不太實際的 他們會想要這麼做的原因 就是因為蘋果超愛垂直整合 他們任何東西都要垂直整合 都要自己做 然後就是有自己的一個Wall Garden這樣子 就是在自己的這個小花園裡面自己爽 自己的生態系自己爽這樣 所以說他們當然是 能不用別人的東西 能自己做就自己做 但是呢 我覺得這樣子的蘋果呢 也是有妥協的時候 像是他們在什麼東西上妥協
(58:49~59:49) 他們在搜尋引擎上就妥協了 對吧 他們在搜尋引擎這邊是妥協給Google 就是這個Apple 我記得也是有嘗試自己去做過搜尋引擎 但想當然就是沒有 沒辦法像Google做得這麼好 所以說他們這邊就是 讓Google進入他們的Safari這樣 把Google變成Default 然後同時呢 他們也可以就是多賺到一筆錢 而且是很大的一筆錢對不對 這個Google每年都好幾個billion這樣 投給Apple 就是為了要變成Safari的Default搜尋引擎這樣子 所以說這個蘋果還是會妥協的啦 就是假設你自己去做的話 會嚴重的損害到使用者體驗 然後同時呢 別人也會給你錢 那你何樂而不為呢 你就直接用別人的東西吧 所以蘋果在這種情況之下就會妥協 那我覺得這個ChatGPT的這個API的部分呢 有可能也是蘋果會妥協的一點 因為他們要自己去做一個 最強的Frontier Model
(59:49~60:49) 太難了啦 追不上的啦 真的不可能啊 他們做出來的模型呢 絕對不可能有GPT4都這麼好 或者是接下來的GPT5之類的 他們絕對追不上的 所以使用者體驗一定是會被損害到一點點 那再來就是有沒有錢賺這邊 我覺得未來也是會有 因為ChatGPT現在還是有點在Figure out 它的Business Model 它就先擴張它的User Base 先讓越來越多人使用他們的服務 之後再想辦法Figure out一個Business Model這樣子 那當他們Figure out這個Business Model之後呢 蘋果就可以抽個三成 抽一下他們的Apple Text 那這個時候呢 他們就是就會也會很舒服 所以說我是覺得 蘋果應該會持續使用現在最厲害的AI模型 去整合到他們的Apple Intelligence裡面 那另外一個補充就是 就目前來看啦 OpenAI跟蘋果的這個Deal呢
(60:49~61:50) 雙方是沒有給錢的啦 就蘋果沒有付錢叫OpenAI來 那OpenAI也很開心去成為Apple Intelligence一部分這樣子 那再來呢我想聊一點就是 從我們幾個禮拜前看到這個Copilot Plus PC 再看到這個Apple Intelligence 我覺得我們可以說 AI PC跟AI手機的業界標準已經形成了 那這套標準呢就是有三個重點 第一個混合運算 就是你小的事情簡單的事情 就由這個裝置本地的模型去直接處理 然後比較困難的事情呢 你就直接發送Request到雲端 那這個雲端跟邊緣的混合運算這樣 那第二點呢就是 以LLM Transformer跟Diffusion Model為主 那當然就是Transformer也不只包括LLM 有可能像是語音辨識ASR的模型 也是一個Transformer 但反正就是Transformer跟Diffusion Model
(61:50~62:54) Transformer主要負責跟語言相關的 Diffusion Model主要負責跟圖像相關的 大部分就是這兩個模型跑在邊緣 那第三個呢就是一個向量資料庫 或者是你說一個Semantic Index 一個語意的一個Index這樣子 那這個Copilot Plus PC有 我已經介紹過了 那這次Apple Intelligence他們也有 就是這些Apple Intelligence這些Siri呢 之所以會Context Aware 就是因為他把很多你自己個人的資料 全部都向量化然後存起來 然後這個Siri就可以很快的去做Retrieval的動作 那這邊具體來說是怎麼做的 你繼續聽我的EP41 我有做一個蠻詳細的解釋這樣 所以這個就是現在AI PC AI手機的業界標準 一個混合運算 LM跟Diffusion Base 然後一個向量資料庫 然後除此之外可能有Adapters Adapters可能也成為第四個標準這樣 我不知道 那我覺得接下來的下一步呢會是這樣
(62:54~63:56) 首先第一步會先等到大家都取得權限 因為其實現在很多的這些AI PC AI手機的功能 都還不開放啦 就很多還在開發中 像蘋果這次WWDC宣布的一大堆Apple Intelligence功能 都還不開放都還在開發中 所以說要等到這些功能慢慢Roll out給所有人 然後大家都開始使用 那大家開始使用之後呢就會開始有使用者反饋 然後這些反饋會幫助這些基礎設施疊帶 這些模型會變得更強會被Tune得更好 然後這個向量資料庫的Retrieval會變得更好 之類的然後慢慢變得更強更強 然後同時呢我們也會看到更多第三方應用程式的加入 你現在從這個Copilot Plus PC 你看到的這些微軟發表的所有功能呢 都是他們自己開發出來的軟體 各自開發出來的功能 蘋果的Apple Intelligence現在發布的 也全部都是他們自己開發的 但第三方軟體也可以使用這些AI PC AI手機的基礎設施
(63:56~64:56) 也可以用這些基礎設施去用這些模型 把他們加入他們的產品中 用這個向量資料庫把這個Siri變得更強之類的 所以接下來我們一定會看到越來越多的這些軟體呢 都出了AI版 就是專門在AI PC或是AI手機上面跑的版本 比如說Notion可能有個AI版的Notion 只有在某一種作業系統以上才可以使用 然後這個每個軟體都有個AI版AI版 那我覺得儘管這些AI的功能在這些軟體裡面呢 並不是一個非常重大的體驗提升 就是它不會讓AI版的Notion不會真的比沒有AI的強非常非常多 但它絕對會比較好一點點 那如果今天所有軟體呢 它都有AI版 然後體驗都比較好一點點 那整合起來他們就會跟沒有AI能力的PC或是手機差非常非常的多 所以說我覺得這個AI PC AI手機絕對是未來的趨勢
(64:56~65:56) 那你要定義它AI PC AI手機 你可以從硬體這邊定義 也可以用我剛剛講的業界標準去做定義 有個Hybrid、LM Diffusion Model、一個限量的資料庫這樣子 反正當越來越多人使用AI PC AI手機呢 越來越多軟體開發商會開發AI版的軟體 那越來越多AI版的軟體出現之後呢 這個AI PC AI手機的體驗就變好更多 變好越多 這個差別就越大 差別就越大 就越來越多人會有AI PC跟AI手機 然後這個輪迴就不斷的輪迴不斷的輪迴 直到最後呢 就大家的手機大家的筆電全部都是AI的 那這個蘋果跟AI的話題呢 我們就先聊到這邊吧 那我一開始有跟大家承諾說 我必須要給大家一個Starship的update嘛 那現在就給這個update 那這邊當然我們有很多時間可以詳談這個話題啊
(65:56~66:58) 但我就用一個爆新聞的方式跟大家講一下 反正就是我們知道馬斯克的SpaceX這間公司呢 在做火箭的公司 他們有一艘火箭叫做Starship 這個Starship是有史以來最大的火箭 最大最重然後推力最強的一艘火箭這樣子 那這個火箭它原本被建造的目的是 要幫助人類殖民火星 馬斯克的夢想這樣 就是他的夢想是要回國 回到他的出生地這樣子 所以說要建造Starship 那他這個Starship呢 目前還在這個開發階段 然後他已經進行了四次的試飛 然後第四次試飛呢是上禮拜這樣子 所以說我覺得這個今天的Podcast要講一下 那這個Starship呢 他在每一次的試飛他都進步非常非常的多 我真的覺得這個SpaceX很厲害很厲害 他們就是依照馬斯克這個
(66:58~67:59) 透過不但炸毀火箭來進步的這個想法 不斷迭代的這個理念去建造火箭 然後他們真的是非常非常厲害的一個Team 好那前三次試飛的結果 我在這個之前的Podcast我都有講到 你們大家可以自己去滑標題 滑標題找出那兩集這樣子 但第四次試飛呢一樣是一個超級大的成功 那他們這次試飛他們 特別要去測試的一個功能呢 就是他們Booster的Landing Burn 就是他們的緩降海面這樣子 那他們有沒有做到呢 有他們做到了 我那時候看到的是真的是起雞皮疙瘩 非常非常的驚人啊 那這件事情呢稍微解釋一下背後的概念 就是Starship這艘火箭呢 有一個非常非常重要的功能 就是它必須要能夠完全重複利用 那所謂的完全重複利用呢 就是兩節在發射出去之後呢 都要可以完全被回收 然後能夠被重複利用
(67:59~69:00) 那這件事情是我們就是之前從來沒有看過的 人類歷史上沒有一個 這麼大的火箭可以重複利用 能夠重複完全重複利用的火箭都不存在了 在這之前最能夠重複利用的火箭 就是馬斯克的Falcon 9 它可以80%重複利用 它的第一階段 或者是你說它的Booster 是可以重複的使用的 但它上面那一階這個機艙是要拋棄的 但這個Starship呢 一樣是兩個階段組成的嘛 一個Booster跟上面的他們叫做Starship 它這兩個階段都要全部重複利用 那在這次IFT-4 也就是他們第四次的試飛呢 他們真的完成了這個Booster的Landing Burn 也就是說這個Booster呢 它把這個Starship送出去外太空之後呢 它直接往回飛 飛到指定的位置 然後直接降落海面 然後它是緩降海面喔 就是它在接近海面的時候呢 它會除了把自己翻正以外
(69:00~70:00) 它會開始就是噴火 讓它降低它的速度 直到它最後在幾乎是精準的位置 以0的速度在海面上停著 那這很明顯的是一個大成功嘛 因為上一次這個Booster在接近的海面的時候呢 就直接爆炸了 那這次竟然有停 就是在海面上緩降 然後最後才落海 而且是在幾乎是精準的位置做到這件事情 真的是非常非常厲害 那馬斯克也說 馬斯克也說 下一次他們要嘗試在發射台去回收Booster 因為這是他們未來的願景 就是希望可以這個Booster發射出去之後呢 直接回到發射台 然後直接再發射下一台上去 這是他們的這個願景 那他們 馬斯克說下一次要測試這個 SpaceX沒有講 所以不確定會不會 反正這Booster這邊是一個大成功 那Starship這邊也是一個大成功
(70:00~71:03) 那上一次這個Starship要回到地表的過程中呢 他沒過多久直接在高空中就直接燒掉了 因為他承受不住這個上千度攝氏的高溫嘛 那這一次呢 Starship竟然也成功的來到了海面 一直到海面都還有訊號 超級厲害都沒有爆炸 也沒有被燒掉 當然他們有一些部分是有被燒掉的啦 但他們有到海面已經很厲害 而且似乎還有嘗試Landing Burn 但是應該是沒有成功這樣子 所以說呢總而言之 這一次第四次的星見是非呢 真的是一個大成功 然後我們真的又是離火星殖民又近了一步 我覺得真的在有生之年 是真的有機會可以踏上火星的耶 這很扯耶 儘管我不能親自踏上 我也能夠看到火星的一個人類殖民地長什麼樣子 真的是很期待那一天的來臨喔 好那你如果喜歡今天這集Podcast的內容 或是覺得這個內容真的對你有幫助 你有學到東西的話
(71:03~71:42) 你可以幫我把這個科技量分享給你的朋友們 不管是你在IG上分享 在臉書上分享 還是在Threads上面分享 就是告訴你的朋友們 有科技量這個Podcast 我的科技量呢才可以持續做下去 因為做了這麼多集都做了快一年了 我完全都沒有收過大家一毛錢的費用嘛 純粹是靠贊助 有你們的分享才有更多人來聽 有更多人來聽我才能持續的去接贊助 同時也在這邊感謝一下 我們今天的贊助商NordVPN 這個最好的VPN 大家可以用這個科技量的專屬連結去申請一下 好那本集就到這邊結束啦 最後就祝大家有個愉快的一周
