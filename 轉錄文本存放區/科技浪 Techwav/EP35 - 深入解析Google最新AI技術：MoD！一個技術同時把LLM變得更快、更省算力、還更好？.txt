(00:00~01:04) 哈囉大家好 歡迎收聽科技浪 我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂 但是又深入的方式 帶你了解時下最火的科技話題 本集節目由Digitimes贊助播出 今天要介紹的是在這個月底有的一場AI博覽會 AI Expo 這個博覽會主要由Digitimes財團法人人工智慧科技基金會 以及IC之營主辦 會在今年的4月24到26日在台北圓山花博鎮宴館舉行 AI Expo是全台灣最大的人工智慧博覽會 今年的主題是Ivolution全面進化 有聚焦五大領域 包括智慧工廠、AI城市、企業治理、商業生活、聲明科學等 會共同討論最新的話題
(01:04~02:04) 雲端儲存、晶片運算、機器視覺、工業電腦、軟體服務解決方案等 同時也會探討到一些AI Plus的概念 包括區塊鏈技術、資訊安全、人才與能源議題等 在三天的AI Expo當中 有各式各樣大大小小的活動在進行 首先他們有大師Keynote的部分 他們有邀請到一些大師來進行專題的演講 像是AWS台灣暨香港總經理的王定凱 還有美商高通國際股份有限公司的副總裁劉思泰 還有AMD台灣區的資深業務副總經理林建成 同時他們也有上百家的從大廠 像是AWS Google Cloud這種大廠 到新創公司的這些各種廠商 會在現場擺攤介紹他們的解決方案 你也可以去跟他們建立很多的connection 除了這些以外他們還有很多的其他活動
(02:04~03:04) 像是他們有AI創新獎的決賽 這是一個大專院校生參加的AI比賽 他們會在現場進行決賽的簡報 然後還有未來舞台一系列的演講跟交流活動 然後還有IC之音的現場直播 除此之外Digitimes還有主辦一個活動 叫做用AI支持愛 或是用愛支持愛 他們會為每一位參加者都捐出10塊錢 給伊甸基金會來守護偏鄉孩童的健康成長 那你如果想參加全台灣最大的AI博覽會 我會把報名連結放在資訊欄裡面 大家可以點連結進去免費進行報名 本集業配就到這邊結束謝謝Digitimes的贊助 好那上禮拜呢在這個AI的領域啊 我覺得是有很多最新的發展的 都是一些我覺得不算最大的新聞 就是可能GPT5這種等級的超級大新聞 但也都是蠻有料的這些新聞這些發展
(03:04~04:04) 但我覺得大多數人可能沒有感覺到 上禮拜有很多發展 因為這些發展都是比較技術面的 所以說通常就是可能Machine Learning Community的人會 或是AI Engineering Community的人會比較知道這樣 那這個一般媒體呢不會 然後也沒有能力去報這些東西 所以今天呢我們科技浪Podcast就是要幫大家 趕上這一波最新的發展了解現在大家 把這個大型元模型做到了什麼程度 然後有什麼最新的技術出來這樣 這邊我覺得是蠻有料的喔 那我覺得在講這些AI新聞之前啊 有一個網路上蠻熱門的一個話題 就是Devon的炎上事件 那大家都應該還記得有一個 蠻轟動全球的一個AI工具 叫做Devon的出現嘛 那這個Devon他們是號稱他是由此以來的 第一個AI軟體工程師
(04:04~05:06) 那我們科技浪也有花一集深入的來聊這個東西 你可以去聽科技浪的EP31 他就是一個會自己去寫code 會去debug會去就是 跑測試去看他寫出來的程式 這樣子的一個AI然後他在寫這些 他在做這些事情的過程中呢他也會使用瀏覽器去查資料 然後也會使用這個電腦的終端機 也就是這個電腦的command line就是這個 直接跟電腦下指令的這個介面這樣 也就是說呢他基本上就是一個junior的 要做的所有事情他都會做 然後要用的所有工具他都會用 這樣子的一個AIagentAI工具這樣 那他這次沿上是沿上什麼呢 就是最近有一個youtuber他拍了一支影片說要 揭穿Devon的謊言然後在這影片裡面呢 他基本上就是把那個Devon在他的demo影片 裡面做的那個專案拿下來自己做了一遍 然後在整個過程中呢跳出所有Devon 做的不好的地方
(05:06~06:08) 那就像是第一個他的deliverable不complete 那要知道他在demo裡面做的那個工作 他是一個upwork的一個task upwork就是國外的一個有點像是 你要outsource你的工作到網路上 給其他那些freelancer做的一個網站這樣 就是你可能有一些 一個獨立的一個軟體工程的專案然後你不想 為他請一個全職的軟體工程師你就把這個工作呢 放到upwork上面 那他在demo影片裡面呢 Devon就是實際的去做了這個upwork的工作這樣 但是這個youtuber就說Devon 他給出來的這個deliverable 也就是他做出來的這個結果呢 是不complete的是沒有辦法完成這個upwork的工作的 為什麼呢因為你要真正完成一個upwork的工作 你並不是寫出code就好 並不是debug完跑出來就ok了 你要去完整的交代這個客戶所有的需求 就是包括對於這個客戶來說
(06:08~07:08) cost跟speed哪一個是比較重要的 就是你要怎麼樣權衡這兩者 should this always be up 他是要一直跑這個東西嗎他實際的使用狀況究竟是如何 然後你的input跟output的資料形態 要怎麼樣去表示這個客戶才可以用得最順 然後除此之外有很多很多這些比較 要跟客戶去溝通的一些事項 然後這個Devon都沒有做到嘛 然後除此之外呢Devon也很常 有幻覺會寫出很糟糕的code 然後明明人家就有一個 就是inference的file叫做infer 但Devon不用他還特地去寫另外一個inference的file 然後在寫的過程中裡面又產生一堆bug 然後他很緩很多時間在debug 他自己寫出來的那些bug 然後最後一點就是Devon花了很長的時間 才把這件事情做完可能甚至有跨日 可能將近24小時這樣
(07:08~08:08) 那他自己去做這個專案的時候呢 他只花了大概36分鐘那這影片出來之後呢 立刻就爆紅了然後一大堆人呢就是 開始在網路上嘲笑Devon也好然後罵Devon 也好就是說這個東西呢是沒有什麼特別 大用處然後各位軟體工程師們 我們的工作安全啦我們不會被這種東西 這種爛東西給取代這樣那我自己看了很多 這些言論我有兩個想法第一個想法呢 就是我覺得他們看錯方向然後第二個想法呢 就是我覺得他們看得不夠遠他們的眼光太過 狹隘第一個我覺得他們看錯方向的地方 就是在於首先像這個youtuber 他是拿他自己做這個專案的過程去跟Devon 做這個專案的過程進行比較但他真正 應該比的是他自己跟一個 使用Devon的軟體工程師進行比較 因為這個才真正符合大家會使用 這個Devon的實際情境對吧 當這個Devon釋出的時候呢你真的以為公司
(08:08~09:08) 會讓Devon自己去跑然後自己去就是 取代目前公司所有的junior south engineer嗎不可能嘛你上面一定有人類 人類在我們把它稱作human in the loop 就是有人在監管這些Devon在看他們 做的所有事情然後在一些必要的時候在一些 可能他們卡關的時候去幫他們修改方向 這樣那這邊我這個科技量的ep31 也有講到就是我覺得短期之內啊 當然這個現在AI發展的速度這麼快 短期是幾年很難講啊但我猜可能 三年之內我們這些所有的AI agent 都還是會需要human in the loop還是會需要 人類去監管他們去控制他們這樣所以 那些批評的人如果有看到這一點如果有用這個角度 在看事情他們就不會說出什麼Devon的 deliverable不完整兄弟這個deliverable 的完整性是人類在顧的這個是 人類需要去引導Devon去做出來的事情 這個在實際的一個工作的情況之中呢
(09:08~10:08) 是不會發生的因為這是人類的工作 然後絕大多數大概99%這些批評的人 都沒有用過DevonDevon現在是在 只有非常非常少量的人可以進行測試 然後其中一個人呢就是SwicksSwicks 是這個矽谷的AI engineering圈子中 非常非常備受尊敬的一個AI engineer 那我追蹤他很久了他的內容我都會 看他是非常有料的一個人大家 就是想去多了解他的話可以去聽他的 AI engineering的podcast叫做Latent Space Pod 從名字就可以聽得出來是一個 非常machine learning technical的一個podcast 我覺得超棒的我很常聽 反正回到SwicksSwicks就是少數的 有使用Devon的那個人這個是 Scott Wu 就是這個Devon這間公司的CEO 直接給Swicks這個access使用Devon這樣 然後這個Swicks他就有po一則X文他說 他使用Devon做到了什麼事情
(10:08~11:08) 他有寫Swift的程式碼然後有實際上架到 Apple App Store他有這個更改 前端的架構把他從React改到Svelte然後 他有後端的一些Data engineering的東西 他有做full stack的project一個murned project 然後他有做這個主動產生 GitHub上面的PR也就是這個 Poll request那這些都是非常有用的事情 那整個過程中Swicks他就是 他自己寫說他是Active as a Semi-technical supervisor就是一個 有點半technical的半技術的 一個主管這樣子 那因為他剛剛講的他用到的這些 所有的技術有一半他都沒有用過 一半的這些程式語言他沒寫過然後完全沒有 看過但他就是當作一個半技術的 一個主管去監督Devon去把 這些事情全部做到這樣他說他真的感覺 他就是一個PM或是一個比較technical的
(11:08~12:08) PM然後就是在監督五個 軟體工程師在寫code就是這樣他就是有這種 感覺然後成果他是非常滿意的他覺得 是非常厲害的當然過程中很多的 批評是正確的就是他很慢沒錯 他超級慢而且他很可能 非常的貴因為他不知道又 就是要發出幾千幾萬個這個 GPT-4的API code然後累積起來 是非常非常貴的為什麼會發API code呢這個 你就可以去聽這個科技量的EP31我有講解 那他這個Devon會不會寫錯code 他當然會寫錯code他會不會自己寫了code然後有Bug 還自己去debug他自己寫的code當然也會 但整體來說Swix是非常被Devon經驗的 然後他也有說Devon是他看過最厲害的 Coding agent AI coding agent 那所以說我覺得那些批評的人呢有一點點 看錯Devon的方向然後也有一點 這個低估了Devon這樣那我另外一個想法呢
(12:08~13:08) 就是我覺得他們看得不夠遠就是Devon 他們都說Devon現在做不到 ABCD然後Devon很慢然後Devon會講錯話 所以說呢Devon是沒有用的東西沒錯Devon Devon現在是有這些問題但是這些問題都是可以 被解決的而且是很快就會被解決的 不要說解決啦會被大幅的改善Devon的大腦 就是一個大型圓模型嗎那大型圓模型 有沒有在變聰明有啊有沒有變聰明的很快 很快啊所以說Devon的大腦會依照 這個這個這麼快的速度一直在持續的變聰明 然後再來Devon很慢沒錯 但Devon會不會很快的就變很快會 很多很多的技術是在支持這個更快的AI推論 像是我們今天會講到的Google的其中一個技術呢 就有這個大幅加速AI推論的這個潛力 那這些技術呢大家瘋狂的在開發中 然後他被這些技術被這個 整合進Devon當中呢是遲早的事情 我覺得很多人在討論這些未來的科技
(13:08~14:08) 都有一種Oh wake me up when it's true的這種態度 就是喔又還不是真的 但我覺得OK如果我們今天在討論的是量子電腦 那種可能要二三十年好幾個Decade之後才會發生的事情 那確實沒錯 wake me up when it's true 沒問題但你今天如果在討論AI 你有這種想法就很危險因為這個領域發展 實在是太快了這個幾乎是指數型的成長 你今天覺得不可能做到的事情可能隔幾個月 甚至隔幾個禮拜你就已經可以做到了 那在這種情況之下你可能會覺得 我覺得你不看到AGI這麼遠的東西可以理解 但你至少往外看個一兩年吧 你至少就是要結合一下現在發展的最新趨勢 然後最新的技術然後去 至少看個一兩年內這些模型會 有蠻高的機率可能接近80% 接近90%會做到哪些事情 我覺得這樣子你才能真正完整的去評估 一項技術一個工具的好壞
(14:08~15:08) 意思就是說在變動這麼快的一個領域裡面 你如果不往未來看你如果不往前看 你就已經是落後了因為很快的大家都會到那邊了 好那這個Devon的話題呢我覺得就講到這邊就好了 因為其實講的比預期有一點久 因為我原本的想法呢大概就是講個 兩三分鐘三四分鐘的一個小話題這樣 但沒想到講了十幾分鐘 所以我們趕快來進入過去這一兩個禮拜的 最新AI發展那首先第一個呢 就是OpenAI的GPT-4 Turbo模型變強了 那這個GPT-4 Turbo呢基本上就是GPT-4 的這個進階版啦 那它的Turbo模型呢原本呢 是輸給Anthropic的Claw 3 Opus模型 雖然說只輸一咪咪這樣 但他們最近呢應該在前兩天 他們Train出了一個新版的GPT-4 Turbo模型 是比這個Claw 3 Opus又更強的 尤其是在Coding跟Reasoning
(15:08~16:08) 也就是這個推理能力是變強非常多的 然後也有一些其他的進步像是它講話變得更直接 不會再這麼囉嗦這樣那我自己是這樣 就是從去年不知道可能年中吧 去年五月之類的我就開始訂閱OpenAI的 這個GPT-4了就應該說訂閱ChapGPD Plus 然後使用他們的GPT-4模型這樣 因為從去年五月應該說從去年三月 一直到最近這個GPT-4呢 都是最強的大型元模型 那一直到幾個禮拜前那個Claw 3出來 就真的有一個模型可以打贏GPT-4了 這個他們的Opus最大的這個Claw 3模型呢 在這個Chapbot Arena上面的表現 是比GPT-4好的 所以說呢我就摸摸鼻子訂閱了Anthropic 要用這個Claw 3Opus這樣 但是呢訂閱還不到可能還不到兩個禮拜吧 那這個前幾天呢 GPT-4T又進步了然後這個進步的
(16:08~17:08) 就打贏了Claw嘛所以說我這個Claw 3的 這個訂閱呢又有點想要把它取消 那剛剛講的這些模型呢就是這個GPT-4T 然後Claw 3的Opus然後可能還包含這個 Google的Gemini Ultra或是Gemini 1.5 Pro 他們都是我們所謂的God Level Model 他們就是我們現在全世界最強的那些大型圓模型 那這些大型圓模型有共通點 就是他們全部都是幣圓的 他們全部都沒有公開在網路上給大家 自由下載使用然後大家也不知道 它裡面這個賣的是什麼藥對不對 它的模型架構是什麼然後它用什麼資料 去Train都不知道那開圓模型也就是這些 全部公開透明的在網路上給大家下載 使用的這些模型他們的進展到哪裡呢 這個上禮拜也有一個非常好的進展 嚴格來說應該是一個半禮拜前 一間叫做Cohere的AI公司 它釋出了一個叫做Command R Plus的模型
(17:08~18:08) 那這個Command R Plus的模型 它是它有幾個特點第一個它是開圓的嘛 第二個呢它是RAG Optimized Model 它是專門為RAG設計的 然後是專門在針對這些企業客戶設計的 不是給一般人消費者使用的模型 RAG基本上就是給大型圓模型 外接一個資料庫讓它在回答的時候呢 可以隨時取得最相關資料來輔助回答的技術 我們的頻道也講過很多次了 雖然說最近都還沒有提到這樣 那這個Command R Plus為什麼會講它呢 這是因為這是我Command R Plus 是有史以來第一個打敗GPT-4的開圓模型 雖然說它打敗的是最弱的GPT-4 它是打敗GPT-40314 也就是最一開始出來的那一版GPT-4 2013年 講錯2023年3月14號出來的那一版GPT-4 它只打敗它
(18:08~19:08) 但是這也算是開圓社群的一個小里程碑了 尤其是它不只是它的一般回答可以打敗GPT-4 它還專門為了RAG設計 所以說在RAG的使用上呢 它是更強的 雖然說也有一些災情傳出來 但可能也是比較個案的部分這樣 除此之外呢Mistral也就是法國的這間 明星AI公司呢他們也推出了他們的新模型 叫做這個Mistral 8X22B 這個當然就是它Mistral 8X7B的進階版 是更大的一個MOE Mistral of Experts的模型 這個MOE模型具體來說是什麼 我們今天正好待會會講到 我們等一下要分析Google的論文的時候呢 會帶到這一點 到時候你聽不懂的話到時候就可以認真聽一下 反正這個Mistral的模型呢 每次推出呢
(19:08~20:08) 大家都感到非常興奮 而且都會開始討論 都會迫不及待開始使用 因為他們每次推出的模型都是品質非常好的模型 Mistral 8X22B呢因為它才剛出來沒多久 實在是沒有什麼相關的資訊 所以說這邊就也不聊太多了 但是我自己會比較想知道就是 哪一個比較好 DBRX就是最近Databricks推出的一個新的MOE模型 那我想要比較這兩者是因為 這個DBRX它的參數數量呢 跟這個Mistral 8X7B是8X22B是差不多的 所以說會想知道他們兩個人是誰比較好這樣 那你如果在想這個Mistral 它究竟需要多強大的硬體設備才跑得動的話 可以給你一個參考點就是 有人使用這個M3 Max的MacBook Pro 然後配備128GB的RAM 就可以跑得動這個Mistral的模型了
(20:08~21:08) 它是跑4bit quantization這樣 那開源模型這邊呢最後還有一個很值得期待的 就是臉書的LAMA 3終於要出來了 這個是最一開始是The Information 在爆料的事情 但之後呢臉書的官方也出來承認說 這個LAMA 3會在下一個月出來 然後甚至是接下來這一兩個禮拜呢 它就會先出一個小型的模型了 那這個就是萬眾矚目的 開源社群的希望嘛 因為臉書的模型怎麼可以不期待一下 因為這個LAMA 3應該一樣跟LAMA 2一樣 是一個開源的模型然後這個臉書呢 最近也是瘋狂在買這些GPU嘛 所以說他們有很強大的算力 這個竹克伯一月就出來說 我們今年呢年底呢我們會有將近 60萬張H100 GPU的算力 這個NVIDIA的H100的GPU
(21:08~22:08) 他們有60萬張 所以說是超級超級GPU rich的一個 的一個一間公司喔 就是以他們這個完全沒有雲端部門來說 然後絕大部分的這些算力都是會拿來做 AI的研究AI模型的開發 他們自己這個在跑社群媒體 的算法的時候確實也會有一些GPU的運算 的需求就是這個推薦的算法呢 它中間都有一個這個神經網路的步驟啦 你還是要算它但是我覺得應該是用不到H100 他們的這種神經網路跟生成式AI的那種是 非常不一樣的他們是小很多的 同時呢他們也有自己開發自己的晶片在做這件事情 就是他們有這個MTIA的 晶片嘛然後尤其他們最近才剛出這個 MTIA V2應該是 幾天前才剛出來的這也算是一個 大新聞算說對於多數人是沒有影響的 因為他這個晶片不會拿去賣也不會拿去租
(22:08~23:08) 他就是完全是拿來算自家的這個社群媒體 的算法而已所以說就是一個 就是一個internal tool nobody cares 反正回來啦我在講的就是他們的GPU 很多有35萬張以上的 H100然後總共加起來 有超過等同於60萬張H100的算力 然後這大部分的這些算力呢 都是會拿來算AI所以呢我們就期待這個 臉書LAMA3的表現吧到時候出來呢 想當然我一定會做一集科技浪來深入的 研究他所以大家就可以持續關注科技浪 好那以上呢就是一些近期的 這些AI模型的發展啦但我們接下來來講 更細的我們來講到AI模型技術的進步 那這邊當然就是要講到Google最近研發出來的 最新技術Mixer of Depth 那其實Google DeepMind也就是這個Google的 AI部門他們的paper很多啦 一天到晚都在發然後每一篇呢
(23:08~24:08) 其實都還蠻有料的但是我並不會 每一篇都介紹給大家我會介紹給大家的 一定都是那些有最大影響力的 或者是討論度最高的應該說這兩者之間 也有很大的關聯啦就是有很大影響力 討論度才會高嘛那這個Mixer of Depth 我覺得就是一個非常重要的技術然後他討論度 也是非常的高雖然說主要是在這個 Machine Learning的圈子討論度比較高跨出圈子 其實沒有很多人在討論這個 應該說大部分人都不知道但就是 至少圈子裡面的人是還算蠻轟動的這樣 好那我們就開始介紹吧這個Mixer of Depth 是什麼樣子的一個技術呢我先從 最高層次最白化的方式來介紹好了 首先他能做到什麼事情他能夠讓你在 訓練大型圓模型的時候節省更多 算力然後訓練的更快而且訓練 出更好的模型你沒有聽錯喔 他是一次全餐直接送給你不但
(24:08~25:09) 更快還更節省算力然後還訓練的 更好然後在使用上也就是這個大型圓模型 的推論上也是可以用這個技術讓你在 推論的過程更節省算力然後更快那聽到 這裡你應該就知道這個技術為什麼會紅了吧 因為他真的是太厲害了就是在這個 大型圓模型三個最重要的面向上面 他都可以帶來優化那他究竟是怎麼做到 這件事情的呢他的核心理念就是跳過 這個模型的某一些部分的運算不做 那每一個字他跳過的部分也是不一樣的 我們知道這些大型圓模型在做運算的時候 他是一個字一個字在算嘛你看 TragiBT不是一個字一個字吐出來嗎 那這個Mixer of Depth用在大型圓模型上面呢 就是讓他在運算的時候呢有一些字 他是會用到整個大型圓模型在做運算 有一些字呢他只用這個模型的某幾個部分 在做運算而已嚴格來說是某幾個 Layer我們知道這些大型圓模型都是
(25:09~26:09) 有很多很多的Layer組成的嘛應該說 深度學習都是這樣大型圓模型呢 是甚至是AI的一種那甚至是AI呢 是深度學習的一種那深度學習呢 為什麼叫深度學習呢就是因為他有 就是因為他有很多很多層嘛 那這個一層是什麼概念呢這個一層呢 你可以把它想像成他在做的事情就是兩件事 第一件就是從資料中提取出重要的資訊 我們專有名詞叫做Feature Extraction 然後第二件事呢就是學習 就是從這些含有重要資訊的這些資料之中呢 嘗試學出一些規律來這樣 好那這個每一種深度學習架構 每一種深度學習架構他都是很多很多層嘛 剛剛有說那每一種深度學習的架構 他每一層裡面的Component裡面的 組成成分就是會有一點不一樣 然後通常不一樣的地方就是在你怎麼樣提取出 重要資訊的這個部分而已學習的部分呢
(26:09~27:09) 就大家都差不多就是一個神經網路 這樣或是更精準的名詞呢你會把它 稱作一個MLP Multi-layer Perceptron 但這個詞是比較你可能看論文你才會遇到的這種詞 那我相信很多人應該到現在已經知道了 就是這些大學院模型呢 全部都是使用一個叫做Transformer的深度學習架構 對吧那這個一個Transformer的Layer一樣 就是一部分的這個零組件呢 這些Component是在做Feature Extraction 提取出重要資訊另外一部分呢 就是學習的部分這樣好那 今天呢你一個Transformer Model你在學的時候 不管你在學還是在訓練的時候啦你在運算這個 模型的時候你一串文字這樣子通過 這個Layer的時候這個Layer呢就是會用一些 像是Positional encoding跟Multi-head self-attention的方法 我相信很多人應該都聽過這個 2017年的一篇Paper叫 Attention is all you need對不對你只需要
(27:09~28:09) 注意力機制就好了那我剛講的這個 Multi-head self-attention就是這篇論文在講的這個Attention 這個也就是提取 從資料裡面提取重要資訊的方法 那他先用完這些方法提取出很多重要資訊之後 再把這個附含了重要資訊的這些 資料呢丟到一個神經網路當中 那這個神經網路呢就會在裡面 透過它非常非常多的神經元 互相連結然後嘗試去 學出一些規律這樣喔應該不是說 就是學習而已你假設你今天在訓練這個 模型的時候你就是在靠這些神經網路在 學習但假設你今天是在使用這個模型的時候 這些神經網路就不用學了他們就是靠他們 學出來的那些知識在進行判斷 在進行預測預測下一個字會是什麼 這樣好那我說學習 其實也並不是最精準的講法因為 最精準的講法是它是先
(28:09~29:09) Forepass完了之後再透過Backpropagation 去把這個gradients給push到 它的神經網路裡面這樣講下去 就太技術了但反正你要記得就是 這個神經網路你在訓練的時候呢它就是幫你 學習然後你在這個使用的時候呢 它就是透過它學習出來的這些知識 去幫你做判斷然後學完了之後呢 這個神經網路之後會再把這串文字給 吐出來吐出來之後誰接 下一個layer接下一個layer做一樣的事情 就是用Position Encoding Multi-head self-attention 去這樣子然後再一個MLP 去做運算這樣那一個大型元模型 大概就是幾十個甚至上百個 這樣子的Transformer layers這樣 像是這個LAMA2的7B模型 它就有32個Transformer layers 好我們回到這個Mixer of Depth 它的核心概念就是你在計算
(29:09~30:09) 每一個Token的時候你會用到的layers 是不一樣的那在一般的模型 沒有Mixer of Depth的這種大型元模型的 裡面呢它運算的方法就是 每一個Token都是每一個layer都要pass過 意思就是說它在算這個Token的時候 我們說Token A的時候它要算出Token A的時候 它要把Token A前面的整串文字 pass過32個layer 每一個layer從第一層pass到最後一層 然後它才可以算得出這個Token A這樣 但是你今天如果有使用Mixer of Depth的技術 它可以它會自己去決定 這個Token A它要用哪幾層去做 這個運算然後有一些層數 它會activate有一些層數它就會直接跳過 就不算了就比如說它在算Token A的時候 它只用單數層就是只用1 3 5 7 到31它只用這一些層數 然後雙數層它直接一律跳過
(30:09~31:09) 那這樣子會發生什麼事呢第一個你的運算量 直接減半對不對因為你只用了一半的層數 所以你運算量當然減半然後第二個 你會算得很快為什麼一樣啊因為一半的 層數都被你跳掉了嘛你這樣當然會算得很快 然後你要知道它節省的算力是非常可觀的喔 就是假設你綜合下來 就是減少50%的算力好了你訓練一個 大型圓模型你要花多少的算力多少 MegaWatts的能量你可以直接節省一半 這是非常非常厲害的一件事然後我剛剛有說 這個Mixer of Depth它厲害的地方不只是 它可以節省算力跟算得更快 它還可以算得更好 它可以讓你的訓練效果變得更好 但這個我覺得應該是會讓有一些 有一些人就是感到一頭霧水就是你明明 節省了這麼多算力你應該是要犧牲掉 一點點成效啊為什麼它反而成效變得更好了呢 這邊我們待會再講我們先把這個Mixer of Depth
(31:09~32:09) 的機制給解釋清楚 那接下來一個問題呢就是你它是 它是怎麼樣做到這個怎麼樣去決定 哪一個Token以及哪一些Layer 要被這個Token給跳掉的呢那它的做法非常簡單 就是在一些選定的層數前面 放一個Router那這個Router的工作呢 就是去判斷說現在要進來的這一串 文字這個Sequence of Tokens這些Tokens 有哪一些Token我要讓它過 哪一些Token我直接讓它跳過我然後這些Router 本身也是要靠資料去學出來的它去學說 對於我這個Layer來說 通常哪一些Token要過比較好 哪一些Token其實不用過我那這邊就有兩個設定可以調 或者是就是比較技術的人會講說 有兩個超參數可以調一個就是 你要在哪些Layer上面放這個Router 另外一個就是一個Router要讓 多少的Token過那他們
(32:09~33:09) 當然是測試了很多種不同的組合但他們測試到 最好的就是他們讓一半的Layer上面 都放一個Router然後每一個Router呢 會讓12.5%的Tokens全過 然後剩下的80幾%的Token全部都直接跳過 然後根據他們這個設定呢你大家自己也是可以 算一下反正它大概就是省了大概 40幾%的這個算力這樣 然後整個訓練的過程呢也快了60% 那這個訓練出來的成果呢也是比較好的 那現在呢我覺得是時候來解釋一下 到底為什麼它訓練出來的成果反而還比較好 真的很犯規耶用人家50到60%的 算力然後比人家快60%竟然還比人家好 那這個答案呢就是 我不知道就是論文裡面也沒有講 那我相信這個Researcher呢他們 本人應該也都不知道應該說他們可能有 各自的猜想但是他們沒有一個科學的方法可以 證明這件事情因為這些神經網路
(33:09~34:09) 這些AI真的都是黑盒子 它裡面幾百億甚至幾千億的這些 參數這些數字然後做一大堆的矩陣運算 到底有什麼意義為什麼我們完全不知道 但It works it just works它就是 我也不知道它為什麼要算這些數學但它就是可以算出 一首詩它就是可以算出一個拒絕性 但儘管我們沒有這個確定的答案我們還是可以依照 我們對於這些模型的一些粗淺的了解 去進行猜測去找出一些假說這樣 那我沒有觀察到像是在一些 電腦視覺的模型上就比如說 一個Convolutional Neural Networks也就是說它是在 判斷一個物體是什麼的那種 AI模型在他們身上 我們有發現說它每一個層它每一個 它在學的東西其實是不太一樣的 就是比較早期比較前面的這些Layer 它可能是在抓一些圖像中的一些 零零角角一些邊
(34:09~35:09) 這樣子的非常零碎的這些資訊 然後在中間的這些Layer它會從前面的這些 抓出來的這些零零角角慢慢學出一些形狀 它會知道哪些零零角角組成 怎麼樣排列會組成什麼樣的形狀這樣 然後在後面一點的Layer這些形狀 會慢慢組成物件它會學習 要怎麼從這些形狀裡面找出一些 物件這樣然後最後面的Layer 就是直接判斷這個物件是什麼物件 它是一隻貓它是一個花瓶這樣子 好那這個我相信 Transformer在做的事情是差不多的 它32個Layer或是更多Layer它每一層 它其實是在學不同層級的東西 不同層級的概念比如說我隨便亂講 可能前面有幾層是在決定它要給 就是什麼樣子的 哪一種語言的回答然後再來 它要給出什麼樣子的回答是一
(35:09~36:09) 一封書信還是這個一段歌詞 這樣子的感覺然後後面有幾層 是在決定你的語氣然後接近 最後面的那幾層是在決定 最精準的那個字最精準的用字 在這種情況之下每一個字它可能 只有某幾層Layer對它來說是最重要的 甚至你如果參與了 其他的Layer它可能會被誤導 給個例子好了假設今天你在 訓練大型元模型的時候使用的是一個專業 書信的文本你現在訓練到這一句話 它下一個正確的Token是一個驚嘆號 那通常在專業書信裡面驚嘆號不會 出現它是一個比較罕見的存在 假設今天驚嘆號前面的這句話 全部的Layer都Pass過那它Pass到 可能要決定這個 要給出哪一種答案的Layer它就決定 說我們現在寫的是一個專業書信
(36:09~37:09) 所以說我們下一個字就是要給出一個專業書信 通常就不是驚嘆號 這個Layer就把驚嘆號的可能性 給減弱了然後最後它就算出 不是驚嘆號它可能算出一個句號 但其實正確答案是驚嘆號 假設今天這些Layer可以選擇要不要吃這個Token的話 今天這個在選擇 要給出哪一種答案的Layer它就選擇 我不要接這個Token給其他的Layer處理 然後誰處理到了 處理語氣的那個Layer處理到了 那處理語氣的那個Layer就覺得 目前的語氣好像是需要加一個驚嘆號的 它就增加了驚嘆號出現的機率 然後最後這個機率夠高 它最後的答案就是驚嘆號 然後就是這個正確的答案 所以有時候這些Layer可以自己選擇要不要接的時候 然後就給最適合處理的那些Layer
(37:09~38:09) 當然這以上全部都是我自己的假說 完全沒有經過任何科學的認證 那這邊呢目前來看 也是沒有一個很可信的 一個科學方法去把這件事情 解釋得很清楚但是 Explainable AI是一個很多學者 都在研究的領域那如果這個領域未來有突破 我們可能就真的知道為什麼這個Mixer of Depth 會表現得比較好但目前啊 我覺得應該就是類似這樣子的情況在發生 我覺得這個就是機器學習很 很美麗但是又很討人厭的地方 就是它有時候真的是 你有點像是變魔法一樣 就像是我前一陣子在訪問Google的 傑出科學家紀懷欣的時候他不就說了嗎 他說很多人覺得這個Deep Learning像是Alchemist 這些Machine Learning的人像是Alchemist 他們都是煉金術師
(38:09~39:10) 他們也不確定自己在搞的這個東西有沒有用 但是搞出來有用那你之後就都這樣搞這樣 所以說不管這個Mixer of Depth 它究竟為什麼會比較好到底是不是 跟我的假說是一致的這個我們也不知道 但也沒差反正它就是比較好我們未來就是這樣 從這邊你也可以看出 為什麼這個技術叫做Mixer of Depth 因為Depth就是深度嘛 Mixer of就是一個混合 一個深度的混合就是代表說 每一個Token它是有不一樣的深度 有一些呢它就是只參與某一部分的Layer 有一些參與全部的Layer這深度不一樣 所以說它才叫做這個Mixer of Depth 那當然呢也是為了致敬就是 很紅的一個技術叫做Mixer of Experts 因為這個Mixer of Experts的技術呢 它跟Mixer of Depth是有一點類似的 他們都是算是同一個支派的
(39:10~40:10) 這個研究領域就是在做這個Conditional Computation 的這種研究領域 那這個Mixer of Experts我們叫它MOE跟MOD 好了完蛋了我早該 我早該剪寫的為什麼我一開始就講說MOD就好了 Anyways反正MOE在做的事情呢 跟MOD很像它一樣是靠一個Router 在決定每一個Token呢 是要被Route去哪一些地方 但是它Route的選項並不是 Skip or not skip而是哪一個Experts 它的選項就是可能8個Experts 中的其中兩個Experts這樣子的概念 什麼是Experts就是不一樣的神經網路 大概就是這樣 很多人會把這個MOE的技術理解錯誤 因為它的名字是Mixer of Experts 不同的專家的混合 所以大部分人會直接聯想到的就是 今天你有8個專家也就是8個AI模型
(40:10~41:10) 第一個AI模型特別擅長回答Coding的問題 第二個AI模型特別擅長回答寫信的問題 第三個AI模型特別擅長做音樂 每個專家擅長的東西不一樣 然後今天看使用者是問什麼樣子的問題 然後你就把它分配給不一樣的專家 其實並不是這樣,這是錯誤的理解 正確的理解呢 它並不是在Task level跟AI model level 做Routing,它是在Token level 跟Layer level做Routing 這什麼意思呢 我一開始給的那個例子 就是大家理解錯誤的那個例子 就是在Task level跟AI model level做Routing 它是從Task來選擇哪一個AI模型要使用 但其實不是,它是每一個Token都在選擇 要使用哪些不同的Expert 然後每一個Layer都會換一個不同的Expert 每一個Layer都會去選擇這個Token要用哪一個Expert來處理
(41:10~42:10) 意思就是說Token 1在Layer 1 會被Expert 1 & 2處理 那在Layer 2呢,它竟然變成了Expert 3 & 8 在處理它,然後在下一個Layer呢 又換兩個不同的Expert,它是這樣子 所以說你完全抓不到說每一個Layer 每一個Expert他在學什麼鬼東西 你完全不知道,甚至你去看他們的這個論文 就是你想讀的話,你可以去讀 Mistral的論文 Mistral是公司,他們的模型叫Mistral 那你去讀Mistral的論文 它就講到這個part就是 他們也不知道這些Expert到底在學啥鬼 但反正他就是可以學得比較好,好,我們回到MOD 那它的運作原理呢,我覺得我已經講的差不多了 但如果你是很細心的在聽 然後不停的在思考的話,你現在應該會有個問題 就是,那哈利,那今天你是要在 使用大型元模型的時候
(42:10~43:10) 使用MOD要怎麼辦 因為你剛剛不是有說嗎,就是你今天一句話裡面 哪一些Token,哪幾個Token要pass 哪幾個Token要過,這個數字 是一開始就被使用者決定的,對不對 換言之呢,每一個Router它有一定的 可以skip的Code,像我們剛剛說的那個 例子就是它可以skip 87.5%的Token 那不能超過這個數字,也不能低於這個數字 那你今天在使用這個AI模型的時候 它是一個字一個字吐出來的 它在吐第一個字的時候,它並不知道它究竟會吐幾個字 對不對,那它要怎麼分配這個Code 然後它也不知道後面的字會不會有更適合skip的 這很難分配對不對,這個其實 是他們解決的問題,就是他們發現這個問題很好解 你只要再多訓練一下你的Router,讓它 學會怎麼樣去預測哪一個Token 是要skip,哪一個Token是不skip
(43:10~44:10) 就可以了,聽起來好像是很困難的一件事 但他們研究結果是顯示 這個對於一個很簡單的神經網路來說 也可以很輕易的學會,那這件事代表什麼呢 代表你在使用LLM的時候 可以使用MOD的技術來增加快 你LLM的運算的速度 然後而且可能不只 不會犧牲掉你的LLM的成效 不會犧牲掉它的表現,還可能有表現的提升 不過這邊就是他們可能 沒有做很多研究的部分,他們主要研究 還是比較focus在training的部分這樣 所以說這個Inference,也就是 使用LLM的過程,這個MOD 究竟有什麼樣的效果,它只有講到一點點 那這邊就等到有更多資訊出來的時候 我再來跟大家分享,好那講了這麼多 MOD這麼技術的部分 你如果聽到現在,我真的是給你拍拍手
(44:10~45:10) 來拍一下,太厲害了 我都不知道我剛剛是在講科技浪Podcast 還是在講一個機器學習的課程 反正技術的部分 我們就講到這邊,我們接下來 來講一些技術的影響 MOD究竟有多麼重大,它會怎麼樣影響 未來的LLM的世界呢 首先我相信這個技術,未來很可能變成 主流的大型原模型技術 就像是MOE一樣,這個MOE Mixer of Experts,現在已經可以被稱為主流技術了 大家都在使用,你聽前面我這個 LLM的update,我就講到他們好幾次 大家現在推出新模型,都會推出一個MOE模型 因為它可以節省很多的算力 那這個MOD呢,就是除非它 真正在scale up的時候出現很多問題 不然它真的是大家都該用的一個技術 你可以省這麼多的運算
(45:10~46:10) 可以跑得快這麼多,然後效果還更好 你為什麼不用,你一定會用啊 但就是怕說,這個MOD呢,用在比較大的 大型原模型上面,會有一些意想不到的成果 或者是這個 會比較難train這樣 我覺得應該不會啦 會有這個concern是因為,他們在Paper裡面 只有在比較小的大型原模型上面跑這個測試 在測試這個技術,比較小是什麼意思呢 大概一個billion參數 我們知道現在就算是最小的模型 也都是7個billion起跳 當然也有更小的啦,但大家通常在使用的這些模型 最小的就是7個billion起跳 所以這個技術呢 用在一個假設今天幾百billion 甚至1trillion參數的這個模型上面 效果會不會一樣好,照理來說應該要會啦 這個難說嘛,那如果這個技術真的成為主流了的話
(46:10~47:10) 然後我對於他的理解也完全沒有錯誤的話 這就代表說,大家在這個預訓練大型原模型的時候呢 這個算力要求會下降非常多 你要訓練一個一樣的大型原模型呢 你現在只要花以前可能50% 或是60%的算力,就可以了 這對於一般的這些AI公司來說 這個影響呢就是 他們現在依照他們現在有的這一批算力 他們一瞬間可以訓練出更強的大型原模型 而且更強非常多 因為你靠MOD省下來的這些多餘的算力 你可以把你的模型做得更大,或者是更深嘛 然後就讓它變得更強 所以說一瞬間所有的AI公司都變強很多 全天下的AI模型都變強了非常多 這樣子的一個概念 MOD會讓大家買更少GPU 大家應該是會持續的搶GPU 然後用這個算力呢
(47:10~48:10) 來做更大更強的模型這樣 除了做出更大更強的模型這一點以外呢 大家使用AI模型的運算速度 可能也會變快非常多 因為我剛剛也說了MOD在Inference 使用AI模型的過程也是可以使用的嘛 也是可以套用這個技術 而且它還可以跟其他的技術混用 像是MOD,你可以做出MODE 或是MOD,我有點忘了 就是它論文裡面有講到這個 但我忘記是誰先誰後 反正就是MOD加MOD的概念 所以就是你不但有這個MOD幫你節省算力 就是它可能有8個Expert 每個Layer有兩個Expert是Active的 所以說它真正在做運算的時候 它使用到的這些參數,它做的這些運算是比較少量的 就幫你省了一些算力嘛 同時你又用MOD又省更多的算力
(48:10~49:10) 然後又算得更快 這個推論真的體驗是會大幅進步的 所以總而言之我期待這個MOD的技術 變成大家普遍使用的技術之一 所以說MOD的運營跟Inference都變得更有效率 不過大家還是要小心一點 因為這個Paper雖然說它是從Google DeepMind出來的 但它畢竟還是沒有被普遍大眾給驗證過 所以說大家也可以還是先等等 這個技術才剛出來的一個禮拜多 等大家都用過了之後 證實了它真的好 然後才會慢慢的有一些AI公司 然後再一次把這個技術應用在他們的訓練跟Inference上面 到時候大家就可以深刻的體驗到AI模型變得多麼強大了 那今天科技浪的內容我覺得就大概講到這邊 我覺得今天這一集真的算是比較技術的一集 剛剛講到一半都覺得自己好像在教課一樣
(49:10~50:10) 但我一開始其實有在考慮說 真的要講這個嗎?真的要講得這麼技術嗎? 但我最後決定還是要講一下 因為我覺得我們科技浪的定位 真的就是用白話輕鬆帶你了解最先進的AI技術 科技技術不一定是AI 雖然說可能八成都是AI 當然這也是因為AI現在是最紅的東西 你去聽一般傳統的科技媒體 他們也都是在講AI 那我們只是把AI講得更深一點 我覺得這個真的就是科技浪的價值所在 這個獨一無二的定位 因為當然每個媒體都會講說 我們想用白話的方式帶給大家 輕鬆的讓大家了解最先進的AI技術 大家都會這樣講 但真正能做到的人有多少 我覺得非常的少 至少我在創科技浪之前 我是沒有看到任何一個華語的媒體 能夠解釋最先進的AI技術 然後解釋到大家都聽得懂
(50:10~51:11) 當然我創科技浪就是因為我想要成為這樣子的定位 我想要把這個空缺給補起來 讓這些想了解最新技術 但是又沒有這個非常深的 Machine Learning背景的人 也可以立刻跟上 但是我自己是覺得 這件事情確實真的是非常難 我們就已經做到了35集了 我還是每一集會去思考說 這樣子會不會講得太深太技術 還是這樣子會講得太白話 大家聽了會不耐煩這樣 我覺得從大家現在給我的留言來看 我覺得應該是大部分人都覺得 科技浪確實有做到我想要做的定位 就是我們有輕鬆的白話的 帶大家了解非常困難的AI技術 但是我也是有看到一些留言 覺得兩派啦 一派是覺得其實好像聽不太懂 另外一派是覺得 你應該可以再講得更深一點 可以講得更技術一點 像是我最近看到一個 在Apple Podcast上面的留言
(51:11~52:11) 就是說這個Bruce周先生 他說他本身也是大概10年左右經驗的 ML從業者 就是Machine Learning的從業者 平時有聽很多國外的Podcast 但是聽科技浪多少還是可以吸收到新知 他想大概應該是因為 哈利能夠歸納並且給出自己的想法 不像是一些報新聞式的Podcast 他給我的一個小建議呢 就是他覺得我可以再講得更技術 更深入一點 或者是分成白話知識的上級 跟兔子洞的下級 這樣子可以同時照顧到一般人 跟有技術背景的人這樣子 那我當然我覺得能做到這一點當然是最好 但我目前呢 我必須老實的說 我沒有辦法做到這一點 我每個禮拜錄一集科技浪 我覺得就已經很ㄍㄧㄥ了 說真的 因為我並不是來這邊講而已 我講就花很久的時間了 在這之前我還要study很久的時間
(52:11~53:12) 像我這一週 我就把這個MOD的論文給看完了 我是直接從第一頁看到最後也全部看完 除了他以外 我其實還去讀了另外一篇論文 Google上禮拜發的一篇叫做 Infinite Attention的論文 那篇更難課 超硬的 但我還是把它看完了 然後也歸納出了一些 我自己的想法跟總結 但今天就 後來想想也覺得 也沒有時間講了 你看我講MOD講的時間快50分鐘了 然後study完了之後呢 我很多時間其實是花在思考 要怎麼樣去表達 要怎麼樣把這個知識傳達給大家 那這個步驟呢 如果同時要做這個白話跟深入的版本 就會非常的耗時間 那當然呢 我覺得有一個方法啦 當然就是請一個人來跟我共同主持 那但這邊就 我覺得就對我來說是非常困難的一件事情 就光是要找到這個人就非常難 要能夠主持科技量的人
(53:12~54:13) 我覺得 不是我自己在自吹自擂 但我覺得真的不多啦 就是你真的要懂技術 但懂技術的人可能也沒有餘裕 然後也不會想要 然後甚至也不會 這個來做podcaster 這個其實是蠻困難的 那找到這個人之後呢 跟他協作又更困難 協作也是有很多成本的 所以 我覺得這邊就先unhold 那在我一個禮拜只能錄一集的情況之下呢 我覺得我們科技量現在已經是最好的定位了 就是這些有豐富的技術背景 從業經驗的這些 Machine Learning的專家 他們也可以學到一些新知 他們可以帶走一些東西 就是可能在最技術的部分 他們有一些還沒讀過的論文 或者是我歸納出的一些想法 可以跟他們產生共鳴這樣 但是小白同時也可以學到一些東西 他們可能反 就相反他們技術最技術的那個part 他們不太懂 但是在白話解釋的那個部分呢
(54:13~54:49) 他多少也是可以學到一些這個 AI產業的知識這樣 AI產業的基本概念 那還有中間很多很多在這個 光譜中間的這個族群呢 這些人呢 應該就是從科技能夠學到最多的這些人 我覺得大家多多少少都有學到一些東西 這樣子我就已經很滿足了 那今天不知道為什麼 就突然有感而發來講了一些這些東西 那最後一樣呢 如果你喜歡這一集 或是你對科技能有任何的想法 或者是你覺得科技能哪裡可以改善 就請大家留言給我知道 也別忘了給我五星評分 那最後就祝大家有個愉快的一週
