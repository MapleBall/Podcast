(00:00~01:00) 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式,帶你了解時下最火的科技話題 本期節目有好好學校課程,王子緣的高校硬聽學習法贊助播出 我上一份工作是在一間Atech的新創公司 Atech就是廣告科技,不確定這樣翻對不對 反正我們在做的就是數位廣告競價的一個機器學習演算法 那個時候我們的客戶基本上都是國外的客戶 所以說都要用英文跟他們開會 那時候我就深深的感受到,哇,硬聽真的是非常重要的一個技能 就是我的英文其實非常好,我覺得我的硬聽已經是非常接近母語人士了 但是我在聽一些國外的腔調的時候,我還是真的聽不懂,你知道嗎
(01:00~02:05) 因為我們那時候很多的客戶都是國外的客戶 應該說幾乎全部的客戶都是國外的客戶 台灣比較沒有人在碰這塊數位廣告 然後很多的這些客戶都是歐洲的客戶 那你知道歐洲他們各國都有不一樣的腔調 然後他們有些人腔調非常重的時候 然後又在講一堆數位廣告非常技術的名詞的時候 哇,那真的是非常恐怖 所以我那時候就意識到,哇,硬聽真的是非常重要的 然後可能是一個會需要花時間去練習的一個技能 那你如果一樣是在職場上有硬聽能力的需求 或者是你單純想要加強你自己的硬聽能力 來吸收更多國外的資訊的話 我推薦你可以看看王子緣的這堂高校硬聽學習法 首先王子緣老師是誰呢 王子緣老師他是有非常豐富的英語教學經驗喔 首先他是從全美排名第一的哥倫比亞大學教育學院 拿到了碩士的學位 然後過去的十年呢 他有到無數的跨國企業做英文培訓
(02:05~03:08) 包括大家熟知的聯發科、聯友、Microsoft、Lenovo、KPMG、法巴之類的 然後他這次是根據他的背景跟他的經驗 設計出了一個系統性的三階段高校硬聽學習法 那今天要推的這堂課程呢 就是會用這三個階段來教大家如何增強你的音聽能力 那這個課程呢我覺得有幾個特點 第一個呢就是他會教你如何辨識、如何聽得懂不同的腔調的英文 這就是以前我自己的痛點啦 然後我相信有一些人可能也有類似的痛點 像是比較常見的一些像印度腔啊或是一些歐洲腔調 王子緣老師都會教你怎麼樣辨識、怎麼樣聽懂這些腔調 甚至聽出一些言外之意 然後另外一個特點呢就是 這堂課並不是教你聽懂而已 還有教你說如果你聽不懂的時候你可以怎麼樣應對 就是你不用再說非常遜、非常基本的 像是Oh sorry I don't understand 或者是Can you say it again?之類的 那我覺得不管你是要透過音聽能力來加強你的職場力 還是你想要透過音聽能力來認識國外朋友
(03:08~04:08) 還是你想要透過音聽能力來接收國外的低手資訊 或者是直接聽懂美句這樣 我覺得音聽能力對你來說 對每一個人來說應該都有它一定的價值 同時這個音聽能力呢 在聽說讀寫裡面算是我們台灣人比較差的嘛 就是我們可能聽跟說是比較弱的 這也是因為我們在學校接觸到音聽的時間是真的是比較少嘛 對吧 尤其我們接觸到的又都是這個 美國啊、英國這種主流腔調 那如果你真的想要提升你的英文能力呢 你可以點進去這堂課看一下 那這堂課呢現在在Hahow的募資中喔 所以說現在預購可以現省600塊 然後同時結帳的時候也可以使用我的專屬優惠碼 Harry 這次沒有Harry幾百幾百 就Harry這樣 H-A-R-R-Y全部都小寫 輸入Harry之後你就可以再折200塊 有興趣的人呢可以到這集Podcast的ShowNo Podcast的資訊欄裡面看一下 可以看到這堂課的連結 這集夜配就到這邊結束謝謝Hahow的贊助
(04:08~05:08) 好那我現在錄音的當下呢 我是剛剛聽完Lex Freeman Podcast最新的一集 如果你不知道的話Lex Freeman Podcast 是我非常喜歡聽的一個Podcast 他就是一個MIT的researcher 然後會跟邀請世界各地非常厲害的講者 進行一個長時間的訪談 非常長喔就是可能通常都兩個小時以上 然後有時候會到三個小時 非常長時間的訪談 然後他的Podcast是我非常喜歡聽的Podcast 然後也蠻常收聽的 雖然說我會看講者聽 我並不是每一集都聽 然後如果是我沒感興趣的講者 我就不會聽這樣 然後有感興趣的講者可能也不一定會全部聽完 因為真的很長 我可能會聽挑我感興趣的地方聽這樣 那很明顯啦這當然不是夜配嘛 因為他的流量這麼好 他根本不需要客家人的夜配啦 那最新的這一集呢是他跟貝佐斯的訪談 貝佐斯就是Jeff Bezos嘛 那個亞馬遜的創辦人 那我剛剛聽完我現在還是
(05:08~06:09) 我現在還有那種感覺存在就是 哇貝佐斯真的是太厲害的一個人 我跟大家說這集絕對要聽 超級推薦 其實也不一定啦也是要看你的興趣啦 但如果你對於這個Space Travel有興趣 就是到外太空有興趣 然後同時你也對於領導力有興趣 想要提升自己的領導力團隊合作能力 然後對於這個Jeff Bezos怎麼創立這一間 非常非常厲害的科技巨頭Amazon有興趣的話 嚴格來說不是創立啦 就是他有講到他怎麼經營這樣 有些經營的一些細節 你如果對這些東西有興趣的話 這一集你絕對會超愛 像我就是超愛這一集的 因為我剛剛也有說了嘛 我並不是每一集都會聽 然後我有聽的我也並不會全部的話題都聽 但這一集我是全部全部都聽 每一分每一秒都聽而且都很認真的聽 因為真的太棒了 我真的不知道Bezos是很少上節目的 尤其是這種長時間的節目
(06:09~07:09) 我印象中我真的是我從來沒有看過任何一個 Bezos的這種長時間訪談 所以我那時候看到這集 我第一個想法是 靠Lex Reven到底怎麼做到的 他到底怎麼邀到Bezos了 真的太厲害了 雖然說是合理啦 因為根據他過去的講者 他邀過馬斯克、竹克柏 很多厲害的人都上過他節目 所以說是合理啦 然後他得到Bezos這種長時間訪談的機會 是還是覺得蠻驚訝的 所以我當然是第一時間就聽爆 然後最後結果也真的是沒有讓我失望 那我覺得普遍大眾呢 其實對於Bezos的印象應該是蠻差的 因為大家對於他的印象就是 他是一個非常邪惡貪婪的有錢人這樣子的感覺 當然啦我這邊講的一般大眾 應該是比較偏中產階級的美國人 因為台灣人我覺得對於Bezos應該是沒有那麼熟悉啦 因為台灣沒有在用Amazon嘛 那美國人就是基本上每個人都會用Amazon
(07:09~08:09) 然後中產階級的美國人 又很多人在這個Amazon的倉庫 或者是Amazon的物流上班 然後說真的啦 其實是蠻累的一個工作 然後與此同時呢 他又看到他的前老闆Bezos 在遊艇上面 然後練得撞得跟一頭牛一樣 然後跟女明星在那邊喝酒啊什麼東西的 然後他坐擁幾千億美金的身價 而且還不用繳稅 基本上不用繳什麼稅啊 所以大家看了當然會心裡不平衡 就覺得好像被自己被壓榨了的感覺 覺得自己是血汗勞工 然後都被這些有錢人壓榨的感覺 然後尤其現在美國的經濟感覺上沒有很好嘛 我這邊說感覺是因為實質上經濟是有在慢慢回溫的 是有在慢慢穩定慢慢變好的 但是perception wise 就是大家的感受上經濟是沒有很好的 那至於為什麼會有這樣子的差異呢 大家可以自己去搜尋一下 應該有蠻多文章在講這件事情的 因為最近很多人在研究這件事這樣
(08:09~09:10) 反正大家就覺得 哇這東西越來越貴 然後自己工資又不漲 然後這些有錢人卻越來越有錢 然後就很不爽這樣 所以說我覺得大家普遍對於Bezos的感覺 都是蠻討厭的這樣 然後甚至網路上還有一首歌 我記得是前幾年開始在流傳的吧 我那時候聽到我真的快笑死了 那首歌就是在唱Jeff Bezos 然後它其實只有一分鐘喔 是很短的一個小片段的一首歌這樣 然後裡面的歌詞就是把 Bezos營造的像是很貪婪冷血殘酷 但是又很有成就的一個有錢人這樣 反正我建議大家可以去聽一下 你在YouTube搜尋Jeff Bezos song應該就有了 反正大家很討厭Bezos啊 那我自己呢我並沒有討厭他 但是我對於Bezos也不是很熟悉 就是我就知道我聽過他的一些事蹟 然後可能知道他在創亞馬遜 然後在亞馬遜裡面 創造了一些非常厲害的企業文化
(09:10~10:11) 很強的領導力啊什麼什麼的 然後他現在在搞一間要去外太空的公司 叫Blue Origin 但這邊就那個焦點都被SpaceX搶走了嘛 所以說我對於他的公司 然後他的這個人我是真的不是很熟悉啊 那這次終於有個機會可以聽他講話聽兩個多小時 我覺得真的很難得 然後我也學到非常多 就是我覺得他真的是一個非常聰明的人 而且不只是學術上的聰明哦 不只是他對於物理啊 Coding這種科目啊 然後以及他對於世界的了解這種聰明 他對於人跟自己都有很高的了解 這個就是EQ的部分 就是他不只IQ很高EQ也很高 那這個是我覺得就是一個非常難得的 就是他了解說要把自己放在什麼的什麼樣子的情況之下 自己才可以發揮最大的潛能 才可以發揮最大生產力 然後他也理解一個Team要怎麼運作 要設什麼原則設什麼規則
(10:11~11:11) 才可以讓大家全部都on the same page 然後把團隊表現提升到最高 所以這就證明了他真的是一個非常厲害的領導者 然後整個Podcast 他分成很多不同的小主題啊 然後很多就是東西是穿插來穿插去 但是我覺得主要的主題就只有兩個 一個是Blue Origin就是Space Travel他這間公司 另外一個主題就是領導力的分享 然後Lex Freeman可能會先問一些跟太空相關的問題 然後突然來講一下他以前在Amazon怎麼帶一個Team 然後再來講再回去講這個太空的事情啊 然後再回來講一下他怎麼樣提升自己的生產力 就是在跳來跳去跳來跳去 但都是這兩個主題這樣 那像是Blue Origin這邊的話題呢 我覺得也很酷 我覺得SpaceX走在他們前面 但是Blue Origin也是非常強的一間公司 他也是一個私人企業啦 然後開發火箭真的是不是簡單的一件事情啊 然後領導力這邊的話題 我覺得他都有講到我的點上
(11:11~12:12) 就是對我讓我十分受用的 包括他如何做一個很困難的決定 要怎麼樣disagree and commit disagree and commit的意思就是你不同意對方的看法 但是你願意用對方的做法去做這件事情 他要怎麼做到這件事情 在什麼樣情況下做這件事情 然後以及亞馬遜究竟是怎麼樣成為一個超級客戶中心的公司 原文是very customer obsessed的公司 我不知道這個中文要怎麼翻 感覺客戶中心還不夠 但就是你真的是非常非常沉溺於 要怎麼樣把客戶體驗提到最高這樣 亞馬遜究竟怎麼樣做到這件事情 我覺得是非常有趣 好總之呢就是推薦大家去聽這集Podcast啊 你直接在YouTube搜尋就有了 就Lex 然後Frid 然後再加Jeth Bezos 就可以找到了 好那我覺得在進入今天的主題之前呢 我還想再分享一下就是
(12:12~13:12) 我對於美國中產階級很討厭有錢人這件事情的看法 因為我最近正好是跟一個美國的朋友在聊天聊到這件事情 然後我剛是很好的朋友啦 就是大家不要會錯意 但我發現他是一個anti-billiners的人 billiners就是身價十億美金以上的人嘛 就是anti-billiners的人就是認為說 billiners不應該存在 任何一個人都不應該有這麼多的錢 然後我聽到我那時候就問他說 欸你為什麼這樣想 然後他就他好像沒有給我一個非常 有邏輯非常直接的一個論點 反正他是說 What are you gonna do with that money 就是你要那麼多錢幹嘛 你是有那麼多錢要買 那麼多東西要買嗎 你有那麼貪心嗎 身上這麼多人還在餓死 然後連自己的家庭都沒有辦法support 那你一個人坐擁幾十億的資產 為什麼要這樣呢 那我是不知道這些anti-billiners的人 有沒有其他更好的論點啊 反正我目前聽到的所有論點 是沒有辦法說服我 我聽了還是覺得很奇怪 就是為什麼他們不應該存在
(13:12~14:13) 就是我覺得這些人啊 對於一個資本主義怎麼樣運作的 一個最基本的原理 他們不是很瞭解 就是我覺得有一些這些anti-billiners的人啊 他們的出發點是一個相對剝奪感 就是他們覺得 就像是Bezos那樣 就是這個我們現在這麼血汗的工作 這麼累 然後我們才賺這一丁點錢 但是Jeff Bezos 他賺了幾十億幾百億 然後都可以每天超輕鬆 都可以在遊艇上面多爽這樣 這種相對剝奪感 讓他們覺得好像是 這些有錢人從他們身上吸血 這些有錢人把他們應該賺的錢拿走了 所以就變成他們只能賺一點的錢 但其實不是這樣 這些有錢人會有錢 並不是因為他們剝奪 而是因為他們創造 他們創造了好的產品 創造了價值 讓這個世界進步 讓這個世界變得更好 讓人的生活變得更好 然後資本主義 把他創造的所有價值的一部分 分配給他 當作他變成他的資產這樣 意思就是說
(14:13~15:13) 全世界的人其實都因為他而得利了 但他得到的利益最多 因為他是創始人 這跟古代的那種國王 跟這些平民納稅人 然後納稅納到他們 這個平民都生活不下去 不一樣 那種才是剝奪 創業家們是在創造這樣 然後同時他得到比別人多 非常多倍的利益 也不是不公平 這個就是資本主義最基本的運作原理 對吧 假設今天一個創業家 他創了一間很成功的公司之後 他能拿到的錢 就只能跟一般員工一樣 就比一般員工多一點點的話 誰會想創業 沒有人會想創業 整個世界就停滯了 當然啦 如果你硬要挑一些個案 你也可以挑出很多個案 就是他的人生 可能因為這些大公司的出現 而被毀滅了 可能他原本的工作被剝奪之類的 那我覺得這些就是沒有辦法的事情 就是世界要進步 就是有人會被淘汰 就是這樣 所以我們拿馬斯克來舉例好了 馬斯克幾千億的身價 假設馬斯克這個人不存在
(15:13~16:14) 你會變得比較有錢嗎 你也不會變得比較有錢啊 因為馬斯克的錢是他自己創造的 他不是從你身上拿過來 他是自己創造的 而且你可能還會變得更窮一點 因為馬斯克創造的極大的經濟價值 全部都消失了 所以光是從這點思考 你就會覺得 billionaire不應該存在這件事情 是蠻奇怪的 因為你說billionaire不應該存在 好像就是等於是在說 世界不應該進步這麼多的感覺 那當然啦 我覺得有一些anti-billionaire的人 就會跟我說 我在講的不是說他們不能成功 而是說他們賺到這麼多錢之後 應該要拿去幫助別人 不應該全部花在自己身上這樣 這邊我覺得首先 這些真的超級有錢的人 幾乎沒有一個人 可以把這些所有錢花在自己身上 真的花不完這麼多的錢的 然後這些錢也不可能 是以現金的形式存在銀行裡面 它一定是以某種形式 不管是股權還是債 還是很複雜的衍生性金融商品
(16:14~17:14) 存在一個專案裡面 所以你如果真的要看這個人 應不應該擁有這麼多錢 你應該要看他的錢 是放在哪一些專案裡面 這部分我就有同意的地方了 就是我相信有一些這個 有錢人確實是把他們的資產 分配到非常糟糕的專案 可能沒有辦法幫助世界進步的 然後單純就是為了 讓他可以賺到更多錢的 這些人當然存在 然後我也認同他們 不應該擁有那麼多的錢 但是你不能直接否定 有很多錢的人 因為很多人是把他們的錢 放在很好的專案裡面 像是我覺得馬斯克的財務分配 就是非常棒 他創的六間公司 有一間是他買的啦 但是這每一間公司 除了這個Boring Company我沒有特別研究以外 就論其他五間好了 這五間我覺得都對於人類社會的進步 是有幫助的 然後還有XAI嘛 然後更別說OpenAI也是他創的
(17:14~18:14) 他OpenAI一開始的70資金 他投了1億美金進去 然後他現在是 他原本就沒有持股了 然後也退出董事會了 所以那1億美金完全就是他捐出去 他一毛錢都拿不回來 所以假設今天馬斯克賺到了很多的錢之後 他就把這些所有的錢 平均分配給所有人 你覺得世界會變得比較好嗎 我覺得根本就不會 我吃幾頓飯嘛 但這件事情跟什麼相比 跟特斯拉帶來再生能源的革命 SpaceX帶來宇宙探索的進步 跟OpenAI帶來AI的革命 跟Neuralink 他們還沒帶來什麼革命 但他們可能也會做出很多很好的結果 重點是 跟你我平均分掉這筆錢比起來 馬斯克自己來管理這筆錢 運用這筆錢 能為整個世界帶來更大的效益 然後就算 假設今天你不是把馬斯克的財富 平均分配給所有人 分配給你我 而是把財富全部分配給最窮的那些貧窮陷阱下的人口
(18:14~19:14) 這樣子感覺起來 會幫助到他們非常多 很多人可能十幾萬人吧 都可以得到溫飽 那這樣子這些人的溫飽 跟科技進步比起來哪一個比較重要 我還是覺得科技進步比較重要 這是因為雖然說這可能對有些人來說 是有點反知覺 但是其實減少貧窮人口的 並不是慈善事業 而是科技進步 世界的貧窮比例其實是一直在 下降當中的 而這個下降背後的原動力就是科技進步 因為科技進步了人類生產力 提升了每個人能得到資源 就變得更多了 所以你現在如果把你原本要開發科技的資源 拿來支助這些窮人的話 你根本就是治標不治本 你讓他們現在這一代的窮人 可以吃飽 但是未來窮人的比例不會下降啊 我跟科技沒有在進步啊 好啦反正我覺得大家應該懂我的點啦 那最後也跟大家說一下 我剛剛講的這些論點也都不是絕對 就是我知道資本主義也帶來 很多的悲劇
(19:14~20:14) 但是像是Billenier不應該存在 這種非常絕對非常 直接的論點 我覺得也是錯的 然後同時這也是我一時興起想到的話題啊 我剛好看完貝索斯 這個podcast嘛 然後我又回想到前一陣子 然後就一直想說來講一下 那很明顯的我並沒有 非常詳細的研究這個 Anti-Billenier他們的想法是什麼 他的論點是什麼 搞不好這邊有很多我忽略的東西 那我覺得這邊大家如果有想法 也可以在留言區跟我討論 那我也會看一下 或許未來會改變我的想法 好那我們上禮拜也有說嘛 就是這禮拜要講的主題呢 是Gemini的part 2 就是把上禮拜有一些 關於Google這個叫做Gemini的模型呢 他有一些我們沒有講到的亮點 然後還有他跟OpenAI的比較 來稍微再講一下 但我後來回去想了一下 我發現其實我上禮拜的餅 好像有點畫得太大了 就是怎麼可能在一集
(20:14~21:14) 之內講完這麼多的話題 所以我想了一下 我最後決定我們今天這個集數 我們就講Google Gemini其中一個亮點 就是他背後的 training hardware 他是用什麼樣的硬體 去train出Google Gemini這個模型的 那其他亮點包括 Gemini有一個叫做Alpha code 2的模型 然後他背後有一個 他們叫做complex reasoning system 就有點類似 OpenAI的Q star突破 然後還有呢 就是Google Gemini本身 他是一個dense model 不是一個sparse model 意思就是說他本身就是一個非常大的 神經網路模型 而不像是OpenAI的GPT-4 是一個sparse model 也就是他是有非常多個 可能8個或是16個 比較小的神經網路模型 組成的一個模型這樣 那這兩種做法呢 在訓練的 使用模型的時候 都有非常多不一樣的地方
(21:14~22:14) 然後除了這些Gemini的亮點 的討論以外當然還有這個 Google Gemini跟OpenAI的比較 那這邊 這邊所有的部分啊我認為未來 絕對會講到好不好 絕對會講到的像是Alpha code 2那個 我們未來如果講到 這個大型原模型未來的 研究方向或者是說 他下一個突破會從哪一個領域 出來這樣我覺得我們就一定會 講到這個然後這個dense model跟sparse model 雖然說 有一點技術啦我覺得大部分 人可能不用了解到這麼細 但是現在在machine learning 的這個學術圈啊這邊的討論 很多很熱烈因為 Mistral這間公司 我以前有介紹過嘛他是法國的一間 AI新創公司 他們有個非常有名的模型叫做 Mistral 7B嘛那他們最近是把 這個8個Mistral 7B 的模型組成了一個叫做 Mistral的sparse model 那這邊就真的是 幾起蠻多討論的啦所以說 我覺得近期我一定也會做一集
(22:14~23:14) 科技浪來講 這件事情然後Google VS OpenAI這件事隨時都可以聊啦 好不好每次講到Google講到 OpenAI都可以講到所以 我覺得我也不怕這個這個話題聊不到 一定會聊得到所以我們今天就來 聊聊Google究竟是用多 強大的這個超級電腦硬體 設備來訓練出Google Gemini Ultra這個超級 龐大的AI模型首先 如果你忘了的話Google Gemini 有分很多不同的大小嗎 應該說三個啦也沒有很多 最小的呢叫做Gemini Nano它是在手機上也可以跑的 一個非常小的 我記得是一兩B左右 的模型這樣一兩B在講的就是 它的參數數量啊 那個B是billion的意思 所以說它大概是十幾或者是 二十幾億的參數 再來中型的呢叫做Gemini Pro 那這個Gemini Pro呢 基本上就是跟免費版的 Chat GPT也就是GPT 3.5 是差不多強的 那它的參數數量我們並不知道
(23:14~24:14) 但是根據它的表現啊就是跟GPT 3.5 差不多強嘛 所以你可以猜它大概是 可能一千兩千億 參數這樣 那再來最後就是最大最強的 模型叫做Gemini Ultra 這個Ultra呢差不多就是 跟GPT 4是同等級的 模型那這邊一樣Google 沒有公佈Gemini Ultra 究竟有幾個參數 我們並不知道這件事情但我們知道它是 一個Dance Model就是它不是很多小 模型組成的它是一個非常龐大的 非常強大的一個 大模型那這樣子單格 的大模型然後它的表現跟 GPT 4是差不多的 我覺得它它的參數數量 很可能是接近一兆或者是 超過一兆然後我覺得最低 底線啊就是它一定有超過 五千四百億因為Gemini 的前身就是Google的POM P-A-L-M那這個POM POM模型POM2嚴格來說是POM2 那這個POM模型呢 就是五百四十 Billion個參數就是五千四百億
(24:14~25:14) 個參數的模型然後同時呢 Google Gemini這次是有在他們的 Report裡面講說Gemini Ultra是Google訓練過最 龐大的模型就是說它一定 比這個五千四百億個參數更多 然後同時我們也可以大概比一下他們 這兩個模型在訓練的時候 他們使用的訓練資源 POM那時候是使用 兩個TPU V4的 Pod TPU就是Google它 自己設計出來的一個AI 訓練晶片就是大家應該常 聽說吧就是我們在訓練這些大型 AI模型的時候呢我們都要用 一個東西叫做灰達 的GPU NVIDIA的GPU 來訓練那究竟 為什麼AI模型要使用GPU來 訓練呢這個大家可以去聽科技 浪的第四集我非常早 期的集數我那一集有 詳細的講解這個部分 反正這邊我就不講了反正Google 並不是跟其他公司一樣是使用 NVIDIA的GPU在訓練 AI模型因為他們自家有 開發出一個訓練AI模型的 晶片也就是TPU了
(25:14~26:14) 那這邊TPU我待會會再做 更完整的介紹反正這TPU 它有很多版本有V1 V2 V3 V4然後你 把三千零七十二個這個 TPU V4的晶片 或者你說處理器 組在一起會變成一個POD 然後POM那時候呢就是使用 兩個這樣子的POD在訓練的 也就是說它總共 是使用了六千一百四十四個 TPU V4的 處理器這已經是非常驚人 囉就是大家可以自己去 Google一下他們就是你 搜尋Google的這個TPU V4 POD哇真的是非常 龐大的一個系統啊但是 Gemini又比這個更誇張 我們並不知道它到底是使用 了多少個TPU 多少個POD我們不知道這件事情 但我們知道它的用量多到 需要跨資料中心 那一定是非常的龐大 因為Google的資料中心裡面可以有 八個POD就是你一個Data Center可以 有放八個POD而且是放更新 版的POD不是這邊我們剛剛講的
(26:14~27:14) 這個三千多個TPU V4組成 的一個POD是一個更新版我們 待會會再講可以放八個 那難道訓練Gemini八個還 不夠用嗎我覺得應該不是啦 就是它八個當然其中 一些POD會有其他用途嘛 但是像是POM的訓練 兩個POD就真的不用跨Data Center 就是找一個Data Center 然後把那兩個POD都 拿來訓練POM就行了你Gemini如果 真的要跨Data Center 那我覺得絕對不只是兩個POD 所以這個Gemini Ultra一定是一個 極其龐大的模型然後 會需要用到非常恐怖 的訓練資源然後我覺得 很多人不知道的是我覺得大家 聽到想到這個AI訓練 第一時間就是想到NVIDIA 然後都會覺得OK沒有別家了 但是其實Google的TPU 是非常有競爭力的 是非常厲害的而且他們起步 也是非常的早在2015 年的時候吧我記得 Google就推出了第一版的TPU 然後他們過程中完全沒有鬆懈下來 就是他們持續的推出新
(27:14~28:14) 款的這個TPU TPU V1 V2 V3 V4 然後到現在V5 1都出來了而且不 只是TPU而已喔他們資料中心 的技術也在不停的提升 尤其是這個 網路技術連線技術 一直在不停的提升然後這一次 這個我在讀Gemini的Technical Report 的時候他有一個Section 就是專門在講他們使用的 硬體設備然後讀的時候就發現說 哇真的是進步的非常 快就他們這次拿來訓練Gemini 的這整個訓練設施 跟他們上一次在訓練POM 的時候已經非常不一樣了 然後他們最新這個版本的這個 訓練設施啊我覺得真的 不一定會輸NVIDIA的系統 在我介紹這個訓練設施的一些亮點 之前我覺得先給大家 一些先備知識因為我覺得 畢竟還是有很多 非理工背景的人在聽我們的頻道 所以這邊還是要交代 清楚好那我覺得首先 如果你連AI為什麼要用 GPU來訓練都不知道的話
(28:14~29:14) 一樣你先去聽EP4 然後再回來好那假設你 已經知道的話第一個先跟大家介紹 到底什麼是Google的TPU TPU的全名是叫做 Tensor Processing Unit 意思就是說他是專門拿來處理 Tensor的一個處理器 那這個Tensor又是什麼呢 反正你如果去查的話 Google會跟你說他的中文叫做 張亮然後他的解釋 你應該是看不太懂 講一堆很技術的東西 然後你也不知道他在講什麼 但反正非常白話的理解 Tensor就是你在訓練一個 機器學習模型的時候一個AI 模型的時候你的資料 全部都會被轉換成一個叫做 Tensor的形式在做處理 然後其實也不只是你的資料啦 就是這個模型他本身的權重 其實然後還有他的Bias 其實也都是以 Tensor的形式在表達 也就是說你不管是在使用這個AI 模型還是在訓練這個AI模型的時候 你的AI 模型在做的事情基本上就是
(29:14~30:14) 很多Tensor的操作 就是你的資料要承上你的權重 就是這個Tensor要承上 這個Tensor這樣之類的 非常淺的理解非常 可能高層次的理解你理解到這邊 就可以了這就是為什麼TPU 會跟AI有關嘛TPU就是 專門為AI設計的處理器 因為他是專門在做Tensor的 Operation嘛那AI在做什麼 AI就是在做TensorOperation 不過更精準的來講 Tensor他其實就是一個數學物件 他是什麼樣的數學物件 他其實就是一個高維度的矩陣 而已就是我們都知道矩陣這個 數學物件嘛對吧大家 國中我忘記國中還高中 反正一定有學過矩陣嘛就是 一個中瓜號然後裡面有 很多行列的這個 數字這就是一個矩陣嘛 你看到的矩陣全部都是2D的 因為他就是兩個 維度嘛對吧兩個維度然後 排列成一個長方形或是 正方形嘛所以說就是2D的 那一個Tensor就是高維度的矩陣 他就一樣是一個矩陣
(30:14~31:14) 但他是3D的或是4D的 或5D 6D 7D 8D 之類的因為我們知道很多AI 在使用的一些資料啊在 處理的一些資料都是非常 高維度的對吧最好的例子 是什麼一張圖片一張圖片 就是三維度的一個資料 他有長跟寬還有顏色 這三個維度所以你一個AI 軟體你在處理 這張圖片這個資料的時候 你就會把這張圖片變成 一個3D的Tensor 那假設你今天要處理的是一個影片的話 你就多了一個 多了時間的維度你就變成 長寬顏色時間就變成 四維然後就是一個 4D的Tensor那這個TPU呢 我剛剛也講過很多遍了就是專門為 這個Tensor運算 而設計的晶片嘛那 具體來說他是怎麼做到 這件事情就是怎麼專門為 Tensor設計的這個就是 他在他的instruction set 有做很多的客製化但 再下去就真的太深了太難了 所以我們就先點到
(31:14~32:14) 為止反正你知道你要知道 就是TPU專門處理AI 為什麼因為Tensor是跟AI 相關的一個概念就這樣這是第一個你要 知道的先備知識第二個 你要知道先備知識就是 我們在訓練一個超級大 AI模型的時候我們要 做一些平行處理的操作 這是因為兩件事情第一個就是 模型本身非常的大 他沒有辦法放在一個TPU上面 就一個TPU他有一些 他專用的記憶體 他放不下這麼大的一個模型 所以你要把很多的TPU連在 一起然後再 放這個模型這樣另外一件事情 就是我們要讓這個 模型訓練超級大量 的資料整個網路這麼多 的文本那在這個情況之下 你一次複製出很多 個模型然後同時讓他們訓練 不一樣的這些文本才是 最有效率的做法那我剛剛講的這兩 件事情其實他們分別有一個 專有名詞有自己的名稱 第一個就是你要 把一個模型他的切成
(32:14~33:14) 多小塊然後把他放在不同的 GPU上面TPU上面的時候 這件事情叫做 Model Parallelism 也就是模型的平行化 之類的我不知道中文怎麼翻 另外我剛講的第二件事情 就是你把資料分拆成 拆成很多塊然後讓很多這些 你的模型的copy呢 在同一時間 在訓練不一樣的資料然後 最後再把他們學到的東西全部繪整 在一起這件事情叫做 Data Parallelism資料 的平行化我剛去查了一下 這兩個Data Parallelism 跟Model Parallelism的 中文是什麼好像真的是 模型平行化跟資料 的平行化我一猜 就中是蠻厲害的反正你要知道 就是我們在訓練這種超爆大的 大型元模型的時候 我們就是要做這兩種平行化 然後也因此我們會需要把 TPU一個個各種個別的 小TPU組成一個很大的 一個系統那Google 就叫做把這些系統叫做
(33:14~34:14) TPU Pod好那這些先輩知識 大家都有了之後我們可以開始來講 Google Gemini這次使用的 非常扯的這個訓練 設施了他們這次使用的 這個訓練設施啊跟之前訓練 設施比起來是有很多進步 第一個呢就是他們這次 設計出了一個全新的 Pod的單位我之前 我剛一開始有講嘛就是他們在 訓練POM的時候他們是 把這個三千多個 TPU組成一個Pod 但他們這次做出了一個新的 Pod叫做他們把它取名叫做 Super Pods那這個Super Pods 呢總共有4096 個TPU嚴格來說 他是由64個TPU 組成一個Slice然後64個 Slice組成一個Super Pod 也就是4096個 TPU的一個Super Pod 那我們知道我們在看一個這個 訓練AI的系統他能夠訓練的多快 並不是取決 於算力而已有三個大重點 第一個重點是算力嘛當然 第二個重點呢其實是頻寬
(34:14~35:14) 就是這麼多的TPU這麼多 處理器他們之間互相 溝通資料的這個速度就叫做 頻寬那這個很重要 是因為我們剛剛不是有講Model Parallelism 就是他把一個模型 拆成好幾塊嘛 在這種情況之下一個模型他不同的 區塊一定要互相溝通 他才可以達到這個一致 的一致性的訓練嘛所以說 頻寬是非常重要的 你要看的頻寬也有兩種 一種就是Super Pod他 內部的頻寬就是他 內部不是有四千多個TPU 組成的嗎這四千多個 TPU他們互相之間他們 溝通的速率速率 第二種頻寬是Super Pod 跟Super Pod之間的頻寬 那這邊也是需要去 做最佳化的 然後我忘了還有第三種第三種 是Gemini才要用的是叫做 跨資料中心 的頻寬跨Data Center的頻寬 因為Gemini 會需要用到跨Data Center的Super Pod 然後最後一個會決定
(35:14~36:14) 這個這個系統訓練 AI速度的呢就是 軟硬整合的部分這邊我們 待會再講我們先講頻寬好了 那我們剛剛說的這三種頻寬 Google新的這個Gemini 的這個訓練設施呢在這三種 頻寬都有非常大的進步 首先第一個是Super Pod 他自己內部的頻寬嘛就是他 內部這四千多個TPU怎麼樣 溝通那他們這邊是 有一個非常強的技術叫做 注意喔這名字非常長 Reconfigurable 3D Tourist Topology好這個 我覺得應該是科技讓開頻道 到現在講過最長 然後最技術的一個名詞 好但反正我很技術 沒關係啦我們把它拆成小 部分了解首先第一個就是 什麼是Topology Topology 就是在講的就是Network Topology 我去查一下中文是什麼 我查到了中文叫做網路 拓撲 我覺得應該是音譯吧拓撲 有什麼意思嗎他應該是 Topology的音譯
(36:14~37:14) 反正Network Topology 在講的就是這些處理器 要怎麼樣去連結 有哪些連結的方法哪些排列 然後連結的方法怎麼樣把他們 排在一起然後接起來 那這個方法有很多種嘛 之前Google用的是一種 叫做2D Tourist Topology 但我剛剛有唸這次 Gemini的這個設施的 新的名稱嘛叫做3D Tourist Topology意思就是說 他其實是把GPU排用 然後把3D的形狀排列出來 其實就是一個正方形 一個Cube 他最小的單位是一個Slice 就是64個TPU 那這64個他排列的樣子 就是4x4x4 的一個 立方體那如果2D的話 就會是一個平面的 一個網狀的長方形 對吧正方形 就是一個正方形的形狀 那這兩種哪一個是比較好的 很明顯是3D為什麼 因為每一個TPU連到更多的
(37:14~38:14) TPU啊對吧你如果是一個 平面的一個正方形 的話你每一個TPU最多 就是連到4個其他 鄰近的4個TPU對吧 那你今天如果是一個立方體 的話每一個TPU他周圍 會有6個TPU他的 鄰居有6變成有6個 因為不只是前後左右上 下也有嘛對吧所以說 3D的Tourist Topology 他的TPU連線是比2D 更多的這也代表TPU 之間互相傳輸資料 的速度會變得更快因為你多了 一些連結所以這個是 3D Tourist Topology的部分 但我剛剛還有講一個形容詞 對不對Reconfigurable 他是Reconfigurable的3D Tourist Topology 那Reconfigurable的意思 就是說他可以自由 的調整你Topology的形狀 就像是這個Google Gemini 他Technical Report他上面有寫說 他可以把這個 4x4x4的一個Cube 直接轉換成任意的 3D Tourist Topology
(38:14~39:14) 然後10秒之內就會轉換完成了 所以說他可以 就是看這個使用者想要他 用什麼樣的形狀去排列 這些TPU然後 對他的這個application是最好的 他可以做到這件事情 然後這些Tourist Topology之所以 可以做到能夠改變形狀 可以Reconfigurable 因為Google有研發出一個技術叫做 OCS Optical Circuit Switch 這個OCS的技術 就是提供了 這個SuperPOD裡面的 Cubes的連結 就是很多很多個這個 4x4x4的Cubes 互相的連結這樣 然後這個OCS他帶來的好處 並不只是讓這些Cubes他可以改變形狀 可以讓他變成Reconfigurable 他還有另外一個非常大的 好處就是他們可以讓這些Cubes 用光來傳訊號 而不是來傳資料 而不是用電子來傳資料 這兩種做法差別在哪裡 首先就是你要知道你一般 像是你隨便把你的手機插進你的電腦
(39:14~40:14) 然後要傳你的相片到你的電腦的時候 你這些相片是以 電子的形式透過 你的線傳到電腦裡面的 電子可以拿來傳訊號 因為我們知道資料 最原始的形態就是 0跟1而已嘛 你要想辦法用你的電流代表0跟1 你的做法很簡單 就兩種嘛,一種就是你高電壓 就是1,低電壓就是0 或者是有電流就是1,沒電流就是0 反正你可以想辦法 用你的電流,也就是用電子 來代表,來傳這些訊號 但是OCS是讓這些Cubes 直接用光來傳訊號 光來傳訊號的方式一樣嘛 有光就是1 沒有光就是0嘛 那光傳訊號會比電子快非常多 這明顯,光速度比較快嘛 也沒有摩擦力,不會生熱 所以這個OCS是 Google自己研發的一個技術嘛 它真的是非常厲害的一個技術 可以大幅增加整個 SuperPOD 它裡面的頻寬跟它的使用效率
(40:14~41:14) 然後這個技術也真的是 非常領先業界的 當然除了SuperPOD內部 這些Cubes溝通 這些TPU溝通的頻寬以外 還有SuperPOD跟SuperPOD之間的溝通 以及跨Data Center的SuperPOD溝通嘛 這邊Google也是有一些 他們自己獨家研發出來的技術 但就沒有像OCS 這麼有亮點,所以我就先不講了 那我覺得講到這邊 應該很多人就會開始 有一個疑問就是,那到底為什麼 在訓練AI者的這一塊的實戰 NVIDIA占了 90幾%、95%以上 為什麼都沒有聽到有人在 使用Google的TPU在訓練模型 除了Google自己以外 他們的TPU明明也是非常有競爭力的 不是嗎?就像我剛剛介紹的 OCS加強他們的頻寬 除此之外,你比算力的話 一個TPU V4的SuperPOD 還比NVIDIA那個 超恐怖的DGX Grace Hopper 200 還有更多的 算力耶,然後雖然這個詳細的
(41:14~42:14) 比較數據我這邊沒有 就是我沒辦法比較 用Google這些TPU的 System來跑大學模型的訓練 跟使用NVIDIA的系統 他們非常詳細的 Performance、速度、Cost 的比較,我沒有辦法做這個比較 我相信可能有人做過了 大家可以去找一下 啊我想起來了,SemiAnalysis的 Dylan Patel有做過 我上一集有跟大家講到這個 SemiAnalysis這間公司 一個蠻有名的 在分析半導體產業的一間公司 就是連Satya Nadella 就是微軟的CEO 最年來的CEO Sam Almond 都會看他的文章,然後我前幾天在查 一些TPU的東西的時候 我也有看到他有一篇文章是在比較 TPU的系統跟NVIDIA的系統 那他那邊就有非常詳細的 數據比較,但那個 部分我看不到,因為那個是 要付費訂閱才可以的 然後我點進去看 他那個付費價格,他上面是 寫500塊,應該說
(42:14~43:14) 一個月是100多塊 然後重點是,我不知道他是台幣 還是美金,我覺得很有可能是美金 因為他出的都是 非常非常詳細的分析 報告,一般人是不會看的 那他不可能charge100塊 這種一般人的價格 所以說,我猜應該是美金 所以感覺有點貴啊 那這邊詳細的比較,大家可以自己去 再去找一找,或是你要去訂閱SemiAnalysis 也可以,反正我自己是 覺得這個Google的 這個TPU的 System真的不會輸NVIDIA 的System,就我們單純從 他的硬體來看的話,他們真的不會輸 就算我們沒有數據來佐證 這件事情,Gemini的存在就是 一個鐵證,對吧,Gemini就是 Google從零用他的 TPU train出來的一個非常 大非常強大的一個模型 他就是完全沒有用NVIDIA 的GPU啊,然後與此同時 Google也有出租他們的TPU 對吧,他們沒有直接賣他們的TPU 但他們有出租他們的TPU 就是透過他們的雲端平台
(43:14~44:14) 叫做Google GCP啦 Google Cloud Platform 去出租這些TPU 但是到底為什麼都沒有 人在用Google的TPU訓練模型 這邊我自己原本是有一些我的 想法,然後正好我有個朋友 他是 他是一個蠻有名的YouTuber,當然美國人 國外的,台灣人沒有人在看 他的頻道,順便推一下 好了,他的頻道叫做Asianometry 然後他是 主要是在講半導體的一個頻道 他還有很多其他的一些 歷史的內容,但他們他最紅的 然後最主要講的就是 半導體,然後都講到非常 非常深的技術細節 然後他有認識Dylan,就是那個 Semianalysis的Dylan,你看他 他人脈這麼好,我都沒有這種 人脈,但反正他有認識 也算是我的人脈,所以我就 我就跟這個Asianometry 的人,他叫John,我跟John 在聊天的時候聊一聊,然後 我們聊到這個話題,然後 他就說,不然我去幫你問問看Dylan 看Dylan怎麼想這樣
(44:14~45:14) 就是問他這個在Cloud AI Computer這個市場,為什麼Google的 Market share這麼低,明明 TPU system是一個非常 有競爭力的系統,那看過了這個 Dylan的回答之後呢 他的回答其實跟我基本上想的是 一樣的,是差不多的東西 就是這個Google的軟體跟 開發者生態系是輸 NVIDIA的,就是你要知道 NVIDIA的Cuda生態系是非常 強大的,Cuda就是NVIDIA的 一個,自己開發的 一個軟體的平台 那這個平台呢 主要就是可以讓開發者們 把這個NVIDIA的GPU 變成他們想要的樣子 就是你要知道這個NVIDIA的GPU 它可以做很多事情,它可以拿來 打遊戲,它可以拿來跑模擬 它也可以拿來跑AI,那 你就是可以透過這個Cuda 把這個GPU變成專門 拿來跑AI的GPU,就是寫 Cuda Kernel的code 這邊就很複雜了 但反正NVIDIA早在2006年 就開發了Cuda
(45:14~46:14) 然後這20年,將近20年來 一直都在砸錢下去 開發Cuda,然後 不斷的優化,然後開發出新的 韓式庫等等,同時這個Cuda 的SDK也已經跟這個 一般的這些AI開發者 的,平時 自己有在使用的這些工具,已經有 高度的整合了,就是像是 大家最常用的架構叫PyTorch 就是跟Cuda有非常 高度的相容,那這邊一個很大的 原因,當然也是因為,大家都有NVIDIA 的GPU,對吧 連我自己的筆電也是使用 NVIDIA的GPU,大家都有這個東西 然後PyTorch也是完全開源的 所以說,在這種情況之下 當然就是養出了一大批這個 使用Cuda的 開發者,那這個TPU呢,就沒有 這樣子的生態系,因為它是 相對非常封閉的,首先 就是Google沒有在賣TPU的 然後同時呢,TPU也不是 一般消費者會買的東西啊 它是一個Data Center的處理器 那大家要使用TPU呢,只能透過 Google的雲端平台,Google GCP
(46:14~47:14) 來使用,然後同時呢 TPU的開發,它的設計,它硬體 的設計,主要是 跟Google自家的 一些軟體有高度相容 像是,他們使用的是這個 相較於PyTorch,是這個 Tensorflow嘛,那Tensorflow就沒有 PyTorch這麼有名啊,當然在TPU上 也是可以跑PyTorch 的code,但是這個 資源程度就不太確定 所以當一個開發者生態系 已經建立起來的時候,新 加入的開發者會去哪裡?當然 是去這個已經建立的開發者生態 系啊,你一個新手 在寫PyTorch,你不會想在TPU 上面跑,你一定會想在這個NVIDIA 的GPU上跑嘛,為什麼?因為在你之前 有幾百萬人給人跑過了,但是 在TPU上面,平時在用TPU 的人有多少?很少啊,尤其是 使用Google的GCP 本身,也自帶一些摩擦力 對吧,就是你要在Google的這個 GCP上面訓練你自己的模型 的時候,你要先同意他們的 Terms and Conditions 對吧,他們列出什麼條件你都
(47:14~48:14) 要答應啊,然後我又聽說這個Google 的這些Terms and Conditions 是非常複雜的嘛,所以說 反正這些種種原因啦 Google的TPU現在就比較是自己 在用而已,雖然說他們自己本身 的用量也是非常大,然後我覺得 先不管未來Google有沒有想要 靠這個TPU在 雲端的業務賺很多錢 我覺得Google有 TPU這件事情,就算他 不賣給別人,他自己使用,也是一個 非常大的一個優勢,因為 除了他們以外,其他的科技巨頭 現在都非常的依賴NVIDIA 對吧,高度依賴,雖然說最近 那個AMD的MI 300 開始出貨了嘛,那 不確定未來會怎樣啦,反正他們 都是在看NVIDIA臉吃飯 然後NVIDIA那個Markup,就是 他的賣GPU的那個利潤 高的嚇人啊,真的是很恐怖 然後現在大家都想開發自己的 晶片了嘛,就是像微軟 的Mai啊,然後這個 Amazon的Trainium之類的,反正 大家都在開發自己的晶片,但比起 Google,他們真的是玩了
(48:14~48:50) 好多步啊,Google從2015年 就在開發自己的TPU了,到 現在都已經V5了 然後他們現在才開始要V1 所以總之啊,我覺得Google TPU 是不容小看的一個 存在,那你如果喜歡今天的集數的話 你可以幫我五星評分加留言 告訴我你的想法,然後也別忘了 把科技浪分享給你的朋友們 科技浪到目前呢,仍然是全部靠 這個業配收入來維持 經營的一個自媒體,所以說 支持科技浪的最好方法,就是 把科技浪推廣出去,那最後 也祝大家在2023年的 最後兩個禮拜,也要好好 加油,好不好,不要爛尾了
