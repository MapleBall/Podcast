(00:00~01:03) 哈囉大家好,歡迎收聽科技浪,我是主持人哈利 科技浪是一個白話跟你聊科技的Podcast 希望可以用簡單易懂,但是又深入的方式,帶你了解時下最火的科技話題 好,那在本集節目開始之前呢,我先做一個簡單的修正 那本集有很多處提到台北國際電腦展 那台北國際電腦展的英文呢,是Computer Text 但是我整篇Podcast都把它念成了Computer Text 那這邊英文念錯就請大家見諒 正確的念法是Computer Text 那以下開始正文 那我相信大家都知道,過去這個禮拜是Computer Text週嘛 那我相信你就算沒有到現場參加 你應該也有看到我的抽獎文,對不對 就,呃,這次我是跟NVIDIA合作,做了三支抽獎文這樣 分別是抽兩台筆電跟一張顯卡
(01:03~02:05) 那,那些抽獎文,基本上在剛PO出的那幾天就超級爆紅了 那,像是第一篇這個ROG那台筆電的抽獎文 現在已經五百多萬的觀看了這樣 那我自己本人是有到現場參觀 那我不得不說,今年的Computer Text真的是非常的盛大 就是我覺得這個整體的規模是比去年大非常多 那,如果你還不知道這些Computer Text相關資訊呢 我這邊大概給你簡介一下啦 就是這個,它的地點呢,是在南港展覽館的一館跟二館 然後今年這個展會的主軸呢,是叫做AI串聯共創未來 Connecting AI 所以說,基本上就是以AI為中心啦 那確實就是去參加完了之後呢 大部分的這些攤位呢,都跟AI技術脫不了關係這樣 那現場的活動呢,是非常豐富的 就是除了這個展區以外呢 它還有一些CEO的Keynote 然後也有這個生日式AI的論壇,這個Forum這樣子
(02:05~03:06) 然後除此之外,也有一些就是其他的活動啦 就是一些什麼PlayMe跟乖乖的一些聯名活動啊 或是微熱山丘的攤位啊之類的這些東西這樣 好,那在主要的展區這邊呢,我記得它是有分四層 就是這個一館跟二館分別兩層這樣子 然後它裡面所有的攤位呢 有分很多不同的小展區啦 但是這些展區呢,主要都是由六個主題延伸出來的 第一個主題呢,是人工智慧運算 這個就蠻明顯的啦 就是除了從雲端到Edge 然後從Consumer到Enterprise 很多很多的Solution都可以在這邊看到這樣 那接下來是這個前瞻通訊 這邊就是包括一些5G、AIoT的這種Solution 然後這個接下來是未來移動 那這邊就是跟車子相關的啦 有一個叫做台灣先進車用技術發展協會 有在裡面擺一個蠻酷的攤位這樣
(03:06~04:08) 然後接下來是這個沉浸現實 這個就是跟VR、AR、XR相關的一些東西這樣子 接下來還有這個綠能永續 這個就ESG相關嘛 然後最後就是這個新創這樣子 那在Keynote這邊呢,今年真的是眾星雲集啊 有這個AMD的董事長兼CEO蘇志峰博士Lisa Su 她要進行第一場開場的Computex Keynote 那在她之後呢 還有這個高通的CEOCristiano Amon Intel的CEO Pat Gelsinger 然後還有聯發科的CEO蔡麗形 Supermicro的CEO梁建厚 然後還有恩智普半導體的技術長Lars Rejer 哇這個Lineup真的可以說是科技圈的Coachella 那當然除了這些有進行自己的Keynote的CEO呢 這個Keynote的過程中呢也有一些CEO被邀上台
(04:08~05:08) 像這個蘇志峰他在演講的時候呢 就有邀請很多他們的OEM partner上台嘛 就是包括這個華碩的董事長施崇棠 然後還有HP的執行長Enrique Lors 然後還有這個Intel呢 Pat Gelsinger他也邀請了施崇棠 然後也有邀請這個宏碁的董事長陳俊勝這樣子 那很多這些CEO呢都是在這個3號4號會出現在現場 然後這個4號尤其是這個4號呢 很多CEO都會開始逛站 然後就是到他們的基本上就是到他們的這些partner這邊 打聲招呼然後簽簽名 然後稍微造勢一下這樣子 像是這個GigabyteGigabyteGigabyte這樣子 那我自己呢也是這個4號有去啊就是這個第一天嘛 那第一天真的是可以說非常的非常的恐怖
(05:08~06:09) 這個一天之內呢我黃仁勳Lisa Sue跟Pat Gelsinger都看到了 然後看到黃仁勳的時候呢 我真的是差一點上命 好啦沒有那麼誇張啦 但就是現場啊真的是非常的混亂 那我覺得我花一點時間一兩分鐘簡單介紹一下這個 當時的情況好了 那當時呢我是在這個技嘉的攤位 Gigabyte這邊 那我會在那個時間出現在Gigabyte 其實就是因為我知道黃仁勳會過去 因為這個NVIDIA的人已經有幫我打聽這個黃仁勳的這個行程了 所以我知道黃仁勳會在那邊 那我想說這其實一半也是這個NVIDIA這邊的人的這個用意啊 就是他們覺得搞不好可以讓我跟黃仁勳互動一下拍張照 自我介紹一下 然後這邊可以當作我的這個Social Media的素材嘛 對於NVIDIA Gigabyte也有一些更多的曝光這樣子
(06:09~07:09) 好那我剛到現場的時候呢還是非常正常的一個狀態 就是我還是可以走動 然後就是可以拍任何想自己想拍的東西這樣子 但是過了大概5到10分鐘呢 黃仁勳快要來的時候 我就看到這個攤位前面呢 就站了兩排人 就是排出一個走道這樣子的概念這樣子 那我也不確定他們究竟是什麼人 反正他們是有內線嘛他們知道黃仁勳要來嘛 可能是有一些可能是媒體啊或者是有一些是Gigabyte的人這樣子 在那邊等著迎接黃仁勳 那他們出現了之後呢 其他人就開始有點像磁鐵一樣就慢慢被吸過去吸過去 因為大家都知道好像有誰要來了這樣子 那我就趕快躲回我自己的這個角落這樣 我的角落就是我知道黃仁勳一定會走過那邊 這個NVIDIA的人跟我說的 所以我就站在那邊我想說 黃仁勳過來的時候就跟他打聲招呼這樣子
(07:09~08:11) 那我就開始等嘛 那接下來的10分鐘呢 每兩分鐘那個現場的緊張跟混亂程度就往上一個級距 真的你可以是完全是可以體感 是可以感受到那個緊張程度的上升 混亂程度上升非常恐怖喔 真的是兩分鐘之後呢 你看到這個現場的人密度又變得多一點點 然後又過了兩分鐘 現場人又更多了一點點 然後大家開始會推彼此了 就是工作人員會說 過去喔過去喔過去喔 然後這樣子然後大家也互相擠來擠去這樣子 然後又過了兩分鐘 工作人員的聲音又更大聲了 然後很明顯從他們聲音裡面聽得出那個無奈跟慌張 然後現場的人又更多了一點點 然後最後到這個黃仁勳我們 從他的聲音開始被聽見 就是他在那邊喊GIGABYTE GIGABYTE 然後到他我看到他的這個投出來的時候
(08:11~09:12) 這個現場的混亂跟擁擠程度就到了一個巔峰 那那個時候基本上是這樣 就是以黃仁勳為中心嘛 他的第一層最外圍是這個 一些NVIDIA的人吧 或是他的保鏢之類whatever 那在那層之外呢 有厚厚的好幾層大概三四層 全部都是記者 他們就拿著他們的這個恆大支的相機 就一直對著黃仁勳 就把他包圍住一直對著他 然後不管他去哪裡 這幾圈的人都完全不會動 所以基本上黃仁勳周圍已經多了一顆球這樣 然後其他人呢當然就是在附近在等待的 在想跟黃仁勳拍照的這些人呢 就是在比較外圍嘛 然後這顆球呢就有點像是一個磁鐵一樣 會一直把這些外圍的人吸進去 然後把他黏進這顆球裡面 讓這顆球變得越來越大顆 然後越來越大顆之後 又把越來越多的人給黏進去 然後這個技嘉的攤位呢 他並不是完全開放式的
(09:12~10:14) 他有一定的這個空間 然後到了最後這顆球大到最大的時候 基本上所有Gigabyte攤位上面的所有人 第一個你完全沒有任何移動的空間 你的手只能往上伸或往下伸 周圍都會碰到人 四周全部都擠滿了人 無時無刻你就是被周圍的人擠著這樣 也就是說呢所有人都變成了那個球的一體嘛 所有攤位的人全部都變成一體了 然後我本人呢當然也是這顆球的一部分啊 我是在比較外圍的這個部分 那所以想當然啊我是沒有辦法跟他打招呼這樣 但更恐怖的是當這個華人訓要往外走的時候 他就是把這個衝擊波 他首先他的這個外圍的第一層這些人呢 就會開始往外推 就一直大喊然後說 往前走往外走往外走一直一直推推推 然後他們他們推第一波的人 第一波的人就往後倒 然後就是推到後面的人
(10:14~11:15) 然後在這波衝擊波就慢慢被傳出去這樣子 然後這個衝擊波傳到我的時候真的是 我已經是非常高大了 我185然後也很壯可能90公斤吧 但我往後我還是會不由自主的一直往後倒 就是被前面的人推這樣 然後四周人都一直壓著 把像這個三明治一樣把你夾在裡面這樣 然後各種的這個體位混雜 所以真的現場是蠻恐怖 但我是有看到這個華人訓本人啊 他真的是很帥一頭白髮超級有型的這樣 然後也看到他的這個簽名 所以說我覺得是蠻有趣的一個體驗啊 那跟他比起來呢 我現場也有看到Lisa Su這個蘇志峰 那蘇志峰我是在這個ROG的攤位看到 然後現場呢我覺得他的人大概是 華人訓的一半而已 就是他周圍圍繞著的人這樣
(11:15~12:18) 當然也是有蠻多人就是要擠過去 跟他拍照什麼東西的 但絕對沒有華人訓那麼crazy 然後同時我也有看到Pat Gelsinger Intel的CEO 那他的人呢又是蘇志峰的一半 當然這可能也是因為 我看到他的時候他剛好要上樓之類的 他可能在攤位的人是多一點點 但我覺得無論如何 一個不可否認的事實就是這三個 就是那天來的所有CEO裡面 最紅的就是黃仁勳 而且是比其他人紅非常非常多 尤其是在這個台灣的媒體這邊 我相信絕大部分的這個篇幅都是在報黃仁勳 他現在真的是變成一個rock star一樣 你上次看到一個tech CEO 在女生胸部上簽名是什麼時候 我是想不到啦 然後我覺得很大一部分他的名氣很明顯 當然就是來自輝達的股價暴漲 那為什麼會暴漲呢
(12:18~13:18) 主要就是因為他們在Data Center AI Compute這邊的業務 我覺得那時候他們剛超過Google、Amazon的時候 我就已經覺得太扯了 Google跟Amazon他們的業務這麼多 Google有雲端業務有廣告業務 然後現在多了AI業務 Amazon也有雲端最大的雲端 也有零售什麼的這麼多的業務 然後NVIDIA就是做一個顯卡就超過他們的市值了 真的是不得了 然後他們現在竟然又超過蘋果 真的是不可思議不可思議太厲害了 那我覺得這個話題正好可以切入我這個禮拜要跟大家聊的一些主要內容 那這個禮拜主要就是想跟大家聊 我這個禮拜在Computex聽的三個keynote 包括黃仁勳在台大的演講 雖然說這個是Computex聯名keynote 可能不算Computex主要keynote之一 除此之外就是AMD的數字封
(13:18~14:19) 然後還有Intel、Pack Elsinore的keynote 那我們就先從這個黃仁勳的keynote出發 來聊一聊這個AI Data Center這邊的業務 因為AMD跟Intel也有在他們的keynote 發表他們的一些Data Center AI Compute這邊的一些新的資訊 或者是新的更新 所以說我們可以整體來聊一聊 主要就是聊說究竟AMD跟Intel離NVIDIA還有多遠 為什麼跟NVIDIA差這麼多 然後未來究竟如何這樣子 除此之外呢 我也會帶到一些NVIDIA有的但AMD、Intel沒有的一些業務 像是Omniverse 也有Vise versa AMD跟Intel有的 然後NVIDIA沒有的 像是這個AIPC這邊的一些CPU的部分這樣 那這個keynote聊完了之後呢 我再來跟大家分享一些其他的 我的Computex逛展的體驗這樣 好那我們就先從這個老黃的keynote開始
(14:19~15:19) 那老黃這次的keynote呢我有到現場看 但我必須說其實他整個keynote 他並沒有發表任何新的東西 唯一有一個我們之前沒有聽他講過的 就是他說下一代的架構會叫做Rubin 但也就只有這個名字而已 對於他的specs之類的我們其實也沒有知道什麼 然後其他的東西發表的東西都一模一樣 跟他今年的GDC是一模一樣的 就是包括他再講一次這個Blackwell啊 他的GB200MVL72的這個伺服器啊 然後他的這個Omniverse的一些新功能 Robotics的一些願景這樣子 所以說基本上都差不多啦 那AMD跟Intel的keynote其實是有發布新的東西的 但現實是非常殘酷的 儘管這個AMD跟Intel的keynote是真的有發布新的東西 他們的聲量還是比不過黃仁勳的keynote 而且是差非常多 不管是網路上討論的聲量還是 AndriX這個YouTube看這個觀看次數
(15:19~16:21) 真的是差超級多的 所以黃仁勳這次演講內容的部分我就不再重複了啦 你如果想要多去了解這個Blackwell的平台 你就去聽科技狼的EP32 那你如果想要多了解這個Omniverse這邊 你就去聽科技狼的EP33 雖然說我比較focus在機器人啦 但那個可能是Omniverse的一部分這樣 我覺得我們今天可以聊的是 究竟為什麼NVIDIA可以一間公司獨霸這個AI Compute的市場這麼多 因為這是我最近又開始接到的一個問題 有些人問我說 他們看了AMD跟Intel的發表會 他們就知道其實AMD跟Intel的這些AI Accelerator 其實好像感覺沒有跟NVIDIA的這些H100這種GPU AI Accelerator GPU差那麼多喔 就是你單論算力啊還是論記憶體啊 其實都沒有差甚至有稍有過之 對不對稍微贏過一點點
(16:21~17:23) 然後他們的價格也是便宜非常多的嘛 AMD的MI300系列就是便宜很多 然後Intel的高底2跟3又更便宜非常多 就是他們這次有算是有公佈他們高底2跟3的定價 然後基本上就是NVIDIA的H100的大概1-1.3分的等級這樣 所以這些東西這麼便宜 然後你單論他們的這些Spec好像也沒有差這麼多 那究竟為什麼整個AI Computer市場都是這個 目前來看都是NVIDIA在吃呢 整個股價在漲啊也都是在漲NVIDIA而已 我覺得下次你被問到這個問題你就講兩個重點 第一個重點是軟體第二個重點是Networking 這兩個邊真的是差很多 硬體這個部分呢 我覺得單純看單張的晶片它的算力
(17:23~18:24) 然後它的記憶體這些東西AMD真的沒有輸NVIDIA這麼多啦 但是在軟體跟Networking這邊真的是舒慘了 先從軟體這邊開始 我們這邊講的軟體呢是能夠讓AI Engineer他們寫的這些AI的Code 能夠最有效最優化的在GPU上面跑的軟體 那在NVIDIA的生態系呢這個軟體是叫做Cuda 那這個Cuda呢具體來說呢你可以把它想像成它的運作是這樣子 就是一個AI Engineer他先寫一個AI模型的Training Script好了 這個Training Script他就是用Python寫 Python然後PyTorch的套件去寫 那他寫出來的這個Code是非常非常高層次的 就是他用Python這個很接近人類的語言去定義一下這個模型它的架構啊 它有幾層啊然後它的這些Training啊這樣 然後怎麼Process資料啊這些東西
(18:24~19:24) 就是非常高層次把這些東西定義出來 那PyTorch接下來會負責的就是把這些比較高層次的指令轉換成一些數學的運算 因為這些指令下面他要做的其實就是一些數學運算 那接下來呢Cuda會再把這些數學運算變成是能夠最優化最平行化的 在NVIDIA GPU上面執行的這種型態 嚴格來說是把它變成這些Cuda Kernels 這種Kernels就是GPU可以直接執行的這些指令啊這樣子 那Cuda這個程式呢其實真的是非常非常難寫的 很難開發的一個軟體 因為這個GPU是極度複雜的 然後你要怎麼樣最有效最優化的在GPU上平行的執行這些數學的指令呢 這是這個很堅身的一門學問 然後除了這些Kernels啊這些指令本身啊 你也要有一個Compiler去Compile你的這些Code
(19:24~20:25) 然後你也要有這些Library的Documentation 要有這個API 也有一些Debugging Tool 要有就是完整的這種工具包 才能讓開發者能夠使用你的軟體嘛 那這個儘管你都有了這些之後呢 你也是要花一點時間慢慢的去培養你的生態系對不對 把這個開發者數量培養起來 然後慢慢的跟這些主流的Library做整合 像是這個Pytorch跟Cuda就有非常高程度的整合對不對 我剛剛講的那個流程啊 就這個AI Engineer寫完Code之後 其實他的工作就結束了 他不用寫到Kuda Kernels 那些東西都已經跟Pytorch做整合了 你只要在Pytorch上面定義說你的Device是Kuda這樣子 他就知道要用Kuda去執行你這些Code這樣子 那從這裡你就可以看到說 你要開發Kuda這種軟體 並且把整個生態系給建立起來呢 真的是要花時間的
(20:25~21:26) 然後NVIDIA呢從2006年就開始做這件事情了 2006年也是剛開始做Kuda 那時候其實還沒有Focus在AI這邊 但他在2012年之後呢 這個Kuda就開始越來越多AI的Library出現了 然後AI的Support程度越來越高 那在過去這十幾年NVIDIA已經不知道投了多少錢 多少小時的人力在開發Kuda 一直讓他變得更好更好 直到他現在已經變成了AI訓練的主流 有幾百萬個Developer在使用Kuda 開發他們的軟體或者是做他們的科學研究這樣 那AMD這邊呢也有一個他們Kuda相對應的產品 叫做Rockam 但是他們是在2016年才開始Develop Rockam 應該說2016年他是第一次釋出Rockam 所以NVIDIA是比NVIDIA更加有名的 NVIDIA是比AMD早了十年這樣 然後在最新的雖然說我沒有用過Rockam
(21:26~22:27) Kuda我也沒有就直接寫過Kuda kernel 我是間接的透過Pytorch使用過 但我有看到去年年底的時候 有一個網路上有一個工程師在比較Rockam跟Kuda 那他是拿其中一個兩邊都有的Library去進行比較 那他比較出來的結果就是 兩邊的Performance有差 這個Rockam的是比較慢的 然後這個Support Developer Support跟Documentation也差非常的多 就是這個Kuda有非常完整的生態系 完整的支援 那Rockam這邊的Documentation就比較殘缺一點 然後網路上也比較找不到什麼其他的Support或支援這樣 那當然這個整合的部分 就是跟一些主流工具整合的部分這邊又差更多 所以這個Rockam跟Kuda現在還真的是 還是有一段距離啦 那雖然說這個Suma呢 他走的是一個開源路線 他是說他要集結大家的力量 一起去讓Rockam變得更好這樣子
(22:27~23:28) 但我覺得這種事情還是需要花時間啦 因為這種軟體真的是非常非常技術 非常非常複雜的一個軟體這樣 那AMD這邊是這樣 那Intel這邊就更不用說了 他其實真的 我覺得他沒有什麼非常好的這種軟硬整合的軟體Solution 他是有一個 就是他在Keynote裡面他有講到 欸我們有OpenVINO OpenVINO他就是一個 能夠讓你在Intel的晶片上面跑一些 這個AI模型的韓式庫這個工具包這樣子 那我自己是有用他 就是他會可以用你的Intel的這個IGPU 你的內顯或者是你的CPU去跑這樣 那我是有用他跑過一些這個 StableDiffusion或者是 比較小一點的LLM 那他主要其實就是拿來做Inference而已啊 就是這個AI模型的推論嘛 他其實在這個AI模型的訓練這邊 其實沒有什麼支援的
(23:28~24:28) 那這個就跟Cuda還有Rockam就差很多 所以這個更不用講啦 反正第一個NVIDIA領先AMD跟Intel很多的地方 就是在軟體這邊 那第二個呢我剛剛講的是Networking對不對 這邊又差非常的多 那我覺得這邊同時也是蠻多人 有一點忽略的部分啊 當然你在業界裡面的人就不會忽略這一點 但是大部分人講NVIDIA的Mode 就是NVIDIA的互成盒 可能就是講說他的這個Cuda的軟體的互成盒 對不對 但他在Networking這邊的互成盒也是非常非常強的 這個Networking就是連線的意思嘛 兩台電腦之間怎麼樣去連線傳輸資料這樣 那我先跟大家先給大家一個概念 就是為什麼Networking在AI的訓練這邊是非常重要的 那首先呢我們現在在訓練這些AI模型 都有兩個特點 第一個就是他們超級的大 然後第二個就是他們要用到超級大量的資料 對不對
(24:28~25:28) 那這兩個規模這個模型大小的規模 跟訓練資料的規模都是我們前所未見的 就是在生成式AI大型元模型這波技術出來之前 我們從來沒有就是訓練過任何AI模型 會需要這麼大量的這麼大規模的資料跟模型這樣 那模型大到這種程度 就是可能幾百GB甚至上千GB這樣子的一個大小呢 就會多了一個新的挑戰 就是在一個GPU裡面放不下 因為像是NVIDIA H100的GPU呢 它的記憶體就是它的HBM就只有80GB 那你要塞個幾百GB的模型你當然塞不進去 這時候你就會需要拿好幾個不同的GPU 才能裝下一個AI模型 也就是說你要把一個AI模型切成幾個不同的小塊 然後放在這些GPU上面 那這個動作呢我們把它稱作Model Parallelization 這個模型的平行化 那同時呢你的訓練資料也很大對不對
(25:28~26:30) 你通常訓練一個大型模型 你要用到幾trillion的Token 甚至幾十trillion的Token 這麼多的Token 那這個時候呢一個做法就是讓你的模型 因分身之數你copy出很多個這個模型 然後同時讓他們去訓練不同part的資料 就假設你copy出五個你現在要訓練的這個模型 然後把五分不同的資料分別丟給他們 讓他們同時去訓練不同的資料 這樣子你才可以訓練的比較快 才會更快的把這個你的龐大的資料集給消化完 那這個動作呢叫做Data Parallelization 這個資料的平行化 那你今天呢如果想要很好的做到這兩種不同的parallelization 你就要非常好的networking 你首先這個Model Parallelization這邊 因為你的模型被拆在幾個不同的GPU上面 所以你在跑一個training步驟的時候 就假設你今天是五個GPU去hold 這一個模型 你今天在跑一個training的step
(26:30~27:31) 你必須處理完了那個資料之後呢 不管你今天是做forpass還是backpropagation 要把資料丟給下一個GPU再去training 然後再丟給下一個GPU 然後一直丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟丟� 第一個這一番跟阿酸哥 assault 就是結束以後 直播我給你跟大家講一下 這裡其實一素裝的 你首先要看個GPU 那這時候你要很多很多不同的這種伺服器的架子 然後 甚至好幾排 同時在訓練同一個ura模型這樣子 應該說訓練同一個iva模型 但是訓練它們的不同的分身這樣子 好 nesse個時候呢
(27:31~28:32) 不同伺服器的 ​​​ track 之間的這個連線 也要做得非常好 為什麼 因為你 這麼多模型的分身 每一個分身 他這一次訓練的結果要先丟回去給一個中央大腦中央的這個處理器 先這個中央處理器先把所有分身的訓練結果匯集在一起之後 做一個Average做一些數學處理 然後再把這個結果再丟回給所有的這個模型去更新他們的權重 更新完了之後他們才可以進行下一步的訓練 也就是你不同伺服器架子之間這個Rack to Rack的Networking也要做得非常好 也要做得很快你才可以趕快把這個Training Step給結束掉嘛 才趕快進行下一次 所以這邊你就可以看到Networking的重要性了 其實你在訓練一個AI模型的時候你真的60%以上的時間你都是在等資料流來流去而已 像你在訓練一個AI模型的時候跑一個AI模型的Training Step
(28:32~29:36) 他要等到第一個Part流到下一個Part再流到下一個Part 這個資料流動是需要時間的 然後你所有模型訓練完之後結果要匯整在一起 然後再做一個數學運算然後再重新分配回全部的模型 這個過程中是要有一個All to All的Connection 所有GPU的結果都要被匯整在一起 而且這些很多這些GPU是分身在不同的伺服器架子甚至不同排之中這樣子 假設你的Networking技術不好 這些GPU to GPU的Networking跟RAC to RAC的Networking是非常慢的 你今天訓練一個AI模型不管你的GPU的算力多高 你的記憶體有多大你都會算得非常非常的慢 NVIDIA在Networking這邊的技術真的就是一流的 超級超級強 首先是這個GPU to GPU這邊 它有一個自己的技術叫做NVLink 可以非常快速的連接這些GPU
(29:36~30:38) 甚至讓這個軟體把這些所有的GPU都當成一顆GPU 像是老黃最近在GDC還有台大的演講裡面 他都有展示這個身高跟它差不多高的這一台長方形的大的伺服器 叫做GB200MVL72的伺服器 這個伺服器中間有好幾層黑色的Node 那些都是所謂的NVLink Switch 然後整架伺服器背後它有一條脊椎 它就是把它叫做NVLink Spine 這兩個東西都是在使用NVLink把這些所有的GPU 用非常高的頻寬連結在一起 多高呢?1.8TB per second 真的快到嚇死人了 超級高的頻寬把這些所有的GPU全部都連在一起 讓軟體直接把它當作是一塊GPU 那這個NVLink是Link GPU to GPU 我剛剛講到Rack to Rack也很重要
(30:38~31:40) 那NVR在Rack to Rack這邊又更厲害了 那通常這種Rack to Rack的Networking的通訊協定有兩種 一種是以太網路Ethernet 另外一種是Infiniband 那這個以太網路是最通用的 不管是小型企業大家自己在家裡還是資料中心 都是用這個以太網路進行連接 但同時它的速度是比較慢的 另外Infiniband它是比較快的而且快很多 因為它原本就是設計給一個Data Center裡面 在做HPC運算的 就是High Performance Computing 這樣子運算的Application的一種通訊協定 那在2022年之前 這個資料中心裡面沒有人Care Infinite Band 就除了一些特定的HPC的應用 就大家沒有在Care Infinite Band 大家都覺得Ethernet就夠用了 你這個Rack to Rack的Interconnect要快到這種程度幹嗎
(31:40~32:40) 又沒有任何的應用是需要你同時用到很多個Rack 然後中間要非常高速的連接的 這種東西不存在啊 所以Ethernet就夠用啦 但是老黃不一樣 老黃眼光卓越非常英明 在2019年還有2020年的時候 他就把Infiniband裡面最重要的一間公司 就是開發這個技術的最主要的公司 叫做Mellanox 我記得是一間以色列的公司給買了下來 那時候大家不知道為什麼他要買Mellanox 你幹嘛啊 你在做夢啊 又沒有什麼Application是需要用到這麼高速的Rack to Rack Interconnect 沒想到2022年這些大型元模型出現了 然後大家突然發現完蛋了 這個伺服器跟伺服器Rack之間的網路連線也要非常快 那這個時候呢 老黃就跳出來說 兄弟們Infiniband在我手上 就好像是Infinity Stones一樣 無限寶石一樣
(32:40~33:43) 就哇這個資源已經被我買下了 我們現在所有的這些DGX的System 都有Infiniband的Connection 可以一秒做到800GB per second 那其他的這些資料中心沒有Infiniband的 就用這些以太網路做可能300 400GB的Connection 所以老黃那個時候就買了Mellanox 我覺得真的是一個非常非常有遠見 是超棒的一個併購 可能是NVIDIA歷史上最棒的一個併購 我不知道 總而言之NVIDIA不管是GPU to GPU的Interconnect 有這個NVLink 還是Rack to Rack的Networking 有Infiniband 當然他們現在還有Ethernet 這個我待會再講 反正NVIDIA的Networking技術是非常非常先進的 相較之下我們來看AMD跟Intel 他們在Networking這邊 當然就落後NVIDIA非常非常多 他們現在的做法就是搞聯盟 在GPU to GPU這邊
(33:43~34:44) 他們是搞了一個聯盟叫做Ultra Accelerator Link Consortium 其實我不知道中文叫什麼 超級加速器連接聯盟之類的 這個聯盟他們主要的目標就是 做出一個類似NVLink這樣子的東西 然後把它變成業界標準 就是一個標準的連接AI Accelerator的方式 有參與這個聯盟的公司很多 就是從AMD以外 還有Brotcom還有Cisco Google HPE Intel Meta還有Microsoft 這些公司輕一色看過去 大部分都是自己有在做AI加速晶片的 或者是周邊的產業 裡面很明顯的當然沒有NVIDIA NVIDIA就是這個聯盟要打敗的壞人 另外在Rack to Rack這邊 他們有另外一個聯盟叫做Ultra Ethernet Consortium 中文就叫做超以太網路聯盟
(34:44~35:44) 這個我有查到中文 這個超以太網路聯盟 從它的名字你就可以看出 它是要把以太網路連接 連接Rack to Rack的Networking的速度加速 更具體的來說 更技術的來說 它是要在以太網路上做出更好的RDMA RDMA就是Remote Direct Memory Access 也就是一個GPU的記憶體 能夠直接跟GPU記憶體溝通 不用透過CPU來操作的技術 Infinite Band對於RDMA是有原生的支援的 因為它原本就是為了High Performance Computing 我一直每次都念錯 High Performance Computing來設計的 Ethernet不是 Ethernet沒有原生的RDMA支援 這也是為什麼Ethernet會比Infinite Band慢的主要原因之一 這個超以太網路聯盟
(35:44~36:45) 就是想辦法讓Ethernet的RDMA支援 可以做得更好 因為目前其實是有方法在Ethernet上面做RDMA 你可以用一個叫做ROCE的協定 但這個協定有一些缺點、缺陷 這邊的細節我就不進入了 其實也不是我的專業啦 我也不確定自己可不可以講得很好 反正你就知道這個聯盟主要的目的 就是要做更好的Rack to Rack的Interconnect 來打敗NVIDIA的Solution 我剛剛講到其實NVIDIA在Rack to Rack這邊 也是有推出Ethernet的Solution 因為Ethernet算說比Infinite Band慢 然後你要把它做得跟Infinite Band一樣快 你有很多很多技術挑戰要突破 但是Ethernet畢竟還是最普遍的Solution 很多的資料中心 它可能不會想要Switch到Infinite Band的Connection 所以NVIDIA這邊其實也是有推出
(36:45~37:48) 用Ethernet連接他們DJX System的選項 當然他們就是有做到更好的RDMA 這個他們已經做到了 超以太網路聯盟要做的事情 他們應該是已經做得89%了 甚至超過I don't know 畢竟他們有這些Metal Knox的資源 但我覺得儘管如此 我覺得以太網路應該還是比不上Infinite Band 因為這個其實我不是很確定 這也不是我的專業 但我自己看到是這樣 我看到Computex有展示的NVIDIA以太網路的Solution 我記得好像是400GB per second 然後Infinite Band的同樣的狀況之下 Infinite Band可以做到800GB per second 所以是直接插了一倍這樣子 但我不確定理論上以太網路究竟能不能做得跟Infinite Band一樣快 這個就請高手解答這樣 AMD跟Intel他們的兩個聯盟目前的進度如何呢
(37:48~38:49) 首先GPU to GPU這邊的Ultra Accelerator Link聯盟 他們目前的進度是他們上禮拜才成立 他們上禮拜才剛剛成立這個聯盟這樣子 所以進度就我們在期待 Rack to Rack這邊超以太網路聯盟 他們的進度是他們已經成立一陣子了 我忘記可能一兩年前嗎 還是更早就成立了 他們有一個進度就是今年Q3的時候他們要發布1.0的版本 所以基本上在幾個月後大家就可以期待看到 超以太網路聯盟的第一版的協定 大家就可以看一下這個速度究竟有多快 然後跟Infinite Band還差多遠 這樣子你就可以大概知道這些公司跟NVIDIA的差距 我覺得在Networking這邊我們也簡單做個小結 NVIDIA在AI Compute的Networking這邊是領先AMD跟Intel非常多的 主要就是因為首先對於AI的運算來說
(38:49~39:49) 因為我們要算的模型很大 然後要訓練的資料很多 所以我們要進行Model Parallelization跟Data Parallelization 這兩種Parallelization分別會使用到非常高的GPU to GPU的Networking 以及Rack to Rack的Networking這樣子 NVIDIA在GPU to GPU的Networking跟Rack to Rack的Networking都比AMD跟Intel領先很多 GPU to GPU領先是因為他們有NVLink的Solution Rack to Rack這邊領先是因為他們有Infinite Band的Solution 而且他們在以太網路這邊也是有做一些開發 AMD跟Intel在GPU to GPU這邊比較慢 比較慢因為他們才剛成立一個聯盟要開發類似NVLink的東西 Rack to Rack這邊他們也比較慢 因為他們今年Q3才要發布第一版的以太網路 新版以太網路這樣子
(39:49~40:51) 速度多快也不太確定 好的所以說NVIDIA就是因為軟體的領先以及Networking技術的領先 才能在AI這一波遲到絕大多數的市場份額 雖然說我剛剛講了尤其是Networking這邊 其實是比較跟AI的訓練有關的 AI的推論又是不太一樣的場景 這邊我們就不要再繼續講下去了 因為我們要再講下一個話題了 我剛剛有說NVIDIA在Computer Text Keynote 其實真的沒有發布新的東西 有發布新的東西的是AMD跟Intel 他們發布了什麼東西呢? 其實蠻多的 從Data Center這邊的CPU或者是GPU都有一些新的資訊 然後在消費者這一端比較大的發表就是AIPC這邊
(40:51~41:54) 就是Intel跟AMD都有發表他們下一代的AIPC的SOC AIPC的晶片 我覺得在Enterprise這邊 Data Center這邊剛剛已經講太多了 雖然說我們剛剛都是Focus在AI這邊 但其實其他的Data Center應用 我覺得也不夠吸引人 老實說大家都是在想聽AI的東西 Enterprise這邊我們就先不講 我們來講講消費者這邊 就是他們新的AIPC的晶片 Intel是發布了Lunar Lake的晶片 這代晶片跟上一代的Meteor Lake晶片比起來是進步蠻多的 從能源效率這邊 他們只要花比Meteor Lake少40%的能量 但是可以有3倍的AI Performance 在NPU這邊他們也是進步了3倍 他們現在是有48Tops的NPU GPU這邊也進步非常多 他們有新的GPU G2的Core
(41:54~43:01) 比上一代比起來是50%的進步 AMD這邊也是出了他們新的Ryzen AI300的SOC SOC就是這種筆電的晶片 融合了CPU、GPU、NPU的晶片 這個Ryzen AI300是基於他們新的Zen5的架構 他們的NPU有50Tops 比Intel的Lunar Lake 也比高通的Snapdragon X Elite還要高 Intel跟AMD的這兩張晶片 當然也都是要裝在Microsoft的Core Pilot Plus PC裡面 所以第一波的Core Pilot Plus PC 裡面應該會是高通的那一張 但接下來的一波呢 就會是這兩張晶片了 也就是說這三張晶片就是第一代的Core Pilot Plus PC 可以這樣說 這三張晶片究竟誰好誰壞 我們就等他們真的出來了 消費者用到了之後 再來聽聽大家的Feedback
(43:01~44:04) 然後聽聽這些PC的Reviewer他們跑的一些Benchmark成績 但我自己老實說我真的是蠻想要入手一台的 因為這次之前我有用過 Intel上一代的Core Ultra的這個晶片 就是Meteor Lake的這個晶片 那他的NPU是現在這一代AIPC的SOC的三分之一 剛剛有說了 那其實他是真的做不到什麼事情 就是他最多就是幫你背景模糊一下 延伸對焦 這種小小的功能這樣子 但我覺得現在到了這個 這個NPU進步了三倍 來到這個40級level的這種Tops 我覺得真的會變得有用很多 然後我也很想要從最一開始就參與這一波新的AIPC的浪潮這樣 因為他們現在的狀況就是 我們這個先從基礎設施開始 我們把這些硬體的基礎設施做好了之後
(44:04~45:06) 接下來慢慢上面的這個軟體的應用就會慢慢出現了 我是想要參與這個上面的軟體慢慢出現的整個過程 我覺得蠻酷的 所以我是蠻想要買一台的 這個到時候就再看哪一台比較好 最後我覺得我們還是回到Computex這個展覽本身 我可以分享一些我自己在逛展的時候 一些比較印象深刻的我覺得蠻酷的東西這樣 首先第一個我覺得很酷的就是 我可以親眼目睹到NVIDIA最新的這些伺服器 GB200 NVL72 那這個NVL72的伺服器呢 你如果有看NVIDIA他們在GTC或是華人訊在台大這些Keynote 他們中間都有一段 他們這個晶片慢慢的組裝 慢慢的組裝直到變成一個Data Center的這個影片 大概兩分鐘的動畫影片這樣子 那這個NVL72就在中間的一個過程中有出現
(45:06~46:08) 它是一個就是跟一個人差不多高這樣子大的一個伺服器 然後裡面呢有72個Blackwell的GPU 然後還有36個NVIDIA他們自己做的Grace的CPU 那他們這些所有的GPU呢 想當然啦 當然就是用NVLink做互相連結這樣子 剛剛在講那邊的時候也有講到 它背後還有一個NVLink spine 把它們全部連在一起對不對 那這個超級強大 能夠直接運算照集參數的大型元模型的這樣子的一個伺服器呢 平時呢當然就只能在他們的Keynote的YouTube影片裡面看到嘛 或者是在網路上的一些照片 但在Computax你在很多很多的這個NVIDIA Partner的Booth Partner的攤位裡面 你可以實際看到這一架伺服器 然後我看到了好多台 我真的覺得超酷的 然後每一台華人訊都有去親筆簽名 你在旁邊都會看到 華人訊寫說Jensen is here 或者是Hi Blackwell 之類的有的沒的 他又寫這些東西
(46:08~47:09) 然後不管是在哪一個Partner的攤位 就是不管是在技嘉 還是在這個InventTech 還是在還有什麼Supermicro 你都會看到這台機器周圍圍了一大堆人 這些機器旁邊周圍總是有很多的人 大家也不知道是去看Jensen的簽名 還是去看這台機器本身 真的是Data Center界的明星 除此之外當然也是可以看到 AMD的伺服器 然後Intel Gaudi的伺服器 上面也都有Lisa Su跟Pat Gelsinger的簽名 我覺得是蠻酷的 然後我覺得這些攤位裡面的這些員工 這些工作人員也都很好 他們非常友善 你只要過去就算你不主動跟他打招呼 他有時候也是會直接問你說 你有什麼問題嗎? 還是什麼東西的 有時候因為很多Computex業界人士都會去 所以有時候我也會直接就站在旁邊聽他們討論
(47:09~48:13) 我自己其實也不知道要問什麼 我只是去朝聖一下 除了這些Data Center這種比較Enterprise的東西以外 現場當然Consumer的東西也有非常非常多 就是從桌機的每一個parts 你在現場幾乎都看得到 從主機板到機殼到顯卡 現場都有一大堆 我覺得我在看這些冷卻技術的時候 我真的是覺得有點讓我想自己組一台桌機 因為他們現場的那些 不管是水冷的系統還是風冷的系統 我覺得做的超帥的 尤其有一些水冷系統 看起來根本像一個化學實驗室一樣 搭配一些很有造型的主機殼 真的是看起來超帥的 我覺得在家也可以放一台這個東西 真的是很讚 一直以來我都沒有自己組過桌機 所以我其實看完這次的Computex 有點讓我想組桌機
(48:13~49:17) 然後我搞不好接下來這兩個禮拜就會組一台出來了 Maybe如果有時間的話 當然除了這個桌機以外 筆電也是有超多的 所有的大品牌都在那邊 包括ASUS Acer 尤其他們的電競品牌 ROG跟Peditor 有看我IG的就知道這些攤位裡面 都有很多這些NVIDIA的技術 我IG的那些影片都是NVIDIA贊助的沒錯 但這集Podcast不是NVIDIA贊助的 我沒有必要一直講NVIDIA 但NVIDIA的東西真的就是這次Computex的明星 我必須這麼說 就是從伺服器、Enterprise這邊到Consumer這邊 這些筆電、電競品牌 他們裡面都有一個NVIDIA技術展示的一個區域 沒錯我有接到NVIDIA業配去拍他們的這些東西 但是我真的覺得如果不是沒有接到NVIDIA業配 我還是會去那區玩 因為他們的很多技術展示真的是蠻酷的
(49:17~50:20) 尤其是我最喜歡的一個叫做NVIDIA ACE的技術 NVIDIA ACE技術基本上就是可以幫遊戲角色注入靈魂的技術 你可以讓每個遊戲角色都給他們一個AI驅動的大腦 基本上就是一個大型元模型 跑在雲端這樣子 以後這些角色他們都有自己的人格設定 知道自己的Backstory 知道他們自己有自己人生的記憶 然後也可以記得他跟你講過的所有的話 你不覺得這些角色真的就活起來了嗎? 我覺得這真的就是遊戲的未來 未來的遊戲裡面每一個NPC你都可以跟他自由對話 他們都有自己的靈魂 我覺得這個真的會讓遊戲體驗提升非常非常多 讓每一款遊戲都變得好玩很多 像是他們現場他們有Demo的就是一個偵探遊戲 這個偵探遊戲就是你要跟這個遊戲裡面的一些人 場景是設計在一個旅館裡面 你要是跟這個旅館裡面的人去聊天 然後從聊天過程中試圖去找到一些線索
(50:20~51:22) 去硬逼他們說出一些你要知道的資訊 旅館裡面的角色都有不同的個性 有一個脾氣很差的老頭子 一直叫你走開 有一個畢恭畢敬的貴員 就站在那邊回答你所有的問題 有一個親切的大哥 每個人都有自己的個性 然後你講任何話他都會回 真的是非常有趣 我建議大家可以去看一下我IG的這支影片 就算不想抽獎也沒關係 你可以看一下這個影片的內容 我裡面有展示到 Computex裡面基本上所有是NVIDIA Consumer端的Partner的這種攤位 都會有NVIDIA的展示櫃在裡面 展示一種到四種不同的技術 我剛剛講的除了ROG還有Predator以外 很多其他也有 技嘉也有 這我也有拍 然後Zotac也有 然後Inno3D也有
(51:22~52:22) 然後反正不管是做筆電還是做顯卡的 裡面都會有這種展示 以上就是我覺得我比較印象深刻的部分 我花比較多時間就是在看這些Enterprise的 Data Center這些伺服器 然後還有電競的筆電、電腦這樣子 但除了這些以外 現場真的是非常的豐富 各種東西都有 像我剛剛說的有5G跟AIoT的技術 然後也有一些EdgeComputer的東西 EdgeAI的東西 邊緣AI的晶片這樣子 然後也有車子相關的技術 未來移動 有一個台灣先進車用技術發展協會在那邊擺攤 然後也有沉浸現實 像是他們有一間矽谷的新創叫做AMAS 他們主要是在把平面圖變成3D圖的技術 我覺得也是蠻酷的 然後還有綠能永續 還有一些創新的單位這樣子
(52:22~53:24) 我覺得現場真的是非常非常豐富 除了這些攤位以外 還有演講這些forum 然後不只是Computex主辦的這些 甚至是AI的forum 他們有一些攤位 他們自己也會有自己的talk 自己的一些小小的presentation這樣子 所以現場真的是非常熱鬧 我覺得這次Computex真的是收穫很大 然後讓我也很開心 就是儘管我去裡面很長時間我是在工作 但是我心裡還是感到非常的雀躍 這件事情很少發生喔 通常出差的時候就心裡不會這麼雀躍 但是在Computex裡面 在整個氛圍之下我覺得很棒 然後也很多人來跟我打招呼跟我拍照什麼的 雖然我不覺得我是什麼明星之類的 大家竟然會想找我拍照真的是讓我受寵若驚 但也是很好玩啦 那我真的覺得不管你的背景是什麼 不管你是已經在相關產業從事
(53:24~54:24) 還是你是跟科技也比較沒有那麼大的關係 還是你甚至你只是一個學生 我覺得你都可以來Computex看看 一定有你可以學到的東西 一定有會讓你眼睛為之一亮的東西 尤其你現在都已經在聽科技黨了 想必你一定是對於科技對於AI有興趣嘛 那這個Computex真的是你不能錯過的一個活動 尤其它整個過程全部都是免費的 你免費可以看到這個NVL72本人 你不覺得很賺嗎 超賺的 尤其我覺得我們台灣有Computex這個東西 真的是很難得的一件事情 我們台灣不是湊巧Computex就在台灣辦 並不是剛好全世界最大的科技跟電腦展之一 就是在台灣辦 真的是因為我們台灣跟這個整個Computing的產業 是有非常非常緊密的連結的 從個人電腦到伺服器 整個供應鏈好多好多好多的環節 都有我們台灣的參與這樣子
(54:24~55:00) 沒有我們台灣人類個人電腦的發展 真的不會有現在這樣子的榮景 所以身為台灣人 真的是應該要驕傲的來逛一下這個Computex 期待在2025年的Computex再次見到大家 如果你喜歡這集科技浪的話 歡迎你幫我五星評分 然後留言跟我互動一下 然後也可以把科技浪分享給你的朋友們 下次你朋友在問 為什麼NVIDIA它世界可以三兆 這個時候你就直接跟他說 就是兩個東西 軟體跟Networking 然後直接傳這集給大家就OK了 這集會Speak for itself 最後就祝大家有個愉快的一週
