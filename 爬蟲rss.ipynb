{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e34e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # 定義要移除的非法字符集合\n",
    "    illegal_chars = set('/\\\\?%*:|\"<>.')\n",
    "\n",
    "    # 創建一個映射表，將所有非法字符映射為空字串\n",
    "    translation_table = str.maketrans('', '', ''.join(illegal_chars))\n",
    "    \n",
    "    # 使用 translate 方法來應用映射表，移除非法字符\n",
    "    sanitized_filename = filename.translate(translation_table)\n",
    "    \n",
    "    return sanitized_filename\n",
    "\n",
    "def download_mp3(url, folder_path, filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(os.path.join(folder_path, filename), 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"檔案下載完成: {filename}\")\n",
    "    else:\n",
    "        print(\"無法下載檔案\")\n",
    "\n",
    "def get_rss_file(newsurl, test_n):\n",
    "    \n",
    "    def get_title_name(url):\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            title = soup.find_all(\"title\")[0].text\n",
    "            return sanitize_filename(title)\n",
    "\n",
    "    if newsurl[13:21] == \"firstory\":\n",
    "        response = requests.get(newsurl)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            title = soup.find_all(\"title\")[0].text\n",
    "            title = sanitize_filename(title)\n",
    "            folder_path = title\n",
    "\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            \n",
    "            n = len(soup.find_all(\"item\"))\n",
    "            print(title, \"一共\", n, \"集\")\n",
    "\n",
    "            if n <= 2 or test_n == \"all\":\n",
    "                test_n = n\n",
    "\n",
    "            for i in range(test_n):\n",
    "                time.sleep(random.randrange(1, 5))\n",
    "                mp3_url = soup.find_all(\"item\")[i].find('enclosure').get('url')\n",
    "                name = soup.find_all(\"item\")[i].find('itunes:title').text\n",
    "                sanitized_name = sanitize_filename(name)\n",
    "                download_mp3(mp3_url, folder_path, sanitized_name + \".mp3\")\n",
    "\n",
    "    else:\n",
    "        file = feedparser.parse(newsurl)\n",
    "        title = get_title_name(newsurl)\n",
    "        folder_path = title\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        n = len(file[\"entries\"])\n",
    "        print(title, \"一共\", n, \"集\")\n",
    "\n",
    "        if n <= 2 or test_n == \"all\":\n",
    "            test_n = n  # 下載所有集數\n",
    "        else:\n",
    "            test_n = int(test_n)  # 確保 test_n 是整數\n",
    "            if test_n > n:\n",
    "                test_n = n  # 如果指定下載的集數大於實際集數，則只下載實際集數\n",
    "\n",
    "        for i in range(test_n):\n",
    "            time.sleep(random.randrange(1, 5))\n",
    "            try:\n",
    "                mp3_url = file[\"entries\"][i][\"links\"][1][\"href\"]\n",
    "            except IndexError:\n",
    "                mp3_url = file[\"entries\"][i][\"links\"][0][\"href\"]\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching MP3 URL for episode {i}: {e}\")\n",
    "                continue  # 跳過該集數，繼續處理下一個\n",
    "            \n",
    "            name = file[\"entries\"][i][\"title\"]\n",
    "            sanitized_name = sanitize_filename(name)\n",
    "            try:\n",
    "                download_mp3(mp3_url, folder_path, sanitized_name + \".mp3\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading episode {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "# 測試字符是否為中文\n",
    "def is_chinese(char):\n",
    "    # 判斷字符的 Unicode 編碼值是否在中文範圍內\n",
    "    if '\\u4e00' <= char <= '\\u9fff':\n",
    "        return True\n",
    "    else:\n",
    "        return False      \n",
    "    \n",
    "def get_all_category():\n",
    "    all_cata=['all',\n",
    "     'Arts',\n",
    "     'Arts / Books',\n",
    "     'Arts / Design',\n",
    "     'Arts / Fashion & Beauty',\n",
    "     'Arts / Food',\n",
    "     'Arts / Performing Arts',\n",
    "     'Arts / Visual Arts',\n",
    "     'Business',\n",
    "     'Business / Careers',\n",
    "     'Business / Entrepreneurship',\n",
    "     'Business / Investing',\n",
    "     'Business / Management',\n",
    "     'Business / Marketing',\n",
    "     'Business / Non-Profit',\n",
    "     'Comedy',\n",
    "     'Comedy / Comedy Interviews',\n",
    "     'Comedy / Improv',\n",
    "     'Comedy / Stand-Up',\n",
    "     'Education',\n",
    "     'Education / Courses',\n",
    "     'Education / How To',\n",
    "     'Education / Language Learning',\n",
    "     'Education / Self-Improvement',\n",
    "     'Fiction',\n",
    "     'Fiction / Comedy Fiction',\n",
    "     'Fiction / Drama',\n",
    "     'Fiction / Science Fiction',\n",
    "     'Government',\n",
    "     'Health & Fitness',\n",
    "     'Health & Fitness / Alternative Health',\n",
    "     'Health & Fitness / Fitness',\n",
    "     'Health & Fitness / Medicine',\n",
    "     'Health & Fitness / Mental Health',\n",
    "     'Health & Fitness / Nutrition',\n",
    "     'Health & Fitness / Sexuality',\n",
    "     'History',\n",
    "     'Kids & Family',\n",
    "     'Kids & Family / Education for Kids',\n",
    "     'Kids & Family / Parenting',\n",
    "     'Kids & Family / Pets & Animals',\n",
    "     'Kids & Family / Stories for Kids',\n",
    "     'Leisure',\n",
    "     'Leisure / Animation & Manga',\n",
    "     'Leisure / Automotive',\n",
    "     'Leisure / Aviation',\n",
    "     'Leisure / Crafts',\n",
    "     'Leisure / Games',\n",
    "     'Leisure / Hobbies',\n",
    "     'Leisure / Home & Garden',\n",
    "     'Leisure / Video Games',\n",
    "     'Music',\n",
    "     'Music / Music Commentary',\n",
    "     'Music / Music History',\n",
    "     'Music / Music Interviews',\n",
    "     'News',\n",
    "     'News / Business News',\n",
    "     'News / Daily News',\n",
    "     'News / Entertainment News',\n",
    "     'News / News Commentary',\n",
    "     'News / Politics',\n",
    "     'News / Sports News',\n",
    "     'News / Tech News',\n",
    "     'Religion & Spirituality',\n",
    "     'Religion & Spirituality / Buddhism',\n",
    "     'Religion & Spirituality / Christianity',\n",
    "     'Religion & Spirituality / Hinduism',\n",
    "     'Religion & Spirituality / Islam',\n",
    "     'Religion & Spirituality / Judaism',\n",
    "     'Religion & Spirituality / Religion',\n",
    "     'Religion & Spirituality / Spirituality',\n",
    "     'Science',\n",
    "     'Science / Astronomy',\n",
    "     'Science / Chemistry',\n",
    "     'Science / Earth Sciences',\n",
    "     'Science / Life Sciences',\n",
    "     'Science / Mathematics',\n",
    "     'Science / Natural Sciences',\n",
    "     'Science / Nature',\n",
    "     'Science / Physics',\n",
    "     'Science / Social Sciences',\n",
    "     'Society & Culture',\n",
    "     'Society & Culture / Documentary',\n",
    "     'Society & Culture / Personal Journals',\n",
    "     'Society & Culture / Philosophy',\n",
    "     'Society & Culture / Places & Travel',\n",
    "     'Society & Culture / Relationships',\n",
    "     'Sports',\n",
    "     'Sports / Baseball',\n",
    "     'Sports / Basketball',\n",
    "     'Sports / Cricket',\n",
    "     'Sports / Fantasy Sports',\n",
    "     'Sports / Football',\n",
    "     'Sports / Golf',\n",
    "     'Sports / Hockey',\n",
    "     'Sports / Rugby',\n",
    "     'Sports / Running',\n",
    "     'Sports / Soccer',\n",
    "     'Sports / Swimming',\n",
    "     'Sports / Tennis',\n",
    "     'Sports / Volleyball',\n",
    "     'Sports / Wilderness',\n",
    "     'Sports / Wrestling',\n",
    "     'TV & Film',\n",
    "     'TV & Film / After Shows',\n",
    "     'TV & Film / Film History',\n",
    "     'TV & Film / Film Interviews',\n",
    "     'TV & Film / Film Reviews',\n",
    "     'TV & Film / TV Reviews',\n",
    "     'Technology',\n",
    "     'True Crime']\n",
    "    all_category=[]\n",
    "    for i in range(len(all_cata)):\n",
    "        all_category.append((all_cata[i].replace(\" / \",\"-\").replace(\" & \",\"-\").replace(\" \",\"-\").lower()))\n",
    "    return all_category\n",
    "\n",
    "\n",
    "def get_name_href(category_name):\n",
    "    #抓到總排行榜   全部的網址 跟名稱\n",
    "    rank_list_herf=[]\n",
    "    rank_list_name=[]\n",
    "    # 目標網站的URL\n",
    "\n",
    "    url=\"https://rephonic.com/charts/apple/tw/\"+category_name\n",
    "    # 發送GET請求獲取網頁內容\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # 檢查是否成功獲取網頁內容\n",
    "    if response.status_code == 200:\n",
    "        # 使用BeautifulSoup解析HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 在這裡編寫你的程式碼來處理解析後的網頁內容\n",
    "\n",
    "        # 以下是一個示例，尋找所有<a>標籤並獲取其連結和文字內容\n",
    "        for link in soup.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            text = link.get_text()\n",
    "            if len(text)>0 and is_chinese(text)==True:\n",
    "                #print(f\"連結: {href}\\t文字內容: {text}\")\n",
    "                rank_list_herf.append(\"https://rephonic.com\"+href)\n",
    "                rank_list_name.append(text)\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        print(\"無法獲取網頁內容\")\n",
    "    return  rank_list_herf,rank_list_name\n",
    "\n",
    "\n",
    "\n",
    "def get_rss(url):\n",
    "    # 目標網頁的URL\n",
    "    #url = \"https://rephonic.com/podcasts/li-jing-lei-de-chen-jing-shi-jian\"\n",
    "\n",
    "    # 發送GET請求獲取網頁內容\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # 檢查是否成功獲取網頁內容\n",
    "    if response.status_code == 200:\n",
    "        # 使用BeautifulSoup解析HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 尋找包含RSS網址的元素\n",
    "        find_rss=soup.find_all(\"\",text=re.compile(\"@context\"))\n",
    "\n",
    "        # 要解析的 JSON 字串\n",
    "        json_str = find_rss[0]\n",
    "        # 解析 JSON 字串\n",
    "        data = json.loads(json_str)\n",
    "        # 提取 identifier 後面的文字\n",
    "        identifier_text = data[\"identifier\"]\n",
    "        print(identifier_text)\n",
    "\n",
    "    else:\n",
    "        print(\"無法獲取網頁內容\")\n",
    "    return identifier_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a566d30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe &amp; Jet 未過濾的 with Jason 一共 34 集\n",
      "檔案下載完成: EP28JJJ回想做Podcast的原因並談未來的方向 JJJ recalled the reasons for starting the podcast and future plans.mp3\n",
      "檔案下載完成: EP27Joe和Jet談到合併與否，以及Jet的新篇章 Joe&Jet talk about merging or lack thereof, and Jet’s new chapter.mp3\n",
      "Error downloading episode 2: [Errno 2] No such file or directory: 'Joe &amp; Jet 未過濾的 with Jason\\\\Episode 26 PT 2 Out Now 林書豪談到了他對球隊的期望以及關於他摔倒要犯規的誤解及如何改變籃球文化 Jeremy talks about what he desires in a team, the misconception of him floppinggetting calls, and how to improve the culture.mp3'\n",
      "檔案下載完成: EP26 PT1林書豪聊在這個賽季中遇到的困難，以及最後拿下冠軍的心路歷程 Jeremy talked about the challenges he faced this season and his journey to ultimately winning the championship.mp3\n",
      "檔案下載完成: Episode 26( Part 2 下集)鼎哥心中最強隊友及對手, 征戰20多年依然還有旅外夢! Who is Ding’s toughest teammate and opponent Is playing in oversea still an option .mp3\n",
      "檔案下載完成: Episode 25( Part I 上集)鼎哥聊2聯盟的差異及當時轉隊過程 Ding talks about the difference between 2 leagues and why he left P League.mp3\n",
      "檔案下載完成: Episode 24 新世代超級球星!充滿爆發力的Ant強還是進攻行雲流水的Shai厲害 This era’s super stars who’s more fun to watch Ant or Shai.mp3\n",
      "檔案下載完成: Episode 23 例行賽將結束,最後一張季後賽門票會由誰獲得 The regular season is about to endWho will get the last playoffs spot.mp3\n",
      "檔案下載完成: Episode 22 ( PartII 下集)：富邦三連霸過後是否已開始重建計劃 After 3peats, is Fubon rebuilding.mp3\n",
      "檔案下載完成: Episode 22 ( Part I 上集)：和蔡文誠討論籃球的專業知識和富邦的困境 We talk basketball knowledge and Fubon’s struggles with Winston.mp3\n",
      "檔案下載完成: Episode 21台灣出現2支職業球隊及全新聯盟! Taiwan having 2 pro teams to participate and compete in a new league !.mp3\n",
      "檔案下載完成: Episode 20 Jeremy回歸國王有機會排名往上爬!聯盟史上第一次全本土出賽 is Jeremy’s return going to help Kings moving up League’s first time ever game being played without imports.mp3\n",
      "Error downloading episode 12: [Errno 2] No such file or directory: 'Joe &amp; Jet 未過濾的 with Jason\\\\Episode 19 ( Part II 下集) 聯盟強隊換人當, 中華隊被菲律賓血洗 53 分後, 是否還有機會重返亞洲 4 強 Have the top teams in Pleague changed Does Chinese Taipei have a chance to become Asia top 4 still after the devastating loss to Philippines.mp3'\n",
      "檔案下載完成: Episode 19 ( Part I 上集) 黑哥聊對JJJ印象深刻的小故事,也分享牧倫斯事件的看法 Blackie talks about stories about JJJ, also sharing thoughts on Byron incident.mp3\n",
      "檔案下載完成: Episode 18 ( Part II 下集) Mike談到P-league+現況還有富邦的困境 Mike talks about P-league and Fubon’s struggles.mp3\n",
      "檔案下載完成: Episode 18 ( Part I 上集) Mike暢談自己的籃球夢和在Big 12聯盟的經歷 Mike’s basketball journey and the Big 12.mp3\n",
      "檔案下載完成: Episode 17 書緯對位亞洲頂級後衛！聯盟最新排名解析、Jet 三個月後的回歸 Matching up with top guards in Asia, league rankings, and Jet’s return.mp3\n",
      "Error downloading episode 17: [Errno 2] No such file or directory: 'Joe &amp; Jet 未過濾的 with Jason\\\\Episode 16 季中年度 MVP、第一隊和最佳洋將預測  攻城獅無預警換教練對球隊是否有正面的影響 !  Mid- season prediction on League MVP, first team and best import Is it a good impact for Lioneers changing head coach during mid-season.mp3'\n",
      "檔案下載完成: Episode 15 劉錚心中的國家隊是什麼模樣 ？The Gavin episode and what he hopes can improve for national team.mp3\n",
      "檔案下載完成: Episode 14  ( Part II 下集) 傑哥的 NBA TOP 5 竟然是 !   聽到偶像 Kobe 離開當下的反應及心情 Who’s on Beast NBA TOP 5 list ! the moment he finds out Kobe passed away and his reaction.mp3\n",
      "檔案下載完成: Episode 14 ( Part I 上集) 年少輕狂的野獸從自我心態到成為台籃唯一的 GOAT ! 41 歲依舊繼續燃燒 ！From young, wild & free to the one and only GOAT of Taiwanese basketball- 41 years old and still counting.mp3\n",
      "檔案下載完成: Episode 13 大學生涯最強賽季 ! Joe 和 Jet 從第一次見面到成為好兄弟 Joe & Jet talk about their college experience, and how their friendship grew since the first time they met.mp3\n",
      "檔案下載完成: Episode 12 排名大亂鬥 ! 除了國王及鋼鐵人其他隊伍每週排名都有可能變動  Ranking Uncertainty! The  ranking of the teams in the middle could be changing every week!.mp3\n",
      "檔案下載完成: Episode 11 敏哥的籃球故事 The story of Amigo’s basketball career.mp3\n",
      "檔案下載完成: Episode 10 先發與替補的角色錯亂 What are the roles of starters and bench players.mp3\n",
      "檔案下載完成: Episode 9 Green 禁賽風波及KD 不滿球隊現況謠言滿天飛! Green’s suspension, rumors bout KD unsatisfied with the team!.mp3\n",
      "檔案下載完成: Episode 8 新年快樂！來聊聊為什麼夢想家現在排名第一？Happy New Year! Why are the Dreamers the top team right now.mp3\n",
      "檔案下載完成: Episode 7 年輕球員的未來有多光明 How bright is the future for young players.mp3\n",
      "檔案下載完成: Episode 6 聖誕特輯 Christmas Special.mp3\n",
      "檔案下載完成: Episode 5 過去2年最大規模的交易誰才是贏家 The biggest trades of the past 2 years, which team won the trades.mp3\n",
      "檔案下載完成: Episode 4 洋將迷思! 得分多才能幫助球隊 在得分與傳球之間取得平衡 The Myth of Foreign players! Could you only help the team by scoring more points Or strike a balance between scoring and passing.mp3\n",
      "檔案下載完成: Episode 3  Joe和Jet一輩子難忘的Kobe memory Joe and Jet unforgettable Kobe memory.mp3\n",
      "檔案下載完成: Episode 2 Joe & Jet 聊第二週及第三週賽事回顧  Joe & Jet talk Week 2 and Week 3 recap.mp3\n",
      "檔案下載完成: Episode 1 Joe & Jet 分享近況也聊聊各自效力的球隊 新北國王與台北富邦.mp3\n"
     ]
    }
   ],
   "source": [
    "# #貼上rss即可下載。＃新資料夾\n",
    "# get_rss_file('https://feeds.soundon.fm/podcasts/ecd31076-d12d-46dc-ba11-32d24b41cca5.xml')\n",
    "# #史塔克實驗室\n",
    "# get_rss_file(\"https://feeds.soundon.fm/podcasts/e4f101be-289a-4101-bb11-59fc61e5c88b.xml\")\n",
    "# #達特嘴哥地圖砲 \n",
    "# get_rss_file(\"https://open.firstory.me/rss/user/ckcdy2bijlk7n0918zfcwxyyr\")\n",
    "\n",
    "#科技浪 \n",
    "# get_rss_file(\"https://feeds.soundon.fm/podcasts/03f4a53e-80cf-4a20-ad2c-bdb31a76c7b3.xml\",\"all\")\n",
    "#老高 \n",
    "# get_rss_file(\"https://anchor.fm/s/3ba51528/podcast/rss\",\"20\")\n",
    "#Joe & Jet 未過濾的 with Jason\n",
    "# get_rss_file(\"https://feeds.soundon.fm/podcasts/78a91a6a-5c6b-43cc-aaac-7918f792e5ae.xml\",\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143fd6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    #先得到所有分類的名字\n",
    "    category_name=get_all_category()\n",
    "    #使用者輸入想跑多少分類\n",
    "    category_n=input(\"你想要跑多少種分類？ 輸入數字，或者all抓取全部\")\n",
    "    if category_n==\"all\":       \n",
    "        category_n=len(category_name)\n",
    "    else:\n",
    "        category_n=int(category_n)\n",
    "    \n",
    "    for i in range(category_n):      #這邊的迴圈  是指定跑幾個分類    \n",
    "        #得到該分類的所有節目名稱跟網址\n",
    "        rank_list_herf,rank_list_name=get_name_href(category_name[i])\n",
    "        #使用者輸入想跑多少節目\n",
    "        rank_list_n=5        #(\"一個分類想要抓取多少節目？ 輸入數字，或者all抓取全部\")\n",
    "        if rank_list_n==\"all\":    \n",
    "            rank_list_n=len(rank_list_herf)\n",
    "        else:\n",
    "            rank_list_n=int(rank_list_n)\n",
    "        \n",
    "        for j in range(rank_list_n):     #這邊的迴圈  是指定跑幾個節目\n",
    "            \n",
    "            #得到該節目的rss\n",
    "            rss_url=get_rss(rank_list_herf[j])\n",
    "            #下載所有節目\n",
    "            get_rss_file(rss_url,3)    #後面的後面的數字   是測試用的時候。要下載幾集。  ＃要全部的集數。 輸入\"all\" \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
