{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e34e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # 定義要移除的非法字符集合\n",
    "    illegal_chars = set('/\\\\?%*:|\"<>.')\n",
    "\n",
    "    # 創建一個映射表，將所有非法字符映射為空字串\n",
    "    translation_table = str.maketrans('', '', ''.join(illegal_chars))\n",
    "    \n",
    "    # 使用 translate 方法來應用映射表，移除非法字符\n",
    "    sanitized_filename = filename.translate(translation_table)\n",
    "    \n",
    "    return sanitized_filename\n",
    "\n",
    "def download_mp3(url, folder_path, filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(os.path.join(folder_path, filename), 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"檔案下載完成: {filename}\")\n",
    "    else:\n",
    "        print(\"無法下載檔案\")\n",
    "\n",
    "def get_rss_file(newsurl, test_n, parent_folder_path=None):\n",
    "    \n",
    "    def get_title_name(url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            title = soup.find_all(\"title\")[0].text\n",
    "            return sanitize_filename(title)\n",
    "    \n",
    "    # 獲取節目標題，並在母資料夾內建立子資料夾\n",
    "    if newsurl[13:21] == \"firstory\":\n",
    "        response = requests.get(newsurl)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            title = soup.find_all(\"title\")[0].text\n",
    "            title = sanitize_filename(title)\n",
    "    else:\n",
    "        title = get_title_name(newsurl)\n",
    "    \n",
    "    # 如果指定了母資料夾，則在其內建立子資料夾\n",
    "    if parent_folder_path:\n",
    "        folder_path = os.path.join(parent_folder_path, title)\n",
    "    else:\n",
    "        folder_path = title\n",
    "    \n",
    "    # 創建資料夾\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    if newsurl[13:21] == \"firstory\":\n",
    "        n = len(soup.find_all(\"item\"))\n",
    "        print(title, \"一共\", n, \"集\")\n",
    "\n",
    "        if n <= 2 or test_n == \"all\":\n",
    "            test_n = n\n",
    "\n",
    "        for i in range(test_n):\n",
    "            time.sleep(random.randrange(1, 5))\n",
    "            mp3_url = soup.find_all(\"item\")[i].find('enclosure').get('url')\n",
    "            name = soup.find_all(\"item\")[i].find('itunes:title').text\n",
    "            sanitized_name = sanitize_filename(name)\n",
    "            download_mp3(mp3_url, folder_path, sanitized_name + \".mp3\")\n",
    "\n",
    "    else:\n",
    "        file = feedparser.parse(newsurl)\n",
    "        n = len(file[\"entries\"])\n",
    "        print(title, \"一共\", n, \"集\")\n",
    "\n",
    "        if n <= 2 or test_n == \"all\":\n",
    "            test_n = n\n",
    "        else:\n",
    "            test_n = int(test_n)\n",
    "            if test_n > n:\n",
    "                test_n = n\n",
    "\n",
    "        for i in range(test_n):\n",
    "            time.sleep(random.randrange(1, 5))\n",
    "            try:\n",
    "                mp3_url = file[\"entries\"][i][\"links\"][1][\"href\"]\n",
    "            except IndexError:\n",
    "                mp3_url = file[\"entries\"][i][\"links\"][0][\"href\"]\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching MP3 URL for episode {i}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            name = file[\"entries\"][i][\"title\"]\n",
    "            sanitized_name = sanitize_filename(name)\n",
    "            try:\n",
    "                download_mp3(mp3_url, folder_path, sanitized_name + \".mp3\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading episode {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "# 測試字符是否為中文\n",
    "def is_chinese(char):\n",
    "    # 判斷字符的 Unicode 編碼值是否在中文範圍內\n",
    "    if '\\u4e00' <= char <= '\\u9fff':\n",
    "        return True\n",
    "    else:\n",
    "        return False      \n",
    "    \n",
    "def get_all_category():\n",
    "    all_cata=['all',\n",
    "     'Arts',\n",
    "     'Arts / Books',\n",
    "     'Arts / Design',\n",
    "     'Arts / Fashion & Beauty',\n",
    "     'Arts / Food',\n",
    "     'Arts / Performing Arts',\n",
    "     'Arts / Visual Arts',\n",
    "     'Business',\n",
    "     'Business / Careers',\n",
    "     'Business / Entrepreneurship',\n",
    "     'Business / Investing',\n",
    "     'Business / Management',\n",
    "     'Business / Marketing',\n",
    "     'Business / Non-Profit',\n",
    "     'Comedy',\n",
    "     'Comedy / Comedy Interviews',\n",
    "     'Comedy / Improv',\n",
    "     'Comedy / Stand-Up',\n",
    "     'Education',\n",
    "     'Education / Courses',\n",
    "     'Education / How To',\n",
    "     'Education / Language Learning',\n",
    "     'Education / Self-Improvement',\n",
    "     'Fiction',\n",
    "     'Fiction / Comedy Fiction',\n",
    "     'Fiction / Drama',\n",
    "     'Fiction / Science Fiction',\n",
    "     'Government',\n",
    "     'Health & Fitness',\n",
    "     'Health & Fitness / Alternative Health',\n",
    "     'Health & Fitness / Fitness',\n",
    "     'Health & Fitness / Medicine',\n",
    "     'Health & Fitness / Mental Health',\n",
    "     'Health & Fitness / Nutrition',\n",
    "     'Health & Fitness / Sexuality',\n",
    "     'History',\n",
    "     'Kids & Family',\n",
    "     'Kids & Family / Education for Kids',\n",
    "     'Kids & Family / Parenting',\n",
    "     'Kids & Family / Pets & Animals',\n",
    "     'Kids & Family / Stories for Kids',\n",
    "     'Leisure',\n",
    "     'Leisure / Animation & Manga',\n",
    "     'Leisure / Automotive',\n",
    "     'Leisure / Aviation',\n",
    "     'Leisure / Crafts',\n",
    "     'Leisure / Games',\n",
    "     'Leisure / Hobbies',\n",
    "     'Leisure / Home & Garden',\n",
    "     'Leisure / Video Games',\n",
    "     'Music',\n",
    "     'Music / Music Commentary',\n",
    "     'Music / Music History',\n",
    "     'Music / Music Interviews',\n",
    "     'News',\n",
    "     'News / Business News',\n",
    "     'News / Daily News',\n",
    "     'News / Entertainment News',\n",
    "     'News / News Commentary',\n",
    "     'News / Politics',\n",
    "     'News / Sports News',\n",
    "     'News / Tech News',\n",
    "     'Religion & Spirituality',\n",
    "     'Religion & Spirituality / Buddhism',\n",
    "     'Religion & Spirituality / Christianity',\n",
    "     'Religion & Spirituality / Hinduism',\n",
    "     'Religion & Spirituality / Islam',\n",
    "     'Religion & Spirituality / Judaism',\n",
    "     'Religion & Spirituality / Religion',\n",
    "     'Religion & Spirituality / Spirituality',\n",
    "     'Science',\n",
    "     'Science / Astronomy',\n",
    "     'Science / Chemistry',\n",
    "     'Science / Earth Sciences',\n",
    "     'Science / Life Sciences',\n",
    "     'Science / Mathematics',\n",
    "     'Science / Natural Sciences',\n",
    "     'Science / Nature',\n",
    "     'Science / Physics',\n",
    "     'Science / Social Sciences',\n",
    "     'Society & Culture',\n",
    "     'Society & Culture / Documentary',\n",
    "     'Society & Culture / Personal Journals',\n",
    "     'Society & Culture / Philosophy',\n",
    "     'Society & Culture / Places & Travel',\n",
    "     'Society & Culture / Relationships',\n",
    "     'Sports',\n",
    "     'Sports / Baseball',\n",
    "     'Sports / Basketball',\n",
    "     'Sports / Cricket',\n",
    "     'Sports / Fantasy Sports',\n",
    "     'Sports / Football',\n",
    "     'Sports / Golf',\n",
    "     'Sports / Hockey',\n",
    "     'Sports / Rugby',\n",
    "     'Sports / Running',\n",
    "     'Sports / Soccer',\n",
    "     'Sports / Swimming',\n",
    "     'Sports / Tennis',\n",
    "     'Sports / Volleyball',\n",
    "     'Sports / Wilderness',\n",
    "     'Sports / Wrestling',\n",
    "     'TV & Film',\n",
    "     'TV & Film / After Shows',\n",
    "     'TV & Film / Film History',\n",
    "     'TV & Film / Film Interviews',\n",
    "     'TV & Film / Film Reviews',\n",
    "     'TV & Film / TV Reviews',\n",
    "     'Technology',\n",
    "     'True Crime']\n",
    "    all_category=[]\n",
    "    for i in range(len(all_cata)):\n",
    "        all_category.append((all_cata[i].replace(\" / \",\"-\").replace(\" & \",\"-\").replace(\" \",\"-\").lower()))\n",
    "    return all_category\n",
    "\n",
    "\n",
    "def get_name_href(category_name):\n",
    "    #抓到總排行榜   全部的網址 跟名稱\n",
    "    rank_list_herf=[]\n",
    "    rank_list_name=[]\n",
    "    # 目標網站的URL\n",
    "\n",
    "    url=\"https://rephonic.com/charts/apple/tw/\"+category_name\n",
    "    # 發送GET請求獲取網頁內容\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # 檢查是否成功獲取網頁內容\n",
    "    if response.status_code == 200:\n",
    "        # 使用BeautifulSoup解析HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 在這裡編寫你的程式碼來處理解析後的網頁內容\n",
    "\n",
    "        # 以下是一個示例，尋找所有<a>標籤並獲取其連結和文字內容\n",
    "        for link in soup.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            text = link.get_text()\n",
    "            if len(text)>0 and is_chinese(text)==True:\n",
    "                #print(f\"連結: {href}\\t文字內容: {text}\")\n",
    "                rank_list_herf.append(\"https://rephonic.com\"+href)\n",
    "                rank_list_name.append(text)\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        print(\"無法獲取網頁內容\")\n",
    "    return  rank_list_herf,rank_list_name\n",
    "\n",
    "\n",
    "\n",
    "def get_rss(url):\n",
    "    # 目標網頁的URL\n",
    "    #url = \"https://rephonic.com/podcasts/li-jing-lei-de-chen-jing-shi-jian\"\n",
    "\n",
    "    # 發送GET請求獲取網頁內容\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # 檢查是否成功獲取網頁內容\n",
    "    if response.status_code == 200:\n",
    "        # 使用BeautifulSoup解析HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 尋找包含RSS網址的元素\n",
    "        find_rss=soup.find_all(\"\",text=re.compile(\"@context\"))\n",
    "\n",
    "        # 要解析的 JSON 字串\n",
    "        json_str = find_rss[0]\n",
    "        # 解析 JSON 字串\n",
    "        data = json.loads(json_str)\n",
    "        # 提取 identifier 後面的文字\n",
    "        identifier_text = data[\"identifier\"]\n",
    "        print(identifier_text)\n",
    "\n",
    "    else:\n",
    "        print(\"無法獲取網頁內容\")\n",
    "    return identifier_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a566d30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寧可當吃貨 一共 119 集\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"D:\\Podcast_mp3存放區\\mp3\\\\\"\n",
    "\n",
    "# #貼上rss即可下載。＃新資料夾\n",
    "# get_rss_file('https://feeds.soundon.fm/podcasts/ecd31076-d12d-46dc-ba11-32d24b41cca5.xml',\"all\")\n",
    "# #史塔克實驗室\n",
    "# get_rss_file(\"https://feeds.soundon.fm/podcasts/e4f101be-289a-4101-bb11-59fc61e5c88b.xml\",\"all\")\n",
    "# #跳脫Do式圈\n",
    "# get_rss_file(\"https://feeds.soundon.fm/podcasts/22505944-fec2-4417-b277-649ce5d3a491.xml\",\"all\")\n",
    "#週報時光機 (還沒)\n",
    "# get_rss_file(\"https://feed.firstory.me/rss/user/ckcnhs4x0yuqw0918kkui2pjw\",\"all\")\n",
    "#寧可當吃貨 (還沒)\n",
    "get_rss_file(\"https://feed.firstory.me/rss/user/cklase4t37jae0872lm9x1xmv\",\"all\",folder_path)\n",
    "#科技浪 \n",
    "# get_rss_file(\"https://feeds.soundon.fm/podcasts/03f4a53e-80cf-4a20-ad2c-bdb31a76c7b3.xml\",\"all\")\n",
    "#老高 \n",
    "# get_rss_file(\"https://anchor.fm/s/3ba51528/podcast/rss\",\"all\")\n",
    "#Joe & Jet 未過濾的 with Jason\n",
    "# get_rss_file(\"https://feeds.soundon.fm/podcasts/78a91a6a-5c6b-43cc-aaac-7918f792e5ae.xml\",\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143fd6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "無法獲取網頁內容\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[38;5;66;03m#下載所有節目\u001b[39;00m\n\u001b[0;32m     27\u001b[0m             get_rss_file(rss_url,\u001b[38;5;241m3\u001b[39m)    \u001b[38;5;66;03m#後面的後面的數字   是測試用的時候。要下載幾集。  ＃要全部的集數。 輸入\"all\" \u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     rank_list_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(rank_list_n)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rank_list_n):     \u001b[38;5;66;03m#這邊的迴圈  是指定跑幾個節目\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#得到該節目的rss\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     rss_url\u001b[38;5;241m=\u001b[39mget_rss(\u001b[43mrank_list_herf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#下載所有節目\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     get_rss_file(rss_url,\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #先得到所有分類的名字\n",
    "    category_name=get_all_category()\n",
    "    #使用者輸入想跑多少分類\n",
    "    category_n=input(\"你想要跑多少種分類？ 輸入數字，或者all抓取全部\")\n",
    "    if category_n==\"all\":       \n",
    "        category_n=len(category_name)\n",
    "    else:\n",
    "        category_n=int(category_n)\n",
    "    \n",
    "    for i in range(category_n):      #這邊的迴圈  是指定跑幾個分類    \n",
    "        #得到該分類的所有節目名稱跟網址\n",
    "        rank_list_herf,rank_list_name=get_name_href(category_name[i])\n",
    "        #使用者輸入想跑多少節目\n",
    "        rank_list_n=5        #(\"一個分類想要抓取多少節目？ 輸入數字，或者all抓取全部\")\n",
    "        if rank_list_n==\"all\":    \n",
    "            rank_list_n=len(rank_list_herf)\n",
    "        else:\n",
    "            rank_list_n=int(rank_list_n)\n",
    "        \n",
    "        for j in range(rank_list_n):     #這邊的迴圈  是指定跑幾個節目\n",
    "            \n",
    "            #得到該節目的rss\n",
    "            rss_url=get_rss(rank_list_herf[j])\n",
    "            #下載所有節目\n",
    "            get_rss_file(rss_url,3)    #後面的後面的數字   是測試用的時候。要下載幾集。  ＃要全部的集數。 輸入\"all\" \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
